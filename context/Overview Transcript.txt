Confirmed ACME Overview Meeting Recording

Participant_B started transcription

Participant_B   0:07
OK. And then, you know, I'll just call out for the folks we haven't met before. Andre, you want to introduce yourself?

Participant_E   0:14
Yeah, absolutely. I'm Andre, BI developer with Ida Helen, have been with the company for a little over three years at this point. So working on anything data basically.

Participant_B   0:32
Thank you. We have, let's see, Participant_P.

Participant_P   0:37
Yeah, Participant_P BA developer as well. Been with the company for a year and a half and so Yep.

Participant_E   0:46
You mean data scientist? Sorry.

Participant_P   0:48
Yeah, I guess it's, yeah, it's up and coming, yeah.

Participant_E   0:50
Huh.
Ha ha.

Participant_B   0:55
And I have a name here and I don't want to mispronounce it. Is it 22?

Participant_P   0:55
Used to be a developer.

Participant_S   1:00
Just Participant_S. Participant_S. Yep. Hey, I'm Participant_S. I've been here for six months and I'm also a BI developer.

Participant_B   1:02
Very good. Thank you. All right. Well, so we wanted to get together. All right. We had a I I think it's been almost a month now since we we first initiated. I know you folks wanted to take a step back and and and meet with your ModelQ partners.
We wanted to you know gauge progress here and and and you know understand where you're at and look if to to see if we can make some progress and and and maybe reintroduce you know some of the goals of the project that.
Were signed up for with you. So the thought was that for you to give us kind of that high level, I don't want to call it status, but an overview of you know where you're at with with your technology side as well as the use case that you're working on.
And then you know we can do some Q&A and and discuss perhaps you know where we can help you in in in moving forward. So with that said, I don't know Participant_R if it how you want to.
Take that you know to maybe you want to start with the architecture side or the platform or or the use case.

Participant_R   2:23
Really up to you guys, I guess. How would you guys want to kick it off? Do we want to touch on kind of what ModelQ is is working on initially here to like in relation to like their their use case that they're working on or or do we want to start with the architecture?

Participant_B   2:29
Well.
Yeah. Well, why don't we start with the architecture and what I'll show you is is something that you gave us, right. And and maybe you can give us an idea of, right. So there were actually 2 views you you gave us this view here and then you also gave us kind of the future future state right of of what what you're aiming towards.
And so we wanted to get an understanding you know where where you're at from your on-prem to the connection to the cloud and you know obviously Participant_C or you know team please jump in if if you have additional questions about you know these diagrams.

Participant_R   3:16
Yeah, I don't mean to put you on the spot, Andre, but would you be able to give a high level overview? Sorry.

Participant_E   3:16
Yeah.
Yeah, absolutely. I will kind of reference some of the projects that are ongoing because I think that that would be pretty important to know what's happening. So the on Prem side looks pretty accurate at this point. We have a project with a vendor where we're putting all of the.
IT, MES, SCADA system layers into UNS that's gonna be hosted by our MQTT broker. We're partnering with Hive MQ for that purpose. So that place of MQTT broker client on both on Prem and the cloud is gonna be.
Maken by Hive MQ, so that's a partner on that site. We also have a partner called Highbyte on the side of the SCADA ignition piece on the on PRAM.
That helps to translate some of the protocols and do some of that heavy lifting around that. We're we're underutilizing them right now, but it's also in the progress. We are rolling out a lot of ignition.
For our baby MES slash replacement for some of the Rockwell systems in place. So those are most of the projects that are happening on Prem. So all of that data will will.
Shape up at the end of all of these projects into something that we hope is gonna be like a unified place for all of the OT data that will be fed into the MQTT broker and then whether we aggregate that to a certain level by that point or not.
It will also decide on case by case scenarios, then that will be fed via MQTT to the clouds and from the cloud it's gonna be placed into Data Lake to create that historical aspect for reporting machine learning.
And other pieces. Alim, I see your hand is up.

Participant_C   5:36
Yes, Sandrak, I just have a quick question, right. So I understand like you will have your MQTT broker on Prem and in in the cloud. So you're Are you sure that you can go from the broker directly into data lake or you're thinking putting?
You know something else as a gateway like event hub or or something? Have you guys tested that?

Participant_E   5:58
We're, yeah, we're pretty sure the broker that we have has a native connection to Data Lake. We are writing Parquet to Data Lake right now as our POC.

Participant_C   6:08
OK.

Participant_E   6:14
There is the functionality is sort of very similar to what like Event Hubs or IT Hubs offers as well. So that's we know that that it works.

Participant_B   6:23
OK.

Participant_P   6:31
Yeah, so and just a little bit of context, it does land parquet files every 5 seconds right now, so it's definitely working.

Participant_E   6:32
So.

Participant_C   6:41
OK, I just want to make sure.

Participant_E   6:42
Yeah.

Participant_P   6:42
Yeah.

Participant_E   6:43
Um.

Participant_C   6:44
Because generally what I have seen is I have seen you know people put you know Event Hub I know in in in the in the MQTT right that's acting as a you know a subscriber from the.
You know left side which is on Prem and then once you have filters and whatever you have, you know messages that you're distributing between the publisher and subscriber, right. I think it goes to the gateway but I have never tested MQTT directly to data lake but you know things are changing rapidly so.

Participant_P   7:18
Yeah, Hive MQ has an enterprise version and with that version you're able to connect directly to Data Lake. If you buy the not enterprise, can't remember the exact name, but you do have to go through MQTT to Event Hubs to Data Lake.

Participant_C   7:25
Mhm.
Can you can you so now I'm so hold on I I know natively it cannot do it. You know that's why I'm I'm, I'm, I'm, I'm kind of hung here. So you are developing something else to go to data lake or or you are saying there is a connector directly to data lake.
Cool.

Participant_P   7:54
There's a connector, yeah, if you buy the Enterprise version of Hive MQ.

Participant_C   7:56
OK.
Uh, there you go. OK. Thank you. Perfect. All right, we can move on now.

Participant_E   8:05
And you can think of the left side as just being one plant. Eventually it's going to be all three plants, sort of the on-prems. There's going to be 3 different on-prems with their own MQTT broker at the edge.
And they all will be feeding into the same cloud MQTT broker. So that broker will be playing role of just enterprise broker for us and all of that data will be kind of ISA 95 formats structured into.
Specific topics following UNS slash ISA 95 and that's what we're thinking is going to be landing into the data lake and then the data lake is going to have the connection to fabric.
Basically, we'll use Fabric as just the parallel processing engine to do all of the processing of that data. The upkeep on the right side is no longer in the picture. That was supposed to be our CMM.

Participant_C   9:11
Mhm.

Participant_E   9:18
System. So we're walking away from that. We're demoing a different CMMS system that would be more integrated into MQTT world.

Participant_B   9:28
OK.

Participant_E   9:32
Thank you. Red Zone is a cloud solution that we are using and Dynamics 365 is our ERP system. So that's where the enrichment of the OT data with a Business Insight will happen, will will marry that dollar numbers.
That are in D 365 to the sensory numbers that come from the OT world.

Participant_C   9:58
OK, perfect. So once the ingestion happens, right, where are you going to perform transformation of the data? What are you using for transforming the data for transformation?
In the fabric I assume and in the fabric, are you going to use event streams or what is the plan?

Participant_E   10:13
Um.
Can you explain what types of transformations you have in mind?

Participant_C   10:26
Data transformation, right? So, so, so you have multiple. Mm-hmm.

Participant_E   10:29
Well, I understand data transformations. What what kind like OT side data transformations or or like cloud side data transformations?

Participant_C   10:38
Otiside.

Participant_E   10:39
OT side. So we do have a tool called Highbytes that allows transforming from certain protocols to different protocols like Spark plug, BMQTT, all of that. It also allows it's kind of like a data OPS tool.

Participant_C   10:40
Mhm.

Participant_E   10:56
That works as just basically pipelines where you pump certain type of data into one end. It comes out out of the other end on the OT side. The like preparation for transformations in the cloud is gonna be in fabric.

Participant_P   11:07
Problem.

Participant_E   11:16
So that is just gonna be where we'll probably do the modeling for that data. For like ML purposes and reporting purposes, we'll just use notebooks and other features.

Participant_C   11:28
Mhm.
OK, how how familiar are you guys with the fabric?

Participant_P   11:34
And.

Participant_C   11:39
Like what is your, you know, level of understanding? You know CloudProviderA Fabric like you are, are you guys well versed what it can do versus you know, are you guys going with the traditional things? Because I see the icon for Fabric.

Participant_E   11:39
Oh.

Participant_C   11:56
I know there are not too many details there, but how how familiar are you with fabric?

Participant_E   12:02
Participant_P has four years of fabric experience, given it's been out for two years, right?

Participant_C   12:06
OK.
Hmm.

Participant_P   12:10
I saw it's it's an inner joke. It's just, yeah.

Participant_E   12:12
Yeah, yeah. No, we we've been demoing Fabric and the tools since the since it's pre GA basically. So we are familiar with its capabilities.
Some of our team members are more familiar with Databricks, but it's kind of like a clone of that in a way. So we've worked and demoed tooling like event houses, lake houses.
All of those concepts, data warehouses, pipelines, so everything that existed in Azure, we have somewhat understanding and then as it's packed into fabric tooling, that's kind of our knowledge.

Participant_C   12:58
OK, OK. All right. Now I'm just, I'm not questioning your design, just trying to remove anything that we can actually use fabric for, right? Definitely, right. That's why I'm trying to slowly peel it away. Again, that's not our responsibility.

Participant_P   13:01
Yeah, we've.

Participant_E   13:09
Mhm.

Participant_C   13:16
From the scope perspective, but I want to make sure that your design is solid and secure honestly speaking, right? And it to me it it looks good. The only thing that was not clear to me was the cloud MQTT, but you have made it very clear to me, you know you. So I don't know whatever the cost is really not here for the cost conversation.
Yeah, we are good. We can move on now. Thank you.

Participant_P   13:37
And just to add a little bit of context.

Participant_E   13:38
Mhm.

Participant_G   13:39
One of the things, one of the things that oh sorry, Participant_P, one of the things that that for the CloudProviderA team is to evaluate the scalability and of course the security of the design as as it as it looks on paper now but but the.

Participant_P   13:43
No, go ahead.

Participant_G   13:59
The way it's put together I think is pretty solid, but as we begin to scale the operation into more and more PLC sources, you know, how do we, how do we feel that that holds up in the way that we want and performs in the way that we want?
And one question I have around that might be notebooks, because notebooks may not be as performant as maybe either Databricks or Spark.

Participant_C   14:29
Mhm.

Participant_G   14:29
For processing thoughts.

Participant_C   14:33
So I know you know it's a third party, right? It is, it is a great product honestly and it's highly scalable, but it really depends on on the design and the way I am seeing right design looks, you know, pretty good. But again, right, one of the things that we will do is we will verify.
Fight, you know and validate how the how fabric is set up and how the connections are made, if they are secure or not. That's one of the things that we'll definitely do, Participant_G.

Participant_P   15:05
And and for right now.

Participant_C   15:06
I I see you're shaking your head so.

Participant_B   15:08
Yes. And and so you know and and that's part of the scope.

Participant_G   15:09
Yeah, yeah, I just. I was just. I'm just agreeing.

Participant_C   15:12
Yep.

Participant_B   15:13
Yep. Yeah. So as part of the scope, right, is to assess the the overall, you know, the the fabric, you know that is stood up properly and then the security for that. I know Participant_P, you wanted to speak, so I'll let you go.

Participant_G   15:24
Yeah.

Participant_P   15:26
I was just gonna add a little bit about what's going on right now in fabric cause we we are landing parquet files every five seconds in the data lake and so right now we've test we've we've been playing around with structure streaming.
Pypark structure streaming and it seems to be working very well. So yeah, any suggestions around how to, you know, do live streams of data or or anything related to that would be appreciated on your.

Participant_C   15:47
Mhm.
Yeah.

Participant_B   15:59
Yeah. And and one of the things that just mentioned, right, since we were kind of pausing the engagement, there are fabric team members that will be joining the project that you know the bringing that expertise. We just haven't brought them on board yet because you know those folks will be busy then and they can't be.

Participant_P   16:00
On your end as well.

Participant_B   16:19
You know we can't have month delays before they work and they need to be elsewhere. So, so as we get kicked off and as we get moving in our you know 910 week engagement, we'll have that those folks here kind of on a half-time basis to work and and bring that fabric expertise to the project and right now we're at the.
The initial just getting ready to get kicked off type stage, but we will be bringing that expertise with us to help you.

Participant_G   16:47
Yeah, perfect. And I think that part of that would be I guess doing some of the some prediction around load and per for on adding many machines to the into the design.

Participant_B   17:02
Yeah. And it might be a good time. I know, Robert, you wanted to speak a little bit towards kind of the, you know, maybe the end. I don't know if it's a good time now or if you want to.

Participant_T   17:10
Actually I just want to make sure I understand. So this is this connection today between your on-prem and your cloud instance is this this is in place today. This is how you're capturing data today from your devices.
And you're and is there a fabric instance stood up in the Acme-Sub in ten tenant or is that stood up in the ACME tenant?

Participant_P   17:27
Yes.

Participant_E   17:38
We have.

Participant_P   17:38
It's in the Ier Horn.
Have a little F2 capacity.

Participant_B   17:48
OK, so.

Participant_P   17:48
Well, we'll vamp up later on to an F64.

Participant_E   17:51
Yeah, once we get rolling, obviously we're we're going up, but it's it's mostly POC. This is the out. Yeah, like everything is POC. The amount of data that we're pumping right now is what's how many sensors would you say?
Uh.

Participant_P   18:11
It's like 2000 tags or something like that.

Participant_E   18:14
Yeah. So it it will be growing obviously in the future, but we just did POC of these. So we don't have everything ramped up at this point as we're rolling into the project, we'll be going up in fabric and.
All.

Participant_P   18:30
Yeah.

Participant_T   18:30
Just so do do you guys have some metrics or KPIs around that scale scenario? We can do it with two, we want to be able to do it with 200, 2000, two million, et cetera.

Participant_P   18:45
So right now we're pumping data from only one of our lines from one of the plants and that alone is generating 2.7 billion rows per month on average and so.
Uh, we we could do the math based off of that. Um.
But that's probably as close as we would get for a prediction.

Participant_B   19:12
And that would be for the Acme-Sub, for the Acme-Sub use cases, right?

Participant_E   19:18
Yes. So either Helen, we do potatoes. We have three plans. Each plan has like 3 lines roughly.
So that's 2000 per plant probably is what we're gonna potentially that we will be pulling on the aggregation side of the data and on the side of how many sensors we aren't sure yet we we don't necessarily want everything in the.
Clouds, but everything that pertains to machine learning processes and discovery of potential machine learning implementations, that's where we're starting point of what we push into cloud.

Participant_C   20:08
Perfect. 1111 more question, right. And before I ask my question, one of the things Participant_G, we will definitely do is based on what I heard, right, the scalability, will we have calculators, you know, once we start engaging?
I will go through it and I will specify what you know SKU you may need for the capacity for the fabric side of it. So those are the things that we definitely will bring like maybe it's Ms. Fabric F64 or or less or more whatever that may be, we'll give that capacity as well to you.
And so my my question right is are you using any kind of AI model or that's not the case at the second at at this second or for this phase you are only looking at the analytics part of?
Your data.
Stream and then do analytics. Is that what's your final goal?

Participant_E   21:05
No, the final goal is ML model and that's where we do have ModelQ. That's a partner that's working with us on I would say kind of bridging between on Prem and cloud side. So they're the partner who.

Participant_C   21:09
Mhm.

Participant_E   21:23
Will work with us on building 1 use case ML model and deploying it to on Prem and supporting it. So that's our first baby steps into that world and if it goes well we see growth in that department.

Participant_C   21:40
Mhm.

Participant_E   21:42
Um, but that's where we at.

Participant_C   21:44
So they are creating a model for you for your specific case from scratch. They are not using, you know, already built models that are available, you know, by CloudProviderA or by any vendor, third party vendors like you know, Facebook. I'm just giving some random names, CloudProviderC, you know, CloudProviderB and whatnot.
Is that what my understanding is?

Participant_P   22:05
It.

Participant_E   22:07
No, it's it's gonna be deterministic model. So it's not like LM or anything. It's gonna be very specific to use case that will be in numParticipant_K prediction that will control set points of.

Participant_C   22:09
Mhm.

Participant_P   22:10
Oh.

Participant_E   22:21
Machines, so it will be deterministic with specific features, and Participant_P probably can speak more to that.

Participant_C   22:22
Mhm.

Participant_P   22:31
Yeah, it's more traditional ML at this point. But in the future, I mean, as we have all the data centralized in Fabric, who says we can't spin up a copilot or some sort of agent in there? So yeah.

Participant_C   22:35
Mhm.
OK. Yep. I traditional model, I I think I understand. So they would be basically going through you know data cleansing and then they will come up with you know some you know what do you call those?
Where they go and compare things. I I know what what the traditional method is. So yeah, that's fine. We don't have to go to that low level details. That's something they are working on it. So we are good. OK, so now let's talk about security. We have Participant_D. By the way, I don't have any questions unless Robert, do you have any questions before I?
Ask, you know, Participant_D to chime in for what he's going to do from the security perspective.

Participant_D   23:27
Hey, guys, how you doing? So, yeah, thanks, Liam. So, yeah, basically what I'd like to do is, you know, dive the the picture is great that I'm looking at right now, but dive a little deeper, you know, a little closer.
To break out, you know kind of all the the integration points, right. So for example within the on-premises like you know how does the data get into the cloud, right. That's probably a subscription within some tenant, right. And then you know how fabric the SAS service connects to that and then breaks.
Everything out to specific workspaces down to you know the lower level components, right. And then you know obviously what we're gonna be looking at is you know authorization and identity or authentication authorization services like how?
How services are are handling the identity and to traverse data you know in and out who needs access and the various patterns. So I do have a a slide deck that I use to kind of talk through each point with.
The various integration patterns. So for example with fabric security, you know what we're looking at is the fabric service itself, authentication, authorization, data residency and we break it out to a conversation of data handling like how is data being handled at rest and in transit, the various type of telemetry we're looking for.
And then the one lake and workspace security and then we could go even a little lower level item security. And then we do speak related to the permission model. How is that being governed again, you know, different identities, right? Like you know, are we using external identities? How are those governed, you know?
You know how is security gaining visibility or or managing access control into these various resources? Power BI security. You also go into network security and then collaboration and sharing and or managing security, right? So it's a lot of topics related to security, right?
I know that you know within the statement of work we we removed purview, right? So that's you know, one of the key components for you know, data governance and security. What are you guys planning to use for that today?

Participant_R   25:54
And I think this is where we probably need to have a couple other resources be on a a follow-up call. We have Participant_F and Participant_N on on our team that we can include Participant_D in the future that would probably know a little bit more about both those type of questions.

Participant_D   26:10
OK, great. Perfect.
And then obviously you know the SOC, right? Like as all the information you know we do, you know we can help you dump the tenant level security settings which we we can go through talk about those, which ones need to be enabled, disabled.
But then you know any of the analytic telemetry, where does it, where should it go, right? And then you know, you know, how does it get to whichever sim you're, you know, platform you're using and what are some key alerts that you might want to be looking at?

Participant_T   26:50
Do you guys from from the either the ACME powered side or or the OR Participant_R your side, do you see any cross tenant collaboration happening? Something's housed in the ACME tenant but used by the Acme-Sub?

Participant_D   26:51
The bed.

Participant_T   27:07
Resources.

Participant_C   27:13
All the time.

Participant_G   27:13
Most of that shouldn't apply to this, uh to this project.

Participant_D   27:13
We.

Participant_G   27:18
It should be pretty, pretty contained with Acme-Sub and unless there's something really that you guys needed an ACME perspective, I don't think so.

Participant_P   27:18
Well.
The only thing that is in their tenant is Dynamics 365.

Participant_R   27:27
What the?

Participant_E   27:31
And.

Participant_G   27:32
Yeah, I mean.

Participant_E   27:35
Oh, sorry.
And I know that Participant_F's structure for firewall as it hits, it goes through ACME as well. So that's.
So that we don't spin up our own firewall and they did hub and spoke kind of lending zone structure and that's what they're thinking of doing for this project where Acme-Sub is going to be its own tenant, but the firewall is going to go through a centralized ACME.
Um.
Firewall on that site, but I'm a noob in that sphere, so I think Participant_F could could weigh in during one of our next meetings.
Because and to give a little perspective to that, we are trying to avoid it using any public endpoints for any anything for this project and going through private endpoints connecting all the dots.
All the resources and that's where that configuration plays a role.

Participant_D   28:47
Yep. Yeah, so.

Participant_C   28:48
Yeah, so that that reminds me, right? Fabric does not support, you know, private endpoints as of now. So I I'm sure you're aware of it. OK, but everything else, you know, example, right? Data Lake, which is nothing but.

Participant_E   28:57
Yep. Yep.

Participant_C   29:04
You know storage account right? And you can have private endpoint for that and how you make the connective from you know cloud MQTT right? We can definitely verify it.

Participant_E   29:09
Yep.
Yeah. So the the goal is we land everything in either Helen as far as resource allocation, we will be helped by some of the ACME more proficient in in these topics as we go by this project, but.

Participant_C   29:19
Mhm.

Participant_E   29:31
The goal is to land everything with an IRL and tenants as much as we can.

Participant_C   29:37
OK.

Participant_E   29:39
Participant_G, unless you have other instructions, obviously.

Participant_D   29:39
And that's the.

Participant_G   29:41
Yeah, no, I don't. I don't. I didn't see any issue with that. And also too with the with the native capabilities of Dynamics, I didn't see any issue there either. So that's why I mean unless you guys have seen some issues with that.

Participant_E   29:58
Yeah, we we like Participant_P and Participant_G mentioned, we do have Dynamics that is sitting in RDL tenants and we are on our track to utilize the EntERPSys_A fabric connection.

Participant_P   30:04
It.

Participant_E   30:14
To pull data cause we we're pretty old school, we're still using BRD for a lot of stuff and that cross tenant situation there we're we're kind of bypassing it by connecting it to ACME tenant fabric.
And then we just shortcut the data verse into our own tenants. So that's where.
A little bit cross tenant is happening.

Participant_D   30:42
And then on the right side, there's the cloud picture that represents the Acme-Sub and tenant, right?
In the word, I'm not clear right now, OK?

Participant_E   30:50
Yes, Yep.
And the Red Zone is their own clouds and Dynamics is ACME cloud.

Participant_D   31:00
OK, red zone is a OK red zone is who? Whose tenant is that or?

Participant_E   31:07
It's a SAS pass. It's I'm not entirely sure, but they're self managed style.

Participant_D   31:08
Oh, he says. OK.
Oh, OK, OK, this just doesn't reflect already where the ACME sits, right?
The audio tenants.

Participant_E   31:25
Yeah, ACME 10 is the only piece here is Dynamics for that.

Participant_D   31:26
OK.
OK.

Participant_B   31:30
Is is that a good time to switch into kind of this future future state that we we will also share that was shared out with us any any additional comments about that or is this too soon?

Participant_G   31:46
Nope, let's go.

Participant_B   31:49
Who can? Who can explain that?

Participant_D   31:51
So let let me just make sure I understand in terms of like users accessing the various workspaces and or governing the resources within you know some of the subscriptions they're they're going to be either Acme-Sub and and workforce identities or RDS.
Is that correct? They're not external users like consumers like not affiliated with the with with your organization. Is that a correct statement?

Participant_E   32:20
Yeah, not in the scope of this project.

Participant_D   32:23
OK, so the two personas would be, you know, either you know from a from high level perspective, you know Acme-Sub users, users that exist in the Acme-Sub tenant or users that would exist from the ACME.

Participant_E   32:37
Yes.
Uh, correct. Either Helen will will be used majority of the time ACME if they want to hop in sort of.

Participant_D   32:41
OK.
Mm-hmm.
OK. And we haven't talked about like how they would access it if it's a cross tenant synchronization or like AB2B object or a separate managed credential, right? Has that been determined?

Participant_E   33:05
Uh, right now. Sorry, Participant_P, go ahead.

Participant_P   33:09
No, I was just gonna say they're using CSA accounts, right, to access our tenant. I don't know that much. That's all I know.

Participant_E   33:17
Yeah, they're they're.

Participant_D   33:18
OK, yeah, I don't. What's a CSA account like? Like a a cloud account or?

Participant_P   33:22
Like, yeah, like the roles they activate. Um, what's it called?

Participant_E   33:24
There mhm.
Yeah, they're guests. So. So our admins and their admins are friends and they just invite each other into each other's tenants and they're guests and then they're given the CSA access, which is basically like a contributor to a specific.

Participant_P   33:30
OK.

Participant_D   33:31
Oh, OK, good.

Participant_E   33:49
Subscription or whatever the role may be and it just times out in eight hours or something like that. So that's the that's the current structure that we follow.

Participant_D   33:58
OK.

Participant_P   34:02
Privilege Identity Management groups.

Participant_D   34:04
Yeah, yeah. So basically that that's a pattern that, yeah, we would probably lean more towards because you know, like for example in the Acme-Sub and tenant, if I need to invite Alim and let's say for example he's in the, he's in the ACME tenant, right, I could invite him as a guest into my tenant, so.
Hey, I don't need to manage his password. It's an organization I trust, right? So he can essentially use his credential or his identity to access resources that I governed. And then once he comes in, you know, obviously from a security perspective, we don't.
We want to put governance around the roles that he he's he's granted rights to. At that point I would use my privileged identity management policies so he can activate it and then get those authorizations to execute whatever he needs to do. And we would back that through through either approval process or MFA.
But the gist of it, we're time boxing it, so he only has access for a specific period of time, right?

Participant_B   35:01
OK.

Participant_D   35:05
So that that's kind of you know some of the thought process we we we you know we do around the governing of of privileged accounts into your tenant to manage access.
You know, when we do get that, that low level is kind of where I'm gonna try to go to when we start having the ACME folks and we start diving a little deeper, right? Ideally, you know, when we look at this, I could see, you know.
The subscription, like the Azure, the environment, the subscription and then potentially even the resource group that the various resources are going to exist in. From there, you know, I'll have a lot of questions related to OK, like how are resources being spun up if they're doing it through a CICD?
You know, do you have policies to govern the type of resources that get provisioned? If is it? Is it a shared structure where you may have other resources that exist within a resource group and or subscription, right? And then how do we manage those permissions to prevent any users, users and intent?
Eventually authorize, you know, getting access to these resources. Those are types of security questions I'd be looking at, so.

Participant_E   36:21
Mhm.

Participant_B   36:22
Thank you.

Participant_E   36:23
And to give you current state right now, it's Participant_P, myself and  Participant_S, our BI data kind of stuff. We have access into our tenants and then we have admin.
Who has access to our tenant? And that's almost it. From ACME inside we have just 576 people, something like that for stuff and from ACME.
Just a few of them, just a couple of them. So for us being so nimble, I think it's definitely possible to improve without overburdening for such a small group, but I know that on a big scale.

Participant_D   37:04
Yeah.

Participant_E   37:09
US working with ACME, some of those pieces will definitely benefit.
Cross tenant collaboration and all of that.

Participant_D   37:17
Yeah, Yep, Yep, Jackie.

Participant_B   37:21
Do we want to make that switch? Do we have a lot of these kind of the architecture questions on? Can we talk a little bit about the the use case and where we're at right now?
Maybe get into, you know where where you left off with ModelQ and and where that stands.

Participant_E   37:41
Participant_R, who do you want to drive that one?
You can drive that one remote.

Participant_R   37:45
Wait a minute.
Go ahead, Participant_P.

Participant_P   37:52
Yeah, yeah, I can. I can try. We'll see. So I guess the use case is they want to use machine learning, whether it's a linear regression, XG boost, whatever.
Algorithm to be able to talk to ignition and then from there can control the PLC value for a specific machine and so I guess in the context of making potatoes.
It would be kind of like what you do right now when you do potatoes at home, mashed potatoes at home. So you peel it, you pre cook it, you cool it off and then you like cook it again and within that process.
Depending on the solids of the potato, you have to pre cook it X amount of time and so that would be one of the variables, how long you cook it and how high you cook it and so.
They want to use machine learning basically to determine those two variables to optimize, you know, or preventing from undercooking or overcooking a potato at the pre-cooking stage.
I think that's kind of like the use case right now that ModelQ is shooting for and we've sent some data to them, so they're doing the exploratory data analysis at this point, so.
They have the data points, they've asked for more and yeah, that's pretty much the overview of the project. And we started our conversations with ModelQ like 3 weeks ago. So it's in, it's in the beginning stages.

Participant_B   39:46
Right. Yeah. And I, I, I know there was some concern expressed, right. Participant_R, you you said suggested right. They need, they're gonna need more time, you know, focusing on that use case, right. When I think you know, when we talked internally here, we're talking about the fact that we probably need to take a step back and to say, OK.
Let's help you get your architecture ready to be able to take that step of of bringing all that data in and being able to use fabric and you know to have that secure and to to define that architecture and and and.
And help you with that.
I I think that that's where we are, right? Is how do we, you know, do we take a step back here and and figure out how to help you in the short term to get you ready so that when that data is coming in full blast that that that you're ready is is that what you're thinking?

Participant_R   40:46
Yeah, I think so. I think the the pieces ModelQ is very focused on obviously the the generation of that model and getting the model to a point where we would be able to to validate and get it to that, you know get it to the validation and be able to see if it is producing the correct result.
So I do think that the Fabric Foundation building is where the obviously CloudProviderA you guys would plug in. So yeah, I think it's a little two different silos that connect but.
Yeah.

Participant_P   41:25
And and the other component, so there's a kinda like the data engineering side that you guys are talking about, but if we can set up our fabric environment as well to be capable of doing ML OPS as well, that'd be fantastic. I know you.
There's been some implementation of ML flow inside of Fabric and getting us up to speed in that sense would be also ideal.

Participant_B   42:01
Understood.
Any questions team?

Participant_S   42:06
You're muted, Participant_G.

Participant_E   42:07
Hear mute.

Participant_G   42:08
I I Yep, I think that the the one question that we had was we we're not entirely sure of the feature set that lives inside of the ModelQ CloudProviderB implementation of that platform.
And if there are some critical features that maybe we would need help with or I or at least breaking them down, I I don't see any issues with maybe some of the core, you know, operations pieces, but.
Some of the some of the maybe uh uh.
Lipstick, Rebecca, lack of a better word in monitoring or maintaining, maintaining those pieces in their platform, transferring those services to.
Fabric, I think maybe we that would be a place to where we may get some benefit having you guys consult on that. What would you say Participant_P or or Andre?

Participant_C   43:07
If they share, if they share their architecture right, I don't think they will share, but.

Participant_G   43:12
Yeah, part of that, right. Part of that is secret sauce, right. So what? And and we just don't know this yet, right. So it if they're going to hold back on some of these, some of these pieces that end up being critical.

Participant_C   43:18
Mhm.

Participant_G   43:28
That's where we've got to really group the wagons together and solve some of those, but it's all preliminary at this point.

Participant_T   43:37
Yeah. And Participant_G, that's one of the things I think when I think back about being able for scale, supportability, besides whatever ModelQ is doing, the next thing is going to come out, whether it's an ML model, an agent, something, whether you buy it, build it, however you're going to do it, you're going to have to deploy something in your environment to.
Get some value, whether it's yield improvement, scrap waste, whatever it's going to be, we wanna make sure that it's scaling to that. So it's not we've hard coded something in that works for this one scenario, but isn't scalable to support.
The business operations.

Participant_G   44:15
Right, right. And that's, I mean, are you guys in, Andre Participant_P, Tony, are you guys in agreement? Is that kind of the risk that we see with the project?

Participant_E   44:30
Yeah, I think there is gonna be a little.

Participant_G   44:32
No, OK.

Participant_E   44:34
I no, no, no. I agree with Participant_G. Um, sorry. Maybe I should have said no.

Participant_P   44:35
8.
I.
Oh, sorry, maybe I should have said no.

Participant_G   44:41
Ha ha.

Participant_E   44:42
Yeah, definitely. I think our partner is very transparent and they're very willing to have everything be our Pi IP. I mean, it's a long day, so.

Participant_G   44:55
Mhm.

Participant_E   44:58
Everything that we know about now is going to be very open, very ideal and IP. There is some pieces where there's going to be like a deployed agent on Prem that will monitor the.

Participant_P   45:03
Very, very.

Participant_E   45:18
Drift of the model, kind of like Participant_G was saying. We don't know exactly what that is and we don't know if they're gonna be as transparent as to because that kind of borders their support agreement with us as well, so.

Participant_P   45:24
Yeah.

Participant_E   45:37
That something is watching the model and then once you get out of the lower control, upper control, you're kind of end up to maybe shifting some a little bit the model, tossing it a little bit till till it starts working again, right. So that piece is the one we don't know the most about at this point.

Participant_P   45:44
Try it out.

Participant_E   45:57
We think it's going to be pretty open for us to use and it potentially will be our IP, but you never know till you get there.

Participant_G   46:10
Yeah.

Participant_P   46:13
And.

Participant_C   46:13
See some of the keywords that you guys use, right?

Participant_G   46:14
Yeah, and I and I have a lot of.
What's that? Sorry one more time.

Participant_C   46:25
But Participant_G, you are saying something.

Participant_G   46:25
Could you repeat?
Oh, I just, um, I was gonna say that I've got a lot of confidence in the team, their ability to, you know, monitor.
But that the team is, you know, can't scale maybe as fast as we want to implement some of this. And so we really want to understand and get our arms around that, that part of it in this project early on so that we don't end up, you know, with.
Because, because I think one of the goals that we've got is to be pretty self-sufficient when it comes to the project down the road that we don't have. And the way the way Brad, my boss put it was that we don't want to have to call a vendor like ModelQ if we've got.
Had an issue on our in our one of our plans. Does that make sense to everyone on the team? Because because I think that's where that's the level of self-sufficiency we're looking for. We don't want to have them on call.
So that would be one of our one of our operational goals here when it comes to our implementation.

Participant_C   47:35
So, so, so Participant_G, if I if I understand your question right. So for example you know if I'm not mistaken when I heard Participant_P is your data scientist, right. So he understands the EDA right and what what happens under EDA you do like couple of analysis like univariate and bivariate analysis and so on and so.

Participant_G   47:53
Yeah.

Participant_C   47:55
So forth. So anything with the code right or enhancements your team can do. But the piece that is is the the puzzle is actually what are they doing with you know CloudProviderB there. Why CloudProviderB is in the picture? Because if the development is on your data, right, that's your.
Data and if the model is being created for you, what is the CloudProviderB doing here? That's like you know, beyond my comprehension at this second. Unless they have a model that they have created, they are going to use that model in CloudProviderB, call the API of the model and pass the data. That would have made sense to me. So at this second it doesn't make sense to me.

Participant_G   48:34
Right.

Participant_P   48:34
So ModelQ, yeah, has their own fabric per SE. It's their analytical platform that they sell to their customers. So there's a license associated with that and all of.
What they've done has is in CloudProviderB and I posted in the chat an e-mail that they sent with kind of like the tools they use on CloudProviderB side. This was sent a couple of days ago.
And as you can see, it's very standard stuff. It's like Timestream, Influx DB. They're using an S3 storage, Jupiter for data processing.
And then they have their own app builder that's kind of like Power BI and some endpoints. And So what they do with all their customers is they take their data and they sell you this platform. And so they'll develop the model, they'll develop the.
Of the ML model in there and their customers can go in there and modify anything they want and everything. So that's kind of what their business looks like, but our objective is to kind of like.
Maybe use their. What we wanna do is use their ML services but not their platform if that makes sense and so.

Participant_D   50:09
So, so the the idea Participant_P is keeping leveraging their ML service, but keeping it within your security boundary, not sending the data over into their cloud, right? That's the desired state.

Participant_P   50:25
Yeah, yeah. I mean, on the first year since we're new to this, they'll take it to, they're taking it to their cloud in CSV formats. But yeah, eventually everything's gonna be on our on our end, the ML training, the data's gonna be landing in Fabric and everything.

Participant_G   50:41
Right.
Right. Our our instruction in the project from leadership is we don't have a parallel CloudProviderB operation going on.

Participant_D   50:55
And I'm sure within the negotiations, right, like because I I know customers that we deal with, we always have to go through like you know how are you handling our data, right. What happens if you know?
You know, like we're a cloud service also, right? Like there's all kinds of, you know, specific SLAS, you know, information on how data is being protected, et cetera. I'm sure you guys have gone through that with them.

Participant_E   51:26
I'm sure management signed papers on that.

Participant_T   51:30
I mean, is the vision that they're just going to come in and implement their notebooks in your ML environment that's connected back to Fabric? Is that is that the what your guys's intent is to do with this? Because like to me it sounds like they've got a thing, they're not really sure how you can replicate that in CloudProviderA.
Environment yet. So let's go through a process and then move it over to them and then they'll give you back the result while they're trying to figure that out. Is that? Do I understand that correctly?

Participant_E   51:59
Yeah, they they have.

Participant_G   52:01
So a little more, a little more. Oh, go ahead. Go ahead, Andre.

Participant_E   52:06
Oh, oh, God.
Sorry. So they they basically come with something that they've done with customers before. They know how it works, they know what it is, they've built it, they've used it. They can prove value to us using their platform, right?
So their conceptual understanding is, hey, if there is any value to be had in this ML projects, the fastest route to prove the value is use a tool that is familiar to us. We're going to use it. We're going to prove the concept. We're going to make sure that there is actually.
Some squeeze in that project and then Participant_P, myself,  Participant_S will take all of that learning and basically move it into Fabric. So we really respect them and appreciate their brains. They're very good at ML and OT from our initial conversations with them.

Participant_P   52:47
Yeah.
Take all that learning and basic.

Participant_E   53:05
And we definitely wanna learn from that, but the end implementation is gonna be Fabric and resources.

Participant_C   53:14
OK. So they are doing doing the development on on their platform. Once the development is done, once you guys are satisfied, it will be pushed down and then then from there on you will be responsible for managing, maintaining going forward. There will be no connection beyond that to AW, CloudProviderB or any other cloud.
And you are going to run this model locally whether it's local versus whatever hardware you provision because in the second or future future plan I see you are depicting Arc there.
Are are you guys planning to use Local? Are you going to have your own Kubernetes cluster and then maybe you are laughing so I I think I know the answer, but go ahead.

Participant_E   53:58
I I am pretty embarrassed for the graph. I was reading it and there is a lot of misspelled stuff. I created that for me like 8 months ago and I'm embarrassed to admit we're still using it. So it's very conceptual from that standpoint.

Participant_P   54:06
Yes.

Participant_C   54:08
OK, don't worry about it.

Participant_P   54:10
So.

Participant_E   54:14
We do know that one of the requirements from our side is that we do not depend on the Internet to run the plant. So that's why that implementation of Kubernetes on Prem which provides high availability and the ability to run.

Participant_C   54:22
Yeah.
Mhm.

Participant_E   54:34
Containerized load of machine learning, right? That's that's why that piece is there.

Participant_P   54:34
inorized both to learn, right? That's why that is there.

Participant_C   54:36
Yep.
No, I I I agree with you, Andre, right? With all due respect, right, because of Participant_G, one of the concerns of scalability, right. I know you are thinking of Kubernetes. Definitely love the idea. My only recommendation is, you know.

Participant_E   54:43
Uh huh.

Participant_C   54:56
Explore a bit on Local. So now you do not need to be connected to the Internet for Local to run. I think you are already aware of that. You can run it with or without Internet. It's on Prem, but you get the cloud capabilities. You can have your cluster.
Those things and let's say in the future if you want to decide to leverage some of the features of, you know, cloud, there you go, you have something ready already. So think, think in that direction.

Participant_E   55:23
Yeah.
Uh.
Yeah, no, I really like what you're saying. And we did ask our infrastructure team to look into that. The pieces that we didn't like when looking at that specific set is the disconnected operations was rolled out, I don't know, like 7 to 8 months ago or something on Local.
So that's where we from the implementation standpoint, we understand that it runs independently, but then you also need the Internet connection for logging governance pieces and to truly make it disconnected. It seemed like it wasn't there just yet at the.

Participant_C   56:05
Mhm.

Participant_E   56:06
Point when we looked at it and I remember we looked at it as disconnected operations came out like last month before we looked at it. So that's that's kind of our evaluation that we did into the local and that's where.
We do have some licenses for VMware Kubernetes that we're potentially exploring. We're also exploring right now options of running bare metal on like VMS and.

Participant_C   56:34
Mm-hmm, mm-hmm.

Participant_E   56:37
There's different things right now in the in the works from the project standpoint, but it is it is a good suggestion and um I don't know if you guys had a lot of success with those products. We obviously would love to hear them. I just am aware that disconnected operations is extremely.

Participant_P   56:48
You guys have had a lot of success.

Participant_C   56:53
So.

Participant_E   56:57
Recent development and with anything that just came out, you always kind of feel a little anxious.

Participant_C   57:04
Yeah, no, I can honestly speaking right on local, I can pretty much speak for continuously 8 hours how it's being used at different customers in manufacturing, right. And and for you, you know the the business that you guys are in, right. Absolutely it will be a game changer, right? Because remember.
Technology is changing very, very, very, very fast, right? And you need to be ready to adapt to what's coming next. So if you plan that way, Local will be the answer. Yes, you can have VMware, you can have your own infrastructure running, but again, now you're limiting yourself a bit. So again.
You know, if you want, we can, we can go with a session, you know, one of these days, you know, if you need to know more about who's using what and how they are leveraging, definitely I can speak.

Participant_D   57:52
Yeah, yeah. I could also talk to some of the experience I have to help compliment Participant_C on how we used to use it in the federal government.

Participant_C   58:05
Awesome. I think that's all for today, I guess, right. So for the next steps, Participant_B, I think I'm gonna leave up to you how you want to, you know, go in the next phase, whenever that may be, yeah.

Participant_P   58:07
Yes.

Participant_B   58:16
Right. Yeah. Yeah. And I see we're at time here. You know, what I'm here interested in hearing from the team is kind of a readiness to say, OK, you know, we we've learned a little bit about the architecture where you're at, right. We've heard that, you know, there's a focus.
You know on on the the use case and and and you are bringing data in into the cloud with your sensors there, the sensor data is coming in where we're looking kind of at the, you know from CloudProviderA perspective, right, we're coming in to make sure there's readiness from a fabric perspective.
Readiness from a security perspective, making sure you can scale I think is is is you know one of the key opportunities here. So are we ready to kick off and and and work towards those goals while you have your partner working on you know a specific use case right you're you're.
You know the idea is is that you're bringing you're bringing data in now you know can we have bring make sure you're up to speed on fabric so that when that data is ready you're off and running and you can also bring in and and and entertain other use cases right as as they come along.
I mean, are we at that point where we can can kick this off and and and work towards those goals as described and you know?
The agreement that we have to to get started.

Participant_E   59:43
Sounds like a good Participant_R question.

Participant_B   59:46
Yeah.

Participant_R   59:49
So I I guess it would really depend on like what that means in regards to to like scheduling and and time. As you can see we we run pretty lean on our BI team at Acme-Sub and with the the ModelQ project still getting underway and still just getting rolling.

Participant_B   59:59
Mhm.

Participant_R   1:00:05
You know, there's going to be quite a bit of time dedicated to making sure they have what they need to get that model process built. So I guess it really depends on like what would that look like from a schedule perspective, from a time perspective, we'd have to negotiate or not negotiate, work with the ACME.
Networking team as well to kind of figure out what their their calendars look like and the schedules look like for them. So I mean, I think we're probably close, but it would really depend on what that looks like from from your side.

Participant_T   1:00:35
So Participant_R, I'm a just just a question to clarify on this. I'm a little confused. What I understand the ModelQ group doing is really nothing to do with anything they're doing this actually it's going to come in there. I'm more worried about like how do we help ensure that your data estate is set up for whatever model they come up with.

Participant_R   1:00:45
I I'm not.

Participant_T   1:00:54
so that you can start getting value.

Participant_R   1:00:56
No, I was not arguing that we need to wait for them to be done. It was more in regards to the time that Participant_P, Andre and  Participant_S are going to have available to meet to discuss those topics, Robert. It's not something like we're going to wait for them to be completed with that model. It was more we run pretty lean. We we need to make sure we have.

Participant_B   1:01:09
Right.

Participant_R   1:01:16
of the time available and the time that we can sit in the sessions with you guys, digest it, make those changes, and you know just make sure that it's valuable is really the goal.

Participant_B   1:01:28
Right, so uh.

Participant_E   1:01:28
Yeah, and that's sorry, that's very well said. There is kind of like a pre model stuff that we need to get done and then there is post model stuff obviously on the deployment as we want to move away from.
By using specific tooling to using tools. So that's another thing to consider in this conversation. I think that's where Participant_R's idea a little bit of having ModelQ actually produce something cuz that something is something.
Will need to land and until we know what it is, we can't really land it. We are in conversations with them trying to get like infrastructural pieces of what that will look like, what that will pertain. We know a lot of it is going to be pretty open to just being like on notebooks and.
Tons of Python and but there's probably some pieces that we'll we'll know later on as well. So just to give a perspective, Yep.

Participant_T   1:02:33
Right. And we want, that's what we want to make sure that that those notebooks have a place to be housed, right. So that you can use it like the note. There's gonna be a lot of notebooks and you can build your own. They can build some, someone else can build, you know, you can buy them and so on and so forth. We just want to make sure that you have that.
Enterprise environment that can scale so that when it happens you can start getting value out of it. We don't want to keep continuing to say, OK, now we've got a model, but overall the environment's not ready to adopt that model. Then we we got the cart before the horse.

Participant_R   1:03:03
Yeah, I think that's what Andre was mentioning. Like there's like 2, there's two sections of work. There's that pre model which would include that piece, Robert. And then there's the post model when we have that information from ModelQ that we would then be moving into.
Our side, so yeah, so I mean I guess my question to to the CloudProviderA team is we've we've kind of touched on a lot of different things, security, the actual like like Participant_C, you mentioned like local like maybe having a discussion around that like what does it look like from a scheduling? Is it why are we scheduling?
individual sessions over the course of those two sprint weeks, um are we able to do a pre-model, post-model breakout of certain topics and kind of schedule that out?

Participant_C   1:03:52
Participant_B, we can discuss internally before we answer that question, like how we want to position this. Is that OK?

Participant_B   1:04:00
Yeah, you know that that that's fair. Let let me get together Participant_R with the team to recap on that. You know because that's my question as well. You know are we, you know how do we want to frame this to to move right. We you know originally set out to say this is kind of a 10 week engagement where we're kind of moving fast here.

Participant_C   1:04:01
Yeah.

Participant_B   1:04:18
But let's let's take this back offline and see what that commitment is and let me lay that out for you. But I want to, you know, meet with Participant_C and and Participant_D and the team to to iron that out and and get back to you on that. So very good question.

Participant_R   1:04:34
Sounds good. Yeah. We just want to make sure that, yeah, it's really a silly comment, but we just want to make sure we're getting value out of it and we're setting ourselves up and not getting ourselves to the point where we can't give both you and ModelQ what you need to be to be successful. So just trying to make sure we're not to.
Overloading it.

Participant_B   1:04:51
That's got it.
OK. Anything. I know we're past time here. Any other quick comments or should we close the call?

Participant_G   1:05:02
It sounds like we need a follow up just to touch on on some of the points here and continue the discussion, would you say?

Participant_B   1:05:08
Yeah, I I think so too. That would be would be good. Thank you, Participant_G.
Alright, listen, everybody have a great.

Participant_T   1:05:17
Participant_G, do you have a time you want to? Do you have a time that you want to do that real quick? I I know we can adjust sometimes things, but but we don't need to convey the whole group. I mean, there's some things that the Acme-Sub team has to figure out on their schedule, but overall objectives, do you want to set up some time? I have time tomorrow or I have time.
Wednesday, I'm out Monday and Tuesday. I unfortunately got summoned for jury duty, so.

Participant_G   1:05:43
Yeah, I'm out tomorrow, but Wednesday probably better than to to accomplish that.

Participant_B   1:05:50
Unfortunately, that's when I'm at at my funeral. But if you guys want to meet, I I don't need to be the the guy that stops that. So let let let me confer with the team and we'll get something out on the calendar tomorrow so that we we'll regroup then next week, OK.

Participant_G   1:05:59
OK.
OK.

Participant_T   1:06:07
That sounds good. Thank you. Thank you guys for your time. I appreciate it. Nice meeting everyone. Thanks everyone. Thanks guys.

Participant_B   1:06:09
Thanks everyone.

Participant_C   1:06:10
Thanks. Thanks everyone. Nice meeting you all. Yep. Pleasure, guys. Thanks.

Participant_B   1:06:11
Take care. Take care.

Participant_G   1:06:12
Yep. Thanks guys. Bye.

Participant_A   1:06:15
Thanks.
