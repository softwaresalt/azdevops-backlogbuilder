Confirmed  Security Workshop-Meeting Recording
Generated by AI. Be sure to check for accuracy.
Meeting notes:
* Current and Future State Security Architecture Review: Participant_D led a review of the current security architecture for the Acme-Sub Foods environment, with input from Participant_M, Participant_K, Participant_F, and others, discussing existing controls, recommendations, and plans to overlay security on the future state architecture, while Participant_A provided updates on architectural diagrams and changes.
o Current State Security Controls: Participant_D described the current security posture, highlighting the use of Policy, PIM-managed groups, isolated credentials, and cross-tenant sync for identity governance. The team confirmed that conditional access policies are in place for Fabric access, and logging is managed via a dedicated Sentinel instance. Recommendations included enabling advanced threat protection on storage accounts, using resource group locks, and ensuring endpoint protection and encryption on VMs.
o Security Recommendations and Compliance: Participant_D recommended using Defender for Cloud for compliance monitoring, advanced threat protection for storage, and ensuring all resources are deployed in a compliant state via Policy. The importance of tagging for governance and resource management was discussed, with Participant_C and Participant_K sharing common tagging standards such as environment, owner, department, and project.
o Future State Architecture and Diagram Updates: Participant_A explained updates to the future state architecture, including changes to directionality in data flows and the replacement of MQTT broker with High MQ broker. Participant_D and Participant_A agreed to further update diagrams and overlay security recommendations, with plans to run a threat model on the future state and share updated materials for review.
o Key Vault and Secrets Management: Participant_C inquired about the use of Key Vault for encryption and secrets management. Participant_E clarified that while Key Vault is used in other applications, it is not currently implemented in this specific solution, but managed identities are used for app authentication. Participant_D emphasized the need for secret rotation and noted that secrets management is currently handled manually.
* Data Access, Shortcuts, and Private Endpoint Considerations in Fabric: Participant_E, Participant_F, Participant_A, and others discussed the technical challenges and options for accessing data between Fabric workspaces and storage accounts, focusing on the impact of private endpoints on shortcut functionality and alternative data movement strategies.
o Shortcut Functionality and Private Endpoints: Participant_E raised concerns about whether shortcuts between Fabric and storage accounts would work if private endpoints are enabled. Participant_D and Participant_A clarified that private endpoints are currently used for VMs, and that shortcutting data from storage accounts with private endpoints is not supported in Fabric at this time. Alternative approaches, such as copying data or using trusted workspace access, were discussed.
o Tooling and Data Movement Options: Participant_A and Participant_C explained that while some Fabric tools support VNet integration, others do not, and that data can be ingested using connectors, pipelines, or APIs. Participant_C highlighted the use of Power Platform connectors, Data Factory, and EntERPSys_A APIs as alternatives if shortcuts are not feasible.
o Future State and EntERPSys_A Integration: Participant_A confirmed that the future state architecture includes shortcuts to ACME's EntERPSys_A instance, and Participant_C described multiple ways to ingest EntERPSys_A data into Fabric, including low-code ETL and direct API exports. The team agreed that even with private endpoints, connections to EntERPSys_A should work via supported connectors.
* Event Grid, Event Hub, and Messaging Architecture: Participant_C, Participant_A, Participant_K, and others explored the roles of Event Grid, Event Hub, and MQTT brokers in the proposed architecture, comparing them to Kafka and discussing bidirectional communication, scalability, and use cases for real-time and event-driven data flows.
o Event Grid vs. Event Hub vs. MQTT: Participant_C and Participant_A explained that Event Grid is used for lightweight, push-based event notifications and routing, while Event Hub is designed for high-throughput, pull-based streaming and telemetry ingestion, similar to Kafka. MQTT brokers provide bidirectional messaging, which is important for certain on-premises scenarios.
o Bidirectional Communication and Use Cases: Participant_P asked about the ability to send messages from the cloud back to on-premises systems. Participant_A clarified that Event Grid can send outbound messages, but network boundaries must be considered. Participant_C noted that using managed services like Event Hub reduces management overhead compared to running VM-based brokers.
o Scalability and Future Expansion: Participant_E inquired about scaling the architecture to multiple factories and the role of Event Grid in routing. Participant_C explained that Event Grid is suitable for serverless workflows and routing, while Event Hub is preferred for high-throughput telemetry. The architecture can be adapted based on specific scaling and integration needs.
* Edge, IoT, and ML Model Deployment and Monitoring: Participant_E, Participant_A, Participant_C, and Participant_K discussed the deployment and monitoring of ML models on the plant floor using Kubernetes, IoT Edge, and Arc, addressing concerns about offline operation, control planes, and local monitoring during network outages.
o IoT Edge and Model Deployment: Participant_A clarified that IoT Edge facilitates the deployment of ML models to on-premises Kubernetes clusters, with the model running as a containerized application. The IoT Edge component primarily handles deployment and may also facilitate telemetry back to the cloud.
o Offline Operation and Local Monitoring: Participant_E raised concerns about monitoring and controlling ML models during Internet outages. Participant_C and Participant_A explained that IoT Edge writes logs locally and resumes uploading to Log Analytics when connectivity is restored. Local inspection of logs is possible, but real-time cloud-based monitoring is unavailable during outages.
o Manual Control and Maintenance Mode: Participant_P and Participant_E asked about the ability to manually stop or put ML models into maintenance mode while offline. Participant_A and Participant_C confirmed that this can be done by stopping the container or cluster locally, and that IoT Edge does not directly control the running state of the model once deployed.
* DevOps, Tagging, and Governance Practices: Participant_K, Participant_C, Participant_D, and others discussed best practices for DevOps pipelines, tagging for governance, and the use of Key Vault and managed identities, emphasizing the need for standardization, automation, and clear resource ownership.
o DevOps Pipelines and Automation: Participant_K and Participant_A highlighted the benefits of using Azure DevOps and GitHub for standardized deployment pipelines, process management, and source control. The team agreed that moving from manual to automated DevSecOps processes would improve consistency and security.
o Tagging Standards and Governance: Participant_K and Participant_C discussed common tagging practices, including environment, owner, department, and project, and the importance of tagging for cost management, security incident response, and resource tracking. Participant_D offered to provide example nomenclature and documentation.
* Data Processing, ETL, and Tooling in the Architecture: Participant_E, Participant_A, and Participant_C reviewed the ETL processes between event streams and data lakes, the use of notebooks and pipelines, and the role of development tools such as Azure DevOps and GitHub in the overall architecture.
o ETL and Data Transformation: Participant_A explained that data from event streams is typically landed in raw format with minimal transformation, such as parsing JSON to CSV, and that batch processing is preferred unless real-time aggregation is needed. Participant_C referenced the medallion architecture for raw data ingestion.
o Tooling and Development Practices: Participant_A described the use of Azure DevOps for process management, GitHub for source control, and the integration of deployment pipelines. The architecture supports various development tools, and MLOps is included as a process framework for managing ML lifecycle.
Follow-up tasks:
* Architecture Diagram Review: Review the updated architecture diagrams and provide security feedback to Participant_D. (Participant_M, Participant_K)
* Security Recommendations Documentation: Share the current state architecture diagram and security recommendations document with the team for review and feedback. (Participant_D)
* Future State Security Overlay: Overlay security recommendations and threat model on the future state architecture diagram for discussion in the next call. (Participant_D)
* Key Vault and Secrets Management: Provide a reference architecture for DevOps including Key Vault usage for secrets management and share with the team. (Participant_D)
* Tagging Standards Guidance: Provide examples and public documentation on suggested nomenclature and standards for resource tagging to the team. (Participant_D)
* Architecture Diagram Updates: Update the architecture diagrams to reflect the discussed changes, including directionality and component naming, and share the latest version with the team. (Participant_A)
* Legend Addition to Diagrams: Add a legend to the architecture diagrams depicting resource ID and API endpoint formats for easier troubleshooting and reference. (Participant_A, Participant_C)



1h 39m 36s

Participant_B started transcription

Participant_D   0:03
Are both you guys the security folks from ACME?

Participant_M   0:07
Oh, that would be Participant_K and I and Participant_F Bonkowski I think is on here as well. So he's our network security engineer.

Participant_D   0:09
Oh, OK.
Oh, OK.

   0:10
Yep.

Participant_K   0:10
Yep.

Participant_M   0:15
5.

Participant_D   0:15
OK, Participant_K and Participant_M, right? Let me just update my notes.

Participant_M   0:18
Mhm.

Participant_K   0:18
That's Yep.

Participant_D   0:24
So this Will probably be more applicable to you guys. Let me share my screen. So you know, last week what we did was we reviewed the existing architecture just so we could lay IT out. I think there was a lot of information that we we got, we were able to capture for me to kind of, you know, Do a security assessment, right.
And you know, just, you know, call out, you know, areas of concern, right, you know, factoring in, you know, you know, size of organization, you know, kind of the use case, et cetera. And then there's.
There's a diagram that um.
There's a diagram which Participant_A shared last week, you know, kind of talking about the future state. What we want to Do is on this new diagram, the the updated. I don't have security overlaid on this one, but I wanted to, you know, make sure like you guys had reviewed IT before I kind of.
I'll go through that which I'll have in the next call. But in you know within the current state architecture, right, I have this diagram. I'm going to send IT to you guys just for you to review. What IT does is, you know, IT kind of IT outlines the existing architecture.
It's it's a visual file. You know IT outlines the existing architecture of resources that that are that are there today that was captured during the conversation, right. How Services communicate between fabric to the various resources.

Participant_H   1:56
Mhm.

Participant_D   2:01
Groups. Um.
How how communication happens, how identity access you know is governed through ENTRA and then you know IT does have IT does have some of the notes that I I've captured for your administrators that they're you know they're coming into.
To the Acme-Sub and tenant through a cross tenant sync, right. So you know they have they said you have a B to B object. I'm assuming that you guys, you know overall the architect, the security architecture is pretty locked down, right? Like I mean IT looks very good because you guys are using.
As your policy to configure it, you have you know isolated credentials that have elevated rights that that can come in and manage the resources and you're using PM managed groups, right. So you have all the you know the appropriate you know at least the you know the the common guardrails.

Participant_H   2:42
OK.

Participant_D   2:58
On the on the lockdown on the, you know identities that access these resources, right. There are some things that you know I probably have, you know I outlined as recommendations around configuration which I'm assuming.

Participant_H   3:13
Mm.

Participant_D   3:15
Are going to be configured within the policy, right? Really it's it's, you know, it's going to be defined there for, you know, it'll be defined there for you guys to a either consider or just confirm that it's already being enforced on the resources itself.
Before I go into this, Do you guys, is that, is that cool, Participant_M and Participant_K?

Participant_M   3:40
Yep, Yep. Good with me.

Participant_B   3:42
Yep, Yep. Same here.

Participant_D   3:42
Alright, great.
OK. So you know basically what I've captured and what we'll Do is we'll go through the same exercise for the for the future state architecture, right. You know basically you know what we have laid out is you know the the the workloads are built in the Acme-Sub and foods.
LLC Cloud, Cloud and then the subscription that I'm looking at is is the Ioan OA data dev tenant which has two resources group, two resource groups, you know one resource group that is dedicated for networking.
Which has all the private endpoints configured and then the resource group IoT data, right? And these are the specific resources that are are there right within these specific resources, right? Again, I'm sure that you know I like the idea of you guys are are deploying these resources via Azure.
So you know recommended configurations right would be just a time access for the VM itself. You know, enable the encryption. If you guys, if they're Not set right, I could give you those configurations to Do that.
Endpoint protection should be installed, right? And then you could use Update Management for patch management of this VM, right? This is that Hive. I think it's the Hive MQMQVM that they're using, you know, here.
From the network security groups, right? Denial default. I'm sure you guys are locking that down. Disk security, right?
And then one one thing I did Not see in here, but I'm assuming you guys got IT because you you you had mentioned that you have a dedicated Sentinel instance that all logging and Monitoring is configured, right? So those are toggles that you know she she could just be enabled.
From the storage account itself, right? Yeah, definitely. We want to make sure this stuff is blocked in anonymous access and then you know it's configured. Additional lockout, additional things just to consider would be using lockout resource group, lock the resource group itself, right?
So just enabling like can cannot delete or read only just to prevent any accidental deletions. And then I didn't see any tagging, but those are just some things to consider within your policy to manage to to lock down the resource itself.
Right.
Um.
Now I don't recall, I I saw that you guys, you know, I think the free version should be sufficient enough of Defender for Cloud if you wanted to manage the compliance of these of these resources, right? I didn't see anything outstanding that was being used, but you know IT would be a recommendation.
If you're Not using that to manage the posture. So the idea of the ideally the policy would prevent any resources from being deployed in a non compliant state. But if for whatever reason one of the resources get, you know get modified right or you know let's say for example gets gets.
If something happens, at least you'll you'll have visibility within, you know, Defender for Cloud. I did recommend on. I did recommend on the storage account, right? At least in enabling advanced threat protection. So you know you can, you know you.
Have some protections to the content that to, you know, data that gets stored in this storage account, right? So IT does have like, you know, some type of scanning going on there.
So in terms of the resources, you know, just ensuring that they have a compliance, you know, they have the appropriate protections and they have a very specific posture policy, you know, using policy is a good thing, right?
Then just these additional checks in terms of access access to these resources. Definitely you guys are using good practices such as PIM managed groups, right? You know I won't go into what PIM managed groups are because I think you guys know what they.
It is, but you know, for the developers, non-security folks, definitely feel free to kind of ask questions if you if you guys Do have any.
Right.
Subscription level security, right? Again, you know this is probably more towards the you know if they have additional workloads within the platform, right? Like I said, I'm only looking at, I only had visibility into.
You know the, you know this specific subscription. I didn't get a chance to see how many subscriptions you actually have within the Acme-Sub inside, you know, but you know from a security perspective if there are any holes in, you know any subscriptions that are next to this.
Then those can lead to potential areas for compromise. If you know if a user you know if a bad actor got you know you know was able to get access to that they can laterally traverse into this right so.
You know, identity access, you know? Yeah, I I've covered that one. Let's see.
From a fabric perspective, right, you know my notes did state that you know you're using the same groups to manage authorization into, you know, the various workspaces. So those patterns are are, you know, I think that's a good.
You know, an excellent pattern to follow. One thing I did Not see, and I don't know if IT if IT would be a requirement for you guys, the type of data that's being stored here, you know, doesn't require, you know, stringent.
Or, you know, more advanced data security or governance processes. I know Purview was labeled out of scope and it was removed, but you know, again, it it is something to consider or you know.
You know, should this type of data have, you know, classification and you know within this or within this overall solution, is there any, you know, sensitive or confidential type data being handled?

Participant_M   10:37
Yeah, I think maybe it was Participant_G had answered that a couple weeks ago that there wasn't a concern for this particular use case.

Participant_D   10:49
Mhm.
Yep.

Participant_G   10:50
No, not in this one, right?

Participant_K   10:56
So I'm I'm curious here, is there an availability issue on the data?
Is it? Would it be would be bad if we lost this data or lost access to it?
OK, just checking.

Participant_D   11:13
Yeah.
That was probably back end communications, right?
Again, So what I'll do is I'll share this right. One thing you know, I'm not sure like within the ACME environment as you guys, as you guys manage your cloud environment, right, I think we did capture that there aren't any CIC pipelines.
On the Acme-Sub side, so you know, obviously those would be recommendations to, you know, to ensure that resources get deployed, notebooks that get get get get developed, any of the developer.
Type artifacts, right? Get stored in a secure, you know, code repository with appropriate scanning on that before it gets deployed, right? So like I said, I I noted that it's it's kind of manual today.
But you know if ACME has a process that that they leverage for like their CICD pipelines, I would recommend that you know, you know, you know Acme-Sub and adopt something like that versus doing it manual.
Right. Um, OK.
This is just an one of the now one question I had Participant_K and and Participant_M, do you guys do the conditional access policies for users that access fabric?

Participant_M   12:59
Yep.

Participant_D   13:00
OK. So you guys do that, right? OK, cool. OK, perfect. So yeah, that's the that's highly recommended, right, that there's a conditional access policy that's configured, you know, and you guys know how that works, right? It looks at specific criterias.

Participant_K   13:00
We do.

Participant_M   13:02
Mm-hmm.

Participant_D   13:17
That you would determine you know when the when those authorized users that's probably based out of a group, you know we can specify specific things like you may want to put you know block unsanctioned countries.
You know, include them in in in the IP location information to block that. So it's only coming from domestic, you know, US domestic known addresses if they're looking at devices and you can specify the application, right?
And then we would highly recommend turning identity protection on the Acme-Sub folks, right, so we can get user behavioral analytics if something was to happen to their credential, right, especially that it's kind of a sub to you guys as an external organization to you guys.
Right. And you guys look at the security, if something, you know, if their credentials do get popped or get sold on a dark web, we could take some, you'll have, you know, you get to create a policy that could take some type of action to protect the organization, right?
Now this kind of outlines that and then also I, you know, kind of captured. Again, I didn't see this, I didn't see the Log Analytics workspace, but I'm assuming that there is a Log Analytics workspace. So you're taking on the sign in logs activity.
The logs you're sending out and I recall you do have a dedicated central instance for for Acme-Sub in which you guys access through Lighthouse.

Participant_M   14:58
Yep, that's correct.

Participant_D   15:00
OK, cool. Perfect. Um.
So you know what I'll do is, you know that pretty much covers, you know, kind of this. Is this fairly accurate? You know this this depiction of of what I've captured?

Participant_M   15:21
Yeah, I think so from from our perspective, yeah.

Participant_D   15:27
I'll I'll make sure you guys get a copy of this just to review. You guys have any questions on the you know Participant_Ka and and and Participant_M or any of the Acme-Sub folks.

Participant_K   15:44
Well, um, go ahead.

Participant_G   15:45
Yeah.

Participant_E   15:48
Sorry I I just had a functional question rather than the and I was gonna ask if right now is a good time to ask those or maybe later functionality of work that dotted line between the.
The subscription in Fabric.

Participant_D   16:07
Oh, yes.
Yeah, this what this represents is, is the the fabric capacity, right. So basically what it is, is you know they they typically have a spark cluster out here which is.

Participant_E   16:16
Uhuh.

Participant_D   16:23
No, Participant_A, you could, you could talk data, right? What spark clusters do?

Participant_E   16:24
Huh.

Participant_D   16:31
Or Ali, right?

Participant_E   16:31
Yeah, I I I can specify my question as well and and see if it fits in this part of discussion or maybe just answer later. We were hoping that we can utilize some of the functionality of shortcutting.

Participant_D   16:35
OK.

Participant_E   16:47
Between the fabric.
Workspaces and that storage account and I know that in your description that storage account up above in is locked down from public access, but I know that shortcuts right now are not allowed.
For for it to be in a private endpoint connection type. So I was wondering if functionality how are these supposed to be talking to each other or you guys just proposing basically?
We copy the data over or what were you thinking? And if it's if it's not the correct question for this specific part of discussion, we can just answer it later.

Participant_D   17:37
So on these ones, I think the private network private endpoints are are the private endpoints are only being used for the for the VM itself, right? And then the then the storage account is is pinholed. Is that a correct configuration?

Participant_E   17:58
Yeah, I guess I'm asking more so. I just saw it on the in the left where there is text left top go up, up, up, up, up or up. Sorry. And there's a.

Participant_D   18:06
Yes.

Participant_E   18:13
Storage account security, enable private endpoints, restrict access to your Vnet. I was wondering about restricting access using endpoints and how that looks. Are we still able to utilize functionality?
Such as short cutting into fabric for the data? Or will that go away with that level of?

Participant_D   18:42
Oh, OK. I may, I may have. I need to touch that one because I do have a. If this is gonna be publicly accessed or not behind, not behind a private endpoint, then there is specific security settings that I have to set there. I may have overlooked that one.

Participant_E   18:43
I.

Participant_D   19:00
I may have overlooked that one because basically the way the short code would work is this this, you know, using this kind of description, right? It's it's a functionality in fabric that's called trusted workspace access.
Which basically would the access happens under the security context of the managed identity, which you know, it kind of walks through. I I I describe it here.
Now quick question, Participant_M and Participant_K, do you guys recall if this is if this storage, if the storage account is behind the the private endpoint?
I I didn't have a chance to look at that.

Participant_F   19:39
So.

Participant_M   19:42
Participant_F might have that answer.

Participant_F   19:44
I was going to check on that, but my PM role must have expired and went away, so I can't see those resources anymore. But Andre to to go back to your OK Andre, back to your point when we first started looking at this and then we moved things from the audio tenant to the Acme-Sub tenant.

Participant_J   19:55
Give me 5, I'll fix it.

Participant_F   20:04
And then didn't we get like the shortcuts working with that Vnet data gateway if you recall?

Participant_E   20:12
The the way I remember it is certain tooling within Fabric is Vnet enabled like you can utilize private endpoints but other tooling is not.

Participant_F   20:20
Mhm.

Participant_E   20:30
So basically Fabric has multiple ways like shortcutting data, copying data. Oh yeah, that's perfect. Data flowing data and all of them have different configurations and I'm just thinking that we possibly.

Participant_J   20:37
Yeah.

Participant_E   20:46
Want to just address that, hey, can we shortcut using the this kind of security lockdown or what what that will look like?

Participant_D   20:59
Yeah, So what we have is this kind of represents the two options, typically users access and then you would have, you know you'd have a customer Vnet also right, which uses private link to access.
And then you would leverage these specific toolings. These are the methods that you would use to manipulate your data or access your data is probably the better term.
Participant_A or Liam, could you guys talk to this like kind of like these like these toolings that they use?

Participant_A   21:39
So there's one element here that I know that they had an original concept around using IMQ broker in on a VM in and my proposal was.

Participant_C   21:40
Hello.

Participant_A   21:56
To steer towards using Event Hub to ingest that.
Signal data because that can land directly in fabric when we are using. If you're using, if you're trying to land that in a storage account, you can't and you want to set up private endpoints that won't work with fabric at this time.

Participant_D   22:25
And that's the future state, right? This architecture, OK.

Participant_A   22:28
Yes, right. So I, yeah, I want to, you know, delineate, I guess, between whether we're talking current state or future state, but yeah.

Participant_D   22:42
I think was that you Participant_F that was asking like how do you how do you guys do you I I assume you guys have this working now with shortcuts like being able to access the the storage repository or a search account?

Participant_E   22:56
Yeah, yeah, that was kind of the hope that we go the route of shortcutting the data from this storage account and then shortcutting the data from EntERPSys_A instead of copying it all into.

Participant_D   22:57
OK.
OK.
Oh.

Participant_E   23:11
Like one lake necessarily in the because the way I understand like one lake is the ultimately safest repository of data that is behind the security and it's behind fabric. So it's the most.
Like sold by CloudProviderA for storage of the data and for that data that is not in one lake. I was wondering if we'll still be able to use short cutting data instead of actually copying the data and what kind of tools in Fabric right now are capable of.
Or cutting the data from outside of one lake.

Participant_P   23:57
And this is another thing that you had brought up Andre earlier in our conversations, but like the ability to use shortcuts on data burst tables, is that gonna go away if we use private endpoints in fabric?
Um.
Because you know that defeats the whole purpose of having fabric. If we can't marry a whole all our whole ecosystem, we we would like to bring EntERPSys_A data as well as the.
On premise data.

Participant_D   24:36
Participant_A, on the on the on the future state architecture, does that reflect all that we haven't gone, we'll look at it in a bit, but I'm just curious.

Participant_A   24:48
The future state does indicate a a shortcut to ACME's EntERPSys_A instance.

Participant_D   24:59
Uh.

Participant_A   24:59
Start cutting in and out of fabric is sort of. It depends on what you're trying to connect to.
And there are some underlying, I think, reasons why some services are less available via a short or through private endpoints than others. The EntERPSys_A is going to be a completely separate Senate, so.
I know that Fabric can connect to like S3 buckets if you want to. I think that that doesn't really fall into the the category of you wouldn't be able to put a private endpoint on something like that anyway.
Right, but for ingestion purposes you should be able to connect to a EntERPSys_A instance. I mean cause it's essentially it's an API.

Participant_C   25:52
Hey Participant_A, the D65 data works right via Power Platform connector. That's another option.

Participant_A   26:02
Right.

Participant_C   26:02
That will be low code like ETL like you know ad hoc data shipping etcetera. That should work right? Or you know the other way is copy data from EntERPSys_A API or export the file to one lake or lake house too. So there are there are.
You know a lot of ways to ingest the the 65 data into fabric.

Participant_A   26:21
But.
Yeah, they're built in connectors even in Data Factory for for EntERPSys_A. So even if a shortcut doesn't work, it's not the end of the roads hardly.

Participant_D   26:23
At.

Participant_C   26:25
Mhm.
Yeah.

Participant_P   26:36
But you're saying, if I'm understanding correctly, that even if we put private endpoints that that connection to database should work the via shortcuts.

Participant_A   26:46
Yeah.

Participant_C   26:48
Mhm.

Participant_A   26:48
Yeah, yeah.

Participant_P   26:57
I'll have to do some research as to why that's the case. It's just kind of weird, but.

Participant_A   27:02
Well, So what you want if you're if you have a and I think Participant_D can talk to this perhaps a little bit better, but if you have a a virtual private network in which you know you house all of your resources, it becomes sort of a shell in which all of your resources exist and.

Participant_P   27:04
I think.

Participant_A   27:20
Uh, a logical shell, right? And that's where the private endpoints create that sort of shell for you that you that all your resources can talk within. Um.
Certain resources inside, but that that network actually exists inside of a an app physical network, right? In this case it's gonna be your tenant, right? But the ACME is in a separate tenant, so you couldn't do a private endpoint.
That that concept wouldn't even apply because the ACME tenant is going to leave a separate tenant.
Does that make sense?

Participant_P   28:03
I would be lying if I told you no, yes, but that that's on me, so I'll just do some research and stuff, but thanks for trying to explain it.

Participant_D   28:04
Yeah.

Participant_A   28:07
OK, OK.

Participant_D   28:12
I mean, you know, Participant_P, maybe there's an option too, right? Like, you know, you if you guys are playing with this, right, definitely we can, we can coordinate like kind of be a working session, right? To kind of help you guys out if you guys are are going through some of the configurations, right?

Participant_A   28:21
Yeah.

Participant_D   28:33
Get over the shoulder. Um, see what what's going on also.

Participant_P   28:36
Yeah, yeah. From my perspective, that would be amazing. So.

Participant_D   28:40
The only thing that I called out on the overall security right was the on premise.
Was the on premise I don't correct me if I'm wrong on my notes on the on premise the MQTT broker.
They're not using authentication, right? Um.
You know from the from their clients, right. So you know again it's on the private network, you know that's just something I call out also if you guys plan to, you know for me like everything needs to be authenticated, right. That's a recommendation, but I think you guys have mentioned that.
You know they're not configured for authentication today to the for the clients to the MQTT broker, right? I did look at what those authentication, what the, what the, what authentication mechanisms they do support, but you know.
And that's just making sure Participant_K and and Participant_M are aware of that also if they have recommendations to, you know, force authentication on that also.

Participant_K   29:57
I think at the very least it would be a really, really good idea to to do at least machine or actually mutual TLS. So that's basically machine to machine authentication. It's yeah, it is best to you to do the full authentication of the machines.
Of the accounts, the service accounts. I meant if you can do that, I know it's extra work, but it's every little bit of security helps.

Participant_D   30:28
Yeah.
What what I'll do is, you know, as I said it, I'll have a summary of of the the items and we could actually include that in the backlog for future tracking.
Participant_A, did you, um, did you wanna go through this architecture now?
I guess my initial question, this was shared to the Acme-Sub folks. Do you guys have any thoughts or feedback to this to the architecture that Participant_A shared?
Or changes or areas you want to talk a little deeper on. Otherwise, you know what I'll do from here. I'll overlay the security recommendations for this for the future call for the next call.

Participant_J   31:13
I believe we went over that last week in the call and there was some changes we discussed that Participant_A was gonna make.

Participant_D   31:23
OK.
Participant_A, do you recall those changes? Do you know if those were incorporated already?

Participant_P   31:25
Uh.

Participant_A   31:27
Yeah, a lot of those, sorry. Yeah. So a lot of the changes were like there was a directionality especially on the on premise side. Yeah. So instead of MQTT broker, it should be high MQ broker and the arrows going from the broker to.
To high by and should be bidirectional and from high by to skater should be bidirectional. I did make those changes. I think they're not reflected in this particular version of the diagram, but.
I do remember them firm, yeah.

Participant_J   32:02
Yeah, that's fine as long. Yeah, I was just making sure we had them since we had discussed it last meeting.

Participant_A   32:08
Yep, I got them.

Participant_J   32:11
Cool.

Participant_D   32:12
Um.

Participant_K   32:13
I guess at this time I have one comment and it it just it it's it's based on experiences from yesterday we had A and this is unrelated to this application. It's another application that.
Um, people are working on.
It's great to see these drawings because when we get requests for for access and we don't have any drawings or architecture, you know, drawings to go off of, we lack context. So these drawings are they're.

Participant_D   32:46
Mhm.

Participant_K   32:49
Almost imperative. It's they've really helped a lot, so I just wanted to put that out there.

Participant_D   32:56
Great, great. Thank you. I think there are these pictures. I'm a picture guy.

Participant_K   33:02
Yeah, makes all the difference.

Participant_A   33:02
I appreciate that. I'm, I'm, I'm, I'm glad to hear that they are actually helping. It's not just an abstract. It's not just an abstract thing, but it actually helps. Thank you.

Participant_K   33:14
Yeah.

Participant_D   33:16
OK, so in regards to this diagram, these have the modern the more modern components like Event Hub and IoT. I'll work with Participant_A to just get the the latest updates to any of the text.
With that said, you know what I'll do is I'll, you know, I'll break it down and leave a little more further and overlay the security components. This one I'll probably run in a threat model against it because this would be the the future state of where you're going, where where you want to go to. So I want to make sure.
That I get everything in front of you guys as possible. OK, cool. We do have a Power BI scenario also.
Um.
Participant_Ka and Participant_M, did you get a chance to look at these diagrams? Did you guys have any thoughts or feedbacks from a security perspective?

Participant_M   34:22
Uh, I haven't had a chance to review them now.

Participant_D   34:25
OK, I'll make sure this gets packaged up with my communications to you.

Participant_M   34:32
Perfect.

Participant_K   34:32
Much appreciated. I have had a chance to take a peek, but it's not not long enough to to actually rock them so I can, you know, figure out, figure out if there are any security issues.

Participant_D   34:47
OK.

Participant_K   34:47
Yeah, but it's good to have them.

Participant_D   34:54
They switch screens.
Um.
All right. With that said that this is, you know that this was kind of the core topics I wanted to review with you guys, kind of where we're going with what I've been working on. Like I said, I'll update this with the, you know, make this current. I'll share it with you guys. I'll probably schedule a follow up.
Next week you know give me give you guys some time to like look at the document look at provide feedback on the diagrams and then next call I should have I I should have everything prepared to you know with the threat model and.
You know, the security overlay on that and definitely Participant_P, Andre, if you guys have, you know, do you need some like if you guys are doing some configurations, yeah, feel free to ping us if you want us to, you know, kind of over shoulder if you want to, you know, have a working session or whatever, right.
We're here to help you guys. With that said, Participant_A or Participant_C, do you guys have anything else?

Participant_C   36:09
There were like couple of things that I was hoping to get an answer. You know I if when I logged in last time I did not remember seeing any key vault. So wondering you know what's being done for encryption for the data, anything that you guys are doing?

Participant_D   36:40
Yeah, yeah, yeah. I I didn't see anything. I didn't see a key vault in there. One of the one of the topics I would be bringing in, you know, you know, would be kind of a a reference architecture for for DevOps, which would include right the key vault to store all all secrets, right.

Participant_C   36:40
No answer, so yeah.

Participant_E   36:42
1.

Participant_C   36:45
Yep.

Participant_D   36:59
But I guess is that some to Alim's point? Is that something you guys are like, um, is there a key vault instance today that you guys are using?

Participant_E   37:10
Yeah, just not in this specific application. I would say there is not not necessarily a lot of secrets to store between these four pieces of.
But but yeah, we outside of the specific applications, we do use key vaults to store secrets and we use managed identities of all apps to talk to each other and auth with each other where possible. We're not.
We we do use, uh, secrets.

Participant_C   37:46
So so Fabric is using the manage identity.
OK, so then we can basically, you know, whatever the persisted data we have right in one lake or lake house, we should be able to, you know, just use a CMK or you know, CloudProviderA managed key.

Participant_E   37:52
Yes.

Participant_C   38:09
But I prefer CMK obviously because then you have full, you know, control over for the key lifecycle. So definitely I would recommend something like that.

Participant_E   38:21
Mm-hmm. And I know Participant_P can definitely talk a little bit more when when we do use secrets in pipelines or or notebooks. I I believe we do utilize the key vault as well.

Participant_C   38:30
Uh huh.
Yeah.
OK.

Participant_D   38:41
Yeah, I think I, you know, I'm looking at my notes, right. And secrets management was kind of tagged. You know, it was tagged with notes that, you know, this is kind of also being done manual, right? Yeah. So when we do have those secrets, right, remember there's a rotation, remember to rotate, configure the rotate.
The rotation of those secrets also, right? So that that does give, I don't that does give you that. That is, you know, one aspect too, right?

Participant_A   39:12
I suspect that when you try to talk to ACME's EntERPSys_A, you know EntERPSys_A instance, there's gonna be some secrets involved in in in that.

Participant_K   39:28
I will say that Pam is coming eventually. We are looking at vendors right now and.
We hope to have it around. Well, I'm not going to give a date, but soon, soon, probably within a year at at the latest, so.
The other thing I wanted to point out is with DevSecOps, I think to, I mean being that we're doing things manually right now and that that works fine, but eventually we're going to want to make changes or make improvements.
And that is where DevSecOps shines. That's where those pipelines really come in handy, because when you go through and build these things, you want to do things the same way every time.
Time, you know, for everything else but the change, you put your change in and it goes through the pipeline and you don't have anything that you that is left out or forgotten or.
You know problems with the same problems with permissions, that kind of thing. That's, you know, that's that's the that's what I think for for motivation. Also I had a question about tagging on the the tagging for governance there.

Participant_D   40:53
Yep.

Participant_K   41:04
Are there any suggested? Is there any suggested nomenclature for tagging? I think sometimes I've seen financial financial.
Um.
How do you call it financial names being used for like account numbers that that kind of thing to help with you know, billing for example. So that's.

Participant_D   41:32
Yeah, yeah. Like or like organization. Yeah. No, they'll factor that into the the, the, the, you know, the structure, the naming format. I can provide some examples that we have.

Participant_K   41:36
Yes, Yep.
Mhm.

Participant_D   41:48
I I think there's some public documentations, just suggestions on what we have. But you know, Participant_C, do do you know if there's any like do you have, have you, is it pretty consistent on what we've been doing with most customers like or is it all over the board?

Participant_C   42:02
Y.
It's no, it it, it's so there are some standards, right. And then you know some organizations go beyond that. It really depends, right. So what what I'm hearing is you're looking for something like chargeback, right? The chargeback that could go to you know the resource usage versus you know forecast.

Participant_K   42:11
Mhm.

Participant_C   42:24
Thing versus right so so the the tags that I have seen mostly right are for environment right and who owns it and what department and you know what project right. So these are the four that are very common and sometime people add things like you know date.

Participant_K   42:25
Right.
Mhm.
There you go.
Yeah.

Participant_C   42:43
You know, I don't know why because it it doesn't make sense to me. Maybe they have a rational behind, but these are the four common right dev test. You know, let's say if Alim owns it right and Alim belongs to, let's say finance, right as an example and what project was it. So those are the four common ones I have seen.

Participant_K   42:44
Mhm.
Right. Exactly. Yep.

Participant_D   42:56
Yeah.

Participant_K   42:57
Mhm.

Participant_D   43:00
Yeah, I think what was it for? I mean, 'cause I I know I I've used environment, cost center and then app.

Participant_K   43:00
Yes, and I.

Participant_C   43:07
So environment owner department project and at at times dead, Yep.

Participant_D   43:12
Yes, a little bit.

Participant_K   43:13
Yes.
And actually I think owner that comes in really handy when in the middle of a security incident we can look at tags and establish who owns what you know that's yeah that that can help. So I I think I think we've got a a lot of food for thought there so we can.

Participant_C   43:23
Mhm.

Participant_D   43:24
Yes.

Participant_C   43:27
Yep.

Participant_D   43:27
Yes.

Participant_K   43:35
I think we're we've got something to go on. Much appreciated.

Participant_D   43:35
Yeah.
Yeah, I I'll make sure that's summarized too.

Participant_C   43:39
Yeah, absolutely.

Participant_K   43:44
OK.

Participant_E   43:50
I I do have another question unrelated on the diagram. Sorry, since we're asking, could you share the future state one?

Participant_D   43:56
Oh yeah.

Participant_E   44:06
Uh, the other one.
The other one, Yep, that one. In this case where you see the arrows between events, streams and Browns Lake House, could someone talk to what?
ETL is happening in there between those what what tools are being used and what what formats or is it storage? Is it into tables? What kind of data processing is happening?
Um.
Just from the perspective of what that looks like.

Participant_A   44:51
Yeah, so in this case I think what you want to do is land the data virtually as is like you want to do as little transformation as possible in here and just land it.
What you might do, the simple thing you might do in this is because it will come in as a Jason message format with a body section. That is the one thing you'll probably do is kind of parse it out.
Into a tabular format and then maybe a CSV and then that's it. The only thing the only other you know, unless you really needed to do aggregations, then you can start doing like windowing functions in the event stream and doing certain types of aggregations.

Participant_E   45:30
Yeah.

Participant_A   45:42
I suspect that that is not a necessary thing because you don't need to do anything with real-time data. So you can do, you could effectively do all the same things more effect more efficiently with batch processing of that same data.

Participant_C   45:57
Look up, look up medallion structure, Andre, right. What Participant_A just mentioned, right. It's pretty much it's a raw ingestion layer, right? Nothing else, you know, minimum or like you know, transformation. It's basically stored as is for you know, I would say.

Participant_E   45:58
Mhm, right.
Yeah, yeah, yeah.
Yep.

Participant_C   46:17
To trace it or traceability, right? So it may have duplicate or missing values or inconsistent schema, so on and so forth.

Participant_E   46:25
Mm-hmm. Yeah. Is that utilizing Fabric's event streams or cause?
Um.
I guess is that a notebook processing that lends the data that connects to event streams? Or does event stream have ability to just point to a lake house or one lake and it automatically will put those JSON files in there?
I guess that that's my question. Or are you? Yep, Yep exactly.

Participant_C   46:58
So from the tools perspective, right, so from the tools perspective, you can definitely do a a fabric pipeline. You can definitely do even the stream. You can definitely actually use ADF or Synapse link, right? So you are you, you are, you are supposed to define that how how you're going to do it.
And we can help, you know, you know to to to, you know, define all those things.

Participant_E   47:27
Mm-hmm. So we do have capability of using notebooks in in that between event streams and Browns Lake House. OK, sounds good. Yeah, I was just wondering what the tooling was.

Participant_C   47:32
Mhm.
Mhm, mhm.
Yep. Anything else, Participant_A, you want to add in?

Participant_A   47:50
No, I think you got it.

Participant_C   47:52
OK.

Participant_E   47:55
And last question, on the development tools, yellow box, could you guys talk a bit about that piece? What are those? Is that just?
Deployment pipelines of some sort in there? Or what does that encapsulate in this project?
What is in that GitHub and Azure DevOps and MLOps from your vision?

Participant_D   48:21
So.

Participant_A   48:26
Yeah, so Azure DevOps has both process tooling, so for you know, like epics, features, user stories, tasks, boards.
Sprints, Agile process management, right? So it has all of that. It also has a built in Git repository capabilities. I understand that you guys have already like you're solemnly on GitHub Enterprise, so Azure DevOps can also hook directly into.
GitHub as a repo that's like built in capability. So that's like, OK, you wanna use GitHub? Fine, that's a simple configuration. Azure DevOps use GitHub Enterprise for your source control management.
You can use Azure DevOps for your process management and then we're not dictating in this yellow frame or tile. For example, whether you're using Visual Studio or VS Code or anything like that, that's like.
Whatever works best for you, but we do know that there are some flow that goes through that, right? So in Azure DevOps then you can do deployment pipelines and maybe I should have added that in there as well, but that's kind of part of what comes with Azure DevOps.
It's under the umbrella, I guess you should say about your DevOps. But yeah, you can do all your deployment pipelines out of Azure DevOps and that's how we would probably. And yeah, I I heard what Participant_K was talking about also I think with.
With standardizing your deployment, so using Azure DevOps as your deployment pipelines across all of these environments.
That would be the way to go and then L OPS. That's that's also a process oriented framework.
Work.

Participant_E   50:36
Mm-hmm. Awesome. And I know this was probably answered in a previous one, but I'm I'm a little blanking on that one. The event grids before event streams, what role does that play?
Uh in in this uh process.

Participant_A   50:57
So Event Event Grid is essentially it's the receiver of the signal, right? And then you can subscribe to that. So I've done this before with BLOB Storage, so for example BLOB Storage.

Participant_E   50:57
Uh, where? Yep.

Participant_A   51:17
Triggered event. It goes to Event Grid and then you can say, well, I want that message from Event Grid to land in this Storage queue for example, or in this case I want to process it.
Down into a bronze layer of a data lake because this is streaming data as opposed to a message that says do something.

Participant_E   51:45
OK.
So it's basically in this case kind of like a type of message and then the routing system would you say or?

Participant_A   51:56
Yeah, yeah, I mean it. But what it is, is it's a.

Participant_E   51:57
Gotcha.

Participant_A   52:03
It is a scale platform as a service kind of offering, right? So that means that you don't have to host anything yourself, you just you set it up using your.
DevOps deployment pipeline. You say I need an event grid, I want these things and they become part of your deployment pipeline rather than oh I need a virtual machine and I need to manage that to do this and that. It just works and has guaranteed uptime and throughput and all these kinds of things.
Things out-of-the-box and a lot of those and for a lot. In a lot of cases, usage of Event Grid is free because it's hard to exceed the.
The the original, the initial threshold, like you have to do more than like a million messengers or something like that before they even start getting billed. But in your case, I think you probably would.

Participant_C   53:11
I think we lost you, Participant_A. Or maybe it's me.

Participant_E   53:16
I think we'll we'll lost him.

Participant_D   53:16
Well, I heard it was I I think he finished.

Participant_C   53:19
Uh.

Participant_A   53:24
Sorry, did did you? Did nobody hear what I said?

Participant_C   53:28
We lost last 3040 seconds.

Participant_A   53:31
Oh.
Uh, OK.
Let's see here. Uh

Participant_C   53:36
But I I I think, I think that you know the customer got the gist of it, right. So in a nutshell, yeah, use event grid like you know if you are triggering of like you know some sort of a function or a workflow or any kind of other services and for the event hub, right, you know let's say if you have some real time data streaming or telemetry kind of ingestions then use.

Participant_E   53:41
Mhm.

Participant_A   53:41
OK.

Participant_C   53:56
Event Hub for that in a nutshell, right? So you know the the main difference, right? What the message type is lightweight, right? Event notification. That's what I would use the grid for and for high throughput event streams or logs or Jason, et cetera. I would definitely target Event Hubs for that.

Participant_E   54:13
And in this application, will that play a role potentially if we were to scale up from one factory to three factories? Do you guys see using Event Grid for kind of that routing?
Decider if you will in that application or or like for example if our on Prem MQTT can write directly to event streams, what Event Grid, what role Event Grid plays?
In in that situation I guess is my my question. I know there is probably some functionality I'm not thinking about right now.

Participant_C   54:51
So.
It it really depends, right? One of the things, let's say if you are creating a workflow which is serverless, right? We don't know what ModelQ is doing, right? If they are working on a serverless workflow, right? Maybe using some sort of a function or some sort of a, you know, a logic app. That's what we call in Azure, right? Then I would.
You know, use, you know even grid for that, right? OK, and then let's say you know there are there are several different examples I can give, but I'm just trying to keep it to this, you know, use case here. OK and then for the for the for the event hub, right?

Participant_E   55:30
Mhm.

Participant_C   55:33
Let's say if you have collecting telemetry through your IoT or maybe it's coming from your app logs, right? And then if you want high throughput right with low latency, that's when I would recommend Evan Hubs. That's what I was saying.

Participant_E   55:48
Mhm.

Participant_C   55:49
OK. So in this particular example, right, we don't know yet, right? Unless Participant_A, you know, you know that we are proposing both of the event grid as well as event, you know, streams.

Participant_A   56:04
So I apologize, I could be wrong, but I my my assumption was event grid is basically.
So we saw a tool in the Event Hub toolbox. That was my assumption. Maybe I'm wrong, but Event Hub and one of the other diagrams is also capable of doing other things like.

Participant_C   56:18
Mhm.

Participant_A   56:27
Helping to manage the deployment of Edge models. For example, if you're doing, if you want to deploy your model down into your local cluster and you're going to be sending signals directly on the factory floor to the MO model to perform operations there offline.
Event Hub is part of that or IoT hub you know is part of that.
Uh.

Participant_C   56:55
Yeah, there are two. There are two separate things, right? They these are they are not one and the same, right? Event grid and event hubs are different. They serve distinct actually purposes in an event driven architecture, right? So like you know, even routing, I actually pasted in in the chat window here.

Participant_A   56:55
Event.
OK.

Participant_C   57:15
Right. And then the hub is for ingestion for the most part, OK.

Participant_A   57:22
OK.

Participant_E   57:22
Mm-hmm. Makes sense. Thank you.

Participant_K   57:23
Now how does how does event grids compare with event grid grids and event hubs compare with Kafka? Cause I I believe in with Kafka you have.
For for incoming data, you have a connector. So you would have a connector for MQTT, you would have a connector for a database, you know, input from a database, that kind of thing. And that would publish to topics and then you could subscribe to the topics. I believe that's.
As I recall, that's how Kafka is architected, so right? So how does Event Grid and Event Hub compare to that?

Participant_C   57:58
Yeah, you got it right. Yeah.

Participant_K   58:08
I don't know.

Participant_C   58:08
Yeah, so you know the the Kafka you know is is pretty much the same as Eventhub, right? It's used for high throughput. It's a fault tolerant, right? And if you have distributed even the streaming platform that you are trying to ingest and store process.

Participant_K   58:15
Right.
Mhm.
Yep.

Participant_C   58:26
And also distribute in real time. That's when you know Kafka actually shines. They are pretty much the same event hubs and Kafka, right? You know, it's very hard to pick and choose you know who to go with, but they play pretty much the same role.

Participant_K   58:28
Mhm.
Mhm, yeah.
Mhm.
OK, sounds good. And event grid is has a few more features or it does conversion or or how does how does it differ?

Participant_C   58:43
Yeah.
So let's say if you have to route right in in a fashion for publishing and subscriber, that's when you know I would I would use even grid right in a in a publisher and subscriber model of sort, right? The the the pattern for that is push based, right?

Participant_K   58:57
Uh huh.
OK.
Right.

Participant_C   59:10
Uh, but for the event hubs, it's actually a pull based OK.

Participant_K   59:14
Uh, got it. Great.

Participant_C   59:16
So that's one of the other thing that you should consider or should know.

Participant_K   59:20
That's terrific.
Thanks, Ellen.

Participant_P   59:23
Well, we're in this topic. One of the reasons why we decided to use a Cloud MQTT broker is because of the bidirectionality that exists between the on Prem broker and the cloud broker.

Participant_C   59:32
Yes.

Participant_P   59:39
In this case, Eventhubs, does it have that same capability to send messages back to the on Prem broker?

Participant_K   59:51
Good point.

Participant_C   59:52
Yeah, well The thing is you are, you are. So in a way, the way it is set up right. Again, don't get me wrong, I'm not against your architecture or the tool that you have decided to use. You are setting up an extra layer in there. That means security has to be double on that, you know, because.
Is using VMS right? It's not something unmanaged. You have to manage the entire ecosystem for that, right? So we are trying to avoid anything that you need to manage like security patching, patching on the MQT itself.
And whatever it comes with it. And in case of even grid hub, you don't have to worry about those things. CloudProviderA takes care of that and we can pretty much mimic the same topology or the architecture diagrams or what your intentions are with our approach as well. It's just a recommendation.
And that's all. It just adds another layer of management, right? And we need to avoid as much as possible. That's the that's the rationale behind.

Participant_P   1:00:55
Yeah.
I I totally understand that. I just does. I just don't know enough about event streams. That's why I'm asking, does it talk back to the broker or is there another route that we have to go like maybe IoT hub or something else?

Participant_C   1:00:59
Yeah.

Participant_A   1:01:12
Participant_P, maybe you can describe that use case because I'm not aware of the why and I'm not challenging anything. I'm just like I just don't know it and I don't understand it yet. Could you could you describe that use case where?
The the message, the messaging system, let's say Event Grid or or Hive MQ broker in in would need to talk back.
to the on-prem.

Participant_P   1:01:48
Right. We currently don't have a use case or a concrete use case, but one of the things that we were trying to do is just kind of like bulletproof this architecture in a way that if we need to do live data coming into the data lake or.
Out of the data lake into on premise that it could be able to do it without an issue or a problem and so when we were thinking about this specific bidirectionality bidirectional communication.
Between cloud and on Prem, we're thinking of tools like our potential CMMS, right, where it would be interesting to have live data coming from, I don't know, a SaaS product that we buy.
That requires maybe live data or feed it, feed our on Prem EMS or something that the OT world needs on a live stream. That's just the.
Kind of like the thought around that. Like I said, we don't have a concrete use case for it, but we just wanted to make sure that we kind of like bulletproof this system and so.

Participant_A   1:03:08
OK.
So event streams is not itself a a messaging router. Event Grid is so.
It can message out. It does. It's not just oh, I only handle messages going inbound into. You can message outbound. You could have a webhook somewhere else and it sends that message outbound to some webhook wherever you want it, for example.

Participant_P   1:03:48
OK, so you would in a hypothetical case, I guess you would use the bend grid to send that data to the broker or did I?

Participant_A   1:03:57
You could send it outbound too. Now you know there's of course there's additional questions around that, like how would you talk to something that's on premise, the kind of network infrastructure you'd need to accomplish that and that would be true whether using Hive MQ or not, right, because.
You have and Participant_D can talk to this is you know you have network boundaries and such talking forward into like doing a push model into an on Prem network environment. It creates a you have to have a bit more set up to do that I think.
Um, it can be done, but it's.
Yeah, it doesn't really matter whether using, uh, which kind of technology. That's kind of just a network.
A pragmatic network reality, you know, for for talking forward into into the on-brim network. But event grid can that is part of that's kind of what it does is it sends messages, right? It receives and sends messages.

Participant_P   1:05:08
OK.

Participant_K   1:05:11
There I see in the drawing that you've got from all the way over in edge management, there's a there's a component called Arc and that is sending that's acting as a control plane.

Participant_A   1:05:27
Yeah.

Participant_K   1:05:27
And it's sending instructions to the edge device. What we could do if we wanted to, and I'm not saying this is a this is a strategy or anything like that, possible use cases to to extend the control plane.
Through the end of Event Grid and into the MQTT broker, I have engineered systems in the past like a home automation system where I actually have used an MQTT broker to turn on lights and and actuate, you know.

Participant_A   1:05:57
S.

Participant_K   1:06:02
Dials and things like that. So I I I've done that. I don't know if I don't know if we want to go that way. I I don't know if that's the the strategy or if we're but that's I'm just pointing that out that that is a possible use case. We could decide to do that someday.

Participant_A   1:06:15
So just.

Participant_K   1:06:22
So.

Participant_A   1:06:25
OK, so one correction I need to make in this item that shouldn't be an IoT edge device, because it's not going to be a device really. It's more like an executable that runs inside on your plant floor inside of your.

Participant_K   1:06:41
Mhm.

Participant_A   1:06:42
Your Kubernetes cluster right and Dev Factory has a similar type of low on premise installable and the way that it talks to the cloud is the on premise.

Participant_K   1:06:43
Right. That's right.

Participant_A   1:06:58
Executable initiates a channel with the term for this channel if you will to into the network and then it waits for Arc to pull.

Participant_K   1:07:07
Mhm.

Participant_A   1:07:15
And connect and then once that channel is connected then they they can talk to each other. It is not, you know, it's a command and controls kind of set up, but it's initiated by the edge.

Participant_K   1:07:28
Mhm.

Participant_A   1:07:31
The compute on the edge side calling into Azure.

Participant_K   1:07:34
OK.

Participant_A   1:07:35
I don't know, maybe that's too much, you know TMI, but I I worked through this with in rather granular detail for Data Factory and it makes sense to me that essentially this this kind of configuration.
this up, this is how it would be done on, you know, under the hood.

Participant_K   1:08:01
OK, well it's it's interesting and it's I think it's useful to know. Thanks for the description.

Participant_A   1:08:07
Yeah.

Participant_E   1:08:08
And building off of what Participant_K was asking, uh, does the the IT edge piece? Is there a control plane that doesn't rely on the Internet connection like Arc in this case? Is there like a secondary control plane that can be used?
I I don't know much about the IT edge. Like a good example, we we were down for like 11 hours on the Internet was down at one of the plants for like 11 hours last week or the week before. I don't remember exactly.
So we just wanna make sure that there's a possibility of either having something that doesn't rely on the Internet or possibly have a secondary control plane for things like that.
Could you guys speak just a little bit to that?

Participant_A   1:08:59
I'm sorry, what was the?
What was the thing you were looking to control?

Participant_E   1:09:07
So in this case Arc has that line that says control plane to the IoT Edge and IoT Edge is on the plant floor and Arc is in the cloud.

Participant_A   1:09:13
Mhm.
Right.
Mhm.

Participant_E   1:09:24
And we we do have instances once in a while when Internet gets cut off for prolonged periods of time, like latest was couple weeks ago or down for like 9 hours or something. So in those nine hours that control plane.
What happens there? Is there still like monitoring, secondary monitoring that's available or secondary control plane that's available? And this is for me coming. I just don't know what the IoT edge will be playing the role of, but I just wanted to see what you're.
Thoughts about this question.

Participant_A   1:10:02
Yeah, So what the IoT edge is primarily responsible for is how should I put this and say you have in there over on the right in your control plane, you've got a container registry.
Right. And that's where you have your container where you built your ML model and now you want to you want to deploy it back down to on premise to IoT Hub is your mechanism for doing that and.
IoT Hub and IoT Edge talk to each other to accomplish that to deploy it. Now you can't deploy anything down to the edge if you don't have a network connection to the edge, but once your model is down there.
It's there, right? So I I would say in this case, you know, details matter. You're asking an abstract question, but.

Participant_E   1:10:53
Mhm.

Participant_A   1:11:02
It depends on what it is that you're trying to control and if you actually have something that you need to control when you're offline.

Participant_E   1:11:07
Uh.
Yeah. And I guess it kind of comes from a little bit of a worry. It's our first deployment of ML on the edge and us monitoring it on the edge that it's, it's working, it's performing, it's doing what it needs to do.
And and as well as being able to control it. So if that control plane line is only our ability to deploy a new model, then I'm not as worried.
But if that control plane is like includes some kind of logging or monitoring or something that is supposed to go from the plant floor to the clouds that logs, for example the the current state or something like that, does that make sense?

Participant_A   1:11:59
Hmm.
Yeah, so I think like there is a dotted line going back from edge to log analytics, right? So, So what I imagine happens there is it's not a stream it writes. I I need your research to know for sure, but I would be surprised.

Participant_E   1:12:09
Yeah, yeah, yeah, yeah, yeah.

Participant_A   1:12:22
If it didn't write to disk first before trying to push it somewhere to analog analytics, right? Um.

Participant_C   1:12:30
Yeah.
Participant_A, it definitely writes to disk, right? It definitely writes to the disk and there is polling, you know, let's say if you lose the connectivity, right, you know the moment it restores, then it writes back to log analytics. So it definitely writes locally 1st and then depending on like you know if it is a 15 second or.

Participant_A   1:12:33
Because that would be a deep flaw.

Participant_C   1:12:52
You know, a 32nd or a minute or whatever. You know, every device sends data differently based on the SLA. So yeah, it definitely writes locally.

Participant_E   1:13:03
And in the in the example of us being down for 11 hours two weeks ago, what what happens?

Participant_A   1:13:04
OK.

Participant_C   1:13:11
It the moment it gains the connection, it will just take whatever is in the queue and it just goes and it starts ingesting into the workspace.

Participant_E   1:13:20
Are we flying blind or are we able to open that telemetry that's stored locally somehow to kind of monitor it on the Prem, if you will, on the plan floor while there is no Internet connection?

Participant_C   1:13:35
OK, so that particular IoT edge device, right? So let's say if you have set up some alerts or let's say you are trying to look your ingestion rate or or whatever that may be the case, right? Since we are writing our alerts or our monitoring depends on the workspace that is log analytics workspace if there is.
There is no new data. It cannot alert you if your alerts are based on that. It cannot show you any real time, close to real time dashboards or workbooks or whatever you want to call it. You cannot see that because there is no new data coming in.

Participant_A   1:14:13
So the the the concern I'm I'm I'm hearing if I understand is the ability to monitor the health of the model as is running. Is that kind of in the ballpark?

Participant_E   1:14:14
Understood.
Yeah, yeah, exactly. And maybe, yeah, yeah, that's that's one of the one of them. I I don't know what they will be, but I I just assume that we want to make sure that we have visibility into.

Participant_A   1:14:41
1.

Participant_E   1:14:46
And ability to monitor that in cases when things go down and whether that be model itself or the device or whatever that is, I guess it's a very broad question that I'm throwing at you.

Participant_A   1:14:56
Right.
Yeah. So I I think you could break this down into health and monitoring are there are multiple inspection points if you will, right. So you're hosting the model actually as a container.
Or multiple containers on a Kubernetes cluster that you're hosting on Prem. So that's an inspection point right there. Like what's the health of the of the containers running in your cluster? That's an indicator right there. IoT edge logging locally if it loses.
Connection. Tactically you should be able to inspect those log files. Now I don't know what tools might be available to do that off the top of my head, but I've worked places where.
We wrote our own log monitoring tooling and and we're able to observe like what's actually happening inside of this this application.

Participant_E   1:16:06
Mm-hmm. Makes sense.

Participant_A   1:16:07
As long as you have the logs themselves, you know there are something you can do with them.

Participant_E   1:16:15
Mm-hmm. Makes sense. Thank you.

Participant_K   1:16:17
Yeah, and.

Participant_P   1:16:18
A quick follow up to that. So if let's say the power goes down or the Internet goes down and we need to turn off that, I don't know that turn off is the right word, but let's just for lack of better word, turn off that model, right? Can you do that while it's offline or?
What are the limitations there?

Participant_A   1:16:42
I am not sure how to answer that particular question.

Participant_C   1:16:45
No, no, no, no, no. It's pretty straightforward answer, right? So let's say you are monitoring a specific device or a specific service, OK. And let's assume here that you are ingesting data. What we have something called heartbeat. It's a table in Loganalytics. If you go to Loganalytics right now, you can.
Just type heartbeat and hit you know run. It will pull whatever devices are sending the heartbeat data. So what we can do, we can come up with the logic. The logic can say hey if I do not see a heartbeat from this.
Device XYZ whatever, send me an alert. Then you know the alert will come to you in an e-mail or as a service request if you are integrating with tools like ServiceNow or you know IBM.
But whatever that it's called the ITSM tool. So yes, there is a way to notify you when something is down.
Provided that data is being so provided that particular device is configured to send data. So if it doesn't see data coming in for the let's just say for last five minutes and the frequency is supposed to be one minute, then we can alert saying hey I haven't seen data coming in from this device, let me alert the people.

Participant_P   1:18:01
Got you. Yeah, yeah, yeah, that makes sense. Maybe going into like the ML model container that will, you know, host that API. Let's say we need to turn it off in IoT edge.

Participant_C   1:18:01
I hope, yeah.

Participant_P   1:18:19
Can can that be done while there's no Internet or do we just disconnect the connection?
Or stopped using high bytes to to get in outputs from the MML model.
Does that make sense?

Participant_C   1:18:40
No, I'm trying to follow your question, Participant_P.

Participant_P   1:18:43
So if you go to the on on premise diagram.

Participant_C   1:18:47
K Can someone bring it back please?

Participant_P   1:18:53
And this if this question is out of scope for this meeting, please let me know. I am happy to rephrase it. So you know how the ML model will be in Kubernetes cluster, right?

Participant_C   1:18:58
It's OK. We can answer it.
OK.

Participant_P   1:19:09
And it'll be deployed on IoT Edge. Is that correct? Let's say we don't need the outputs of the ML model while the Internet is out. Can we manually go in there and just?

Participant_C   1:19:12
Uh huh.

Participant_P   1:19:27
Turn it off or?
Is that not possible? Like I'm just trying to gauge an understanding of what the control plane is like.

Participant_C   1:19:31
Oh.
Yes.
So you're trying to override something, right? You know, so there there could be some automation that may come in place here, right? And when you stop that automation of sort, I'm just thinking out loud here, you want a manual override of sort.

Participant_P   1:19:39
Would you turn it off?
Mhm.
Yeah, maybe we don't need the ML model while it's offline. We want to turn it off. Can you do that from on Prem or do you have to be online?

Participant_C   1:19:57
Mhm.

Participant_A   1:20:04
Wouldn't you just turn it off? Wouldn't you just turn off the the the broker then?

Participant_C   1:20:10
Mhm.

Participant_A   1:20:11
Stop sending messages.

Participant_P   1:20:12
Yeah, yeah, yeah. That's what I was referring to earlier. Like high bite is gonna be kinda like the one in between the container and the and the broker, right? But I since I haven't used IoT Edge in the past, I'm curious if you can do something like that.

Participant_A   1:20:22
Mhm.
Yes.

Participant_P   1:20:32
It's offline or or not, you know, just trying to learn.

Participant_A   1:20:36
I don't think that let me let me.

Participant_C   1:20:36
So disabling the service, right? That's what he's asking. Can I disable service momentarily or for some time? That's what I think Participant_P is after.

Participant_P   1:20:43
Uh-huh. Yeah.

Participant_A   1:20:44
Yeah, I so let me rephrase reframe or reframe this. So try to imagine that the model is it's it's, let's say it's running as a web app inside of a container.

Participant_P   1:21:15
Right.

Participant_A   1:21:15
And.
That model effectively the app takes. Imagine. So you have a web app, you post something to the web app and then it it pushes something into the model. We'll call it. It's a.
It's an algorithm, right? It's a function you you call it.
It takes what you bring in and it spits something out.
And in the meantime, it's just sitting there.
Right. If you don't call, if you don't make a call, nothing comes back. It's just running now.
I describe it this way so that you understand that if the you're trying to turn it off from Edge and it's more like, well, you would just shut down the cluster if that's what you wanted to do. It's just an app.

Participant_C   1:22:09
Yeah, maintenance mode comes to my mind, right? That's what I think he's he's thinking of for whatever reason.

Participant_A   1:22:16
Yeah, if you don't mind just having the app just available then and the the broker is not sending messages like.

Participant_P   1:22:17
Oh.

Participant_C   1:22:22
Yeah.

Participant_A   1:22:29
Ma, So what?

Participant_P   1:22:32
Yeah, I and I totally understand how ML models work and all that stuff, but I was just trying to learn a little bit more on the IoT edge and how that works when it's offline, but that's fine, yeah.

Participant_E   1:22:33
So.

Participant_A   1:22:43
OK, OK.
Yeah, I think that the main function of the IoT Edge in this case is is just to facilitate deployment, you know of the model in some cases and facilitate model health telemetry.

Participant_K   1:23:16
You know, I was at another meeting and um.
The display, they have a display that shows the current data, the the number of product that they're they're producing and that is driven from.
Um.
From IoT Hub it's it's driven from the cloud. Um.
Is anybody hearing me? OK, it's so quiet. Yes. So, so I'm just curious if that this I I would assume that that display would go down and I don't know how vital that that display on the plant floor.

Participant_A   1:23:45
Yeah.

Participant_K   1:24:02
Is to the continuation of operations. I don't know, I'm not that familiar with this system, I'm just, I'm just learning it. So any comments?

Participant_A   1:24:11
So maybe you can elaborate a little bit more on that, like you're already talking about current state.

Participant_K   1:24:19
Yeah, current state, you know the the data gets ingested, it gets sent into Event Hub and all the other other components that are processing the data and then there is.
But you know it basically it's the telemetry, right? The telemetry is processed and it sends back to this monitor on the plant floor.
You know, data including, you know what they're producing. There's this process is drying flakes and they're really, they're really the moisture of the flakes, the potato flakes is a really important factor, so.
I would assume that they're they're displaying that as well on the on this monitor. Um.

Participant_A   1:25:16
That sounds like current, current part you you're talking event hub, but that's this future state as opposed to current stage, which means you you have some things operating like on the plant floor today, right? And I I know that future state for you is Ignition, but you have another software.

Participant_K   1:25:17
And.
Currents, right?
Oh, OK. So I thought it was on there. All right.
Mhm.
OK.

Participant_A   1:25:36
On the plant floor that's also running the other plant lines, so I'm not sure which one you're you're talking about, whether there's the ignition or the I can't remember the other name off the top of my head.

Participant_K   1:25:37
Right.
Mhm.
No, there's well it's it's all rock Rockwell and yeah there are other people that can speak to that a lot better than I can. So I I was just curious if that if that screen going down is going to interfere with production or not you know at all. So that's and that's that's.

Participant_A   1:25:52
Rockwell, OK.

Participant_C   1:25:59
Do you think I? Yeah.

Participant_K   1:26:08
That's kind of what I was driving at with with when I was bringing up the subject of availability, and in some cases it could be important.
Just a thought.

Participant_E   1:26:20
Yeah, what I.

Participant_C   1:26:21
I think, I I think Participant_A the the the question is related with the visualization, right. When Participant_K is talking about a monitor is is more specific to the Power BI report or of sort right that will be on the floor on a on a screen, right. A TV, yeah.

Participant_K   1:26:27
Uh huh. Right.
Mhm.

Participant_A   1:26:35
Oh.

Participant_K   1:26:35
Yeah.
Yep, Yep, yes, exactly.

Participant_A   1:26:38
Well, so the RBI reporting, you know, is probably, how should I put this? That would be a bit delayed for you. I you're on the plant floor screen is where you're actually operating the machine. That's probably your first best.

Participant_K   1:26:51
Mhm.

Participant_A   1:26:58
You know, signal of the health of the machine, right? And then a lot of the premise I think of pushing this data out into into is to is to ingest the data so that you can actually.

Participant_K   1:27:01
Mhm.

Participant_A   1:27:15
Um.
First, the use case is to create a machine learning model and maybe gradually improve upon it and push it down to the edge and help that improve the operations of the machine itself. So if you didn't need to do machine learning.

Participant_K   1:27:25
Mhm.
Right.

Participant_A   1:27:33
That might obviate some of the need to do any of that potentially, but.
That is. And then there's a second use case of, oh, and we also want to combine all of that data with financial information that's in ACME and you have your, I can't remember the ISA.

Participant_K   1:27:51
Mhm.

Participant_A   1:27:56
Standard that you're trying, but it's like 6 levels and you're trying and it goes up to like financial financially marrying or merging you know financial information with with actual plant floor OT operational data and trying to.

Participant_K   1:28:11
Right.

Participant_A   1:28:14
Put those together, you can.
Get a full picture of the health of your business, I guess, and.

Participant_K   1:28:21
Yeah, you're measuring in energy inputs and and cost inputs and and and looking at profit that you're you're gaining and figuring out is are we, are we being as efficient as we possibly can?

Participant_A   1:28:26
Yeah.
Right. And so some of those areas where you know Power BI reporting going to be helpful because you can take a lot of that financial reporting and maybe operational data that you can go back and perform analysis on. That's a good.

Participant_K   1:28:38
Basically.
Mhm.

Participant_A   1:28:54
Place to to do that kind of data analysis and reporting on in in and Power BI but then but actual like minute or second by second operational stuff that's a bit.

Participant_K   1:28:59
Mhm.

Participant_A   1:29:11
Remote, I think from the plant floor for that kind of thing.

Participant_K   1:29:12
Yep.
And for all I know they have, you know they've got monitors that you know instruments that that are not connected in any of this stuff that can that you can use to directly measure you know the temperature of the the drum that's spinning around and the the.
You know, the the revolutions permitted and all that stuff. Yeah. And it's, yeah, it's probably not an issue for, you know, and actually there in that case there wouldn't be a, there wouldn't be a a loss of productivity if there was.

Participant_A   1:29:38
Right.

Participant_K   1:29:51
A loss of connectivity on on the Internet or at the the Acme-Sub plant to the the Internet.

Participant_A   1:30:00
Yeah, probably not. I mean that's the that's the that's the design I think is is everybody keeps talking about is we need to be able to operational even if we lose Internet connectivity. Of course, you know it's a totally different matter if somebody cuts the electrical cable, but.

Participant_K   1:30:05
Hmm.
Mhm.
Well, yeah, that that obviates everything. That's that's kind of a moot point then. Yeah, yeah, there's one thing, one comment on the drawings that an enhancement and actually when I've when I've you when I've worked with architectural drawings.
I have. I've seen drawings that are that are that have different layers of data. So one is you can have a drawing with that as the details with respect to.
TCPIP connections, the ports that are listening and it's it may not be applicable to this situation, but there are other ones that include what do you call it?

Participant_C   1:31:23
Resource ID, Resource ID.
ID.

Participant_K   1:31:25
Resource ID. That's what I was thinking. Yes, thank you. So those those are nice to have. At least you don't necessarily have them on the drawing, but you can mouse over and have a pop-up. Those kinds of enhancements on drawings make make these drawings really, really productive. So.
Just a thought on that. It's it's it's a nice to have.

Participant_A   1:31:46
OK.

Participant_K   1:31:51
That's all I had to say on that.

Participant_E   1:31:54
Um.

Participant_C   1:31:54
Yeah, so I think, I think he's he's mixing two things here Participant_A. He needs the API endpoint as well as resource ID. Resource ID you know has a specific format like you know, wack, wack, subscription name, resource group name and then and then whatever, right. We can provide you a a general you know.

Participant_K   1:32:05
Mhm.
Right.

Participant_C   1:32:14
Depiction, but you know, we don't know the subscription. We know the subscription, but it may change in the future. So we'll put XXXX or maybe I will just put subscription ID in Curly and this was group in Curly and then you know, whatever the name of the resources. Yeah, that's the format. We can just put a legend here, you know, in the drawing. I think that will, yeah, yeah.

Participant_K   1:32:17
Right.
Mhm.
Right.
Hmm.
Well, that works too. Yeah, that works too. Yeah. And actually one of the reason that I brought this up is it makes it when you when you're trying to troubleshoot access problems, it's really nice to have all this this data right at your fingertips and I have it in incorporating it into a drawing like this.

Participant_A   1:32:48
Mhm.

Participant_K   1:32:52
Is golden. So that's that's why I'm such a a proponent of of adding drawing, you know, adding details like this to drawings.

Participant_A   1:33:03
OK.

Participant_K   1:33:03
It's my two cents.

Participant_C   1:33:04
Yep.
Let's just add a legend. Uh, yeah, yeah, go ahead.

Participant_E   1:33:05
Hey, guys.
Sorry, I know Participant_P dropped, but I wanted to loop back to his initial question real quick just to ask that same question. I guess I'll just try to rephrase it to see what the answer comes back. The IT edge in this drawing is not.
Not playing any role in running model or monitoring the model. It only is playing a role in deploying the model to Kubernetes. Is that yes or no?

Participant_C   1:33:48
Can you come again? Sorry, I was a little distracted.

Participant_E   1:33:50
In in in this drawing, the IT Edge is only playing the role of deploying ML model to Kubernetes. It's not playing a role of controlling it in any way.
Is that correct? It like helps to deploy and then helps to gather that log analytics data and that's it? Or is there more of what it's doing?

Participant_C   1:34:22
See that IoT, what I see is this ingestion point, right? I don't think it's going to deploy the model for you. The deployment of model right in Kubernetes is a different way. You know, if I'm understanding your question, Participant_A, what do you think, right? I think it's a little bit of mix up here.

Participant_E   1:34:36
Mhm.

Participant_A   1:34:41
But my understanding is that the IoT Edge executable runs inside of that cluster and facilitates the deployment from of the model to the edge through IoT Hub based on just based on documentation.

Participant_E   1:34:55
Um hum.

Participant_A   1:34:59
I have an assumption that it also facilitates the telemetry or can facilitate the telemetry of model health going back. I need to research that and to to be give you a definitive answer.
On that.

Participant_C   1:35:18
Yeah. So I'm, I'm, I'm not clear on that piece, right? Honestly speaking, like why would I use the model, right? Are you talking about the versioning of the model? Are you expecting, you know, multiple versions or or like, you know, very frequent?

Participant_E   1:35:20
And.
No, I.
I I think Participant_A actually is answering my question. He's on the right track with that one. And the way I understand from everything that I was able to gather is the final line of defense of, let's say, a powering down or putting the model in maintenance mode.

Participant_C   1:35:36
OK, OK.

Participant_E   1:35:50
Is potentially is just disabling the container itself or so just Kubernetes is the final line of defense like IoT Edge will not play any role in draining the pods or whatever.
Method we choose to put the model in maintenance mode.

Participant_A   1:36:13
Yeah, the container. So the model itself. The model itself is a specific type of file it needs to be.
Put inside of a container with another application and that application that you could think of IT as a web app is designed to interact with the model.
The model itself is just like.
Trying to think of a metaphor for this, but it's just an it's just a a very specific type of function that you call it, but you call, you call a signature.

Participant_E   1:36:53
Yeah.

Participant_A   1:36:57
You pass in parameters and something gets spit out and that's all IT does. But IT doesn't have a natural sort of. It's Not like IT runs on C# or something like that. So you need to have an app that actually runs alongside of IT to be your interface to it, to the model.
And as such, it's just an app that runs on a container.

Participant_E   1:37:17
Mm-hmm. Yeah. No.
Mm-hmm. Yeah. No, that that's perfect. I think, I think I understand everything that you've explained. Yeah. No, I appreciate it. Yeah. And the the demo models that we've deployed, they're basically like what you're saying is.
You take an input, it runs through a pipeline and provides an output, right? And I was just trying to see what the connection between IT Edge and and that container that has the model in it will be if there is anything that we should be aware of, but I'll do more research.

Participant_A   1:37:42
Right.

Participant_E   1:37:56
On my own as well and come back with better questions next time if there are any.

Participant_A   1:38:00
Sure, OK.

Participant_K   1:38:02
Yeah, I I'd be willing to bet that it's based on Tensorflow. The model is that's a that's a typical ML model that that runs exactly like that. You know you you can run it on a command line.
And feed it some input and it it takes that in, compares it to to something using neural networks, the tensorflow and then it spits out.
A number that gives you how how close you are to this or that. An output of some sort. A number that means something.

Participant_A   1:38:44
Right.

Participant_K   1:38:44
To another alication, so something like that.

Participant_A   1:38:49
Yeah, for something like this, I imagine the the output is is numParticipant_K.

Participant_K   1:38:54
Mm-hmm. Yeah.

Participant_C   1:38:56
I just put something in there for easy explanation, input, learning, model and then prediction. That's what it is in a nutshell, high level.

Participant_K   1:39:03
Yep.
Yep, exactly.

Participant_A   1:39:15
Well, I know we've lost a few people. Maybe we should wrap up.

Participant_C   1:39:23
Sounds great. Thanks everyone. Yep.

Participant_K   1:39:25
It's been a good, good, good conversation. Thank you. Thanks everyone.

Participant_B   1:39:28
Yes, thanks everyone.

Participant_D   1:39:29
Bye, guys. Thank you. Bye.

Participant_C   1:39:29
Certainly.

Participant_A   1:39:32
Thanks everyone.

Participant_C   1:39:34
Thank you.

Participant_B stopped transcription