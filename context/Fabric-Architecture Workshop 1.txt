ACME Fabric-Architecture Workshop Meeting Recording

Participant_A started transcription

Participant_B   0:04
Hours set aside. I'm not sure if we're gonna use all three hours, but I would like to do. What I'm gonna do is I'm gonna turn on our recording, right? We're gonna, we're gonna record this.

Participant_A   0:14
Just Ed.
It.

Participant_B   0:17
Yes, I'm sorry. OK, sorry, that's OK. We got, we got the recording started and what I'd like to do is just go around the room and if you can introduce yourself, what we're just looking for is your name and your role on the project.

Participant_A   0:19
I just did. Sorry.

Participant_B   0:34
And then what I'll do is I'll be handing it off to the CloudProviderA team to get us going. So I'll just start off again. You know, Participant_B, I'm the project manager and I'll, I'll read off the names and and basically you can share your roles. So Alim.

Participant_C   0:52
Yeah, hi, good afternoon everyone. My name is Alim. I think some of you may have already spoken to me. I too am from, you know, CloudProviderA Industry Solutions. I will be the lead architect on this engagement. Looking forward to work with you guys.
Nice meeting you all. Thank you.

Participant_B   1:13
Hey, uh, Participant_A.

Participant_A   1:14
Yeah, so my name's Participant_A. I work for the Enterprise Architecture Group here at CloudProviderA, and I'll be with you on the fabric journey.

Participant_B   1:25
You, Participant_D.

Participant_D   1:25
Hey guys, how you doing? My name is Participant_D. I'm a security architect with EAG also. I'm looking forward to work with you folks.

Participant_B   1:34
OK, uh, going down the list of the audio uh side. Uh, Andre.
And if you're on mute.

Participant_E   1:44
Yeah, no, I was just turning on my camera. Hi, I'm Andre. I'm with Ada Helen. I'm wearing the hat today so you guys can easily recognize. I am a business intelligence developer here at Ada Helen and will be supporting from every angle.
I guess touching pretty much everything.

Participant_B   2:08
OK, uh, Participant_F.

Participant_F   2:13
Hey, Participant_F Bonkowski, Network Security Engineer for ACME. I'll be supporting basically all the network infrastructure and network resources in Azure.

Participant_B   2:26
Thank you, Participant_G.

Participant_G   2:30
Participant_G, I'm Director of Data Science and AI Strategy at ACME.

Participant_B   2:36
Thank you. And a pardon me if I pronounce it wrong, but Adalit gay.

Participant_H   2:46
Oops, sorry. Oh, hey everyone. My name is Participant_H and you pronounce it correctly. Participant_B. So I'm with Acme-Sub and I'm the OT Security engineer.

Participant_B   3:00
OK. That's Participant_H. Is that your first name, Participant_H? OK, thank you. Apologize, Participant_I.

Participant_H   3:03
Yes.

Participant_I   3:09
Participant_I, Network Engineer for Acme-Sub.

Participant_B   3:12
Thank you, Participant_J.

Participant_J   3:17
Participant_J, Systems Network Engineer for Acme-Sub and supporting sys admin things in and on Prem.

Participant_B   3:25
Thank you, Participant_K.

Participant_K   3:28
Are Participant_K Participant_M. I'm the lead security admin on the project. I work under Participant_M Participant_M.

Participant_B   3:35
Thank you. Uh, this is another Participant_K.

Mauch, Participant_K   3:38
Yeah, Participant_K Mauch, I'm the Enterprise Infrastructure Manager for ACME. So my team's responsible for all the network and server and storage infrastructure across the org.

Participant_B   3:50
Thank you, Participant_N.

Participant_N   3:53
Participant_N Myers, Systems Automation Engineer. I also have go live and rights on the ACME side.

Participant_B   4:00
You, Participant_M.

Participant_M   4:03
Yep, Participant_M. I laid the data engineers, the BI developers, DBAS and security team on the ACME side.

Participant_B   4:13
Thank you, Participant_O.

Participant_O   4:19
I'm Kalifa Muden, a cloud engineer ACME.

Participant_B   4:23
Thank you, Participant_P.

Participant_P   4:27
Hey, nice to meet you all. Participant_P, data scientist. I don't have my Acme-Sub hat, so that's why I'm not turning the camera on. But Participant_A, if you can send me a CloudProviderA hat, that'd be awesome. I liked it.

Participant_B   4:42
Nice. And finally, Participant_Q.

Participant_Q   4:47
Hey, Participant_Q, Data Analytics, Data and Analytics Architect. And I'm just happy to see that Participant_K and Participant_M got an apartment together looking at their backgrounds.

Participant_B   4:58
Very nice, very nice. All right. So thank you for that. I think we're ready to get started here again. So what we're looking to do is, is, is focus probably on the first three topics here we we are looking to have a series.
Workshops. Typically we're gonna do these on Wednesdays and Mondays afternoons and you know, we're looking forward to your participation contributions. You know, really, we can't do this as CloudProviderA without you, right? We need to get the information.
You need, but it's also good that you can ask questions. You know, I don't think there are any bad questions here. What I'm going to do is I'm going to turn this over to Participant_A to get started. And yeah, Participant_A, why don't you take it away?

Participant_A   5:52
Sure. So I think today one of the things that we want to do is get input from you on your fabric strategy and and because our goal is to help you in your journey to fabric, so.
I know we've had some conversations before and we have notes on this previous conversation, but I think it's worth capturing your intent again and elaborating on that. So maybe you could.
Maybe you could kind of that would be good entry point for for the team to kind of get into that. Who wants to?

Participant_C   6:31
Yeah, let's do this, Participant_A, right. I do have a question from the broader team, Audio or Acme-Sub, right? Yes, we understand, you know, Acme-Sub and Audio are looking into fabric. What do you understand by fabric, right? Do you have full understanding or do you want a quick rundown?

Participant_A   6:35
Mm.

Participant_C   6:51
What you know why and what Fabric can do or or we can.

Participant_Q   6:54
I don't. I don't think we need that per SE, right? Because we've got an F64 capacity. We converted. We were at Power VIP one and we've been on in Participant_G. You can correct me if I'm in.

Participant_C   6:58
OK, good. Good.
OK.

Participant_Q   7:09
If I'm speaking out of turn, but we've been on fabric for for for a little while and we do have workloads running in it, so I don't know that we need the overview per SE.

Participant_C   7:20
Perfect, great. So then let's do this right. Walk us through like you know what you guys have done so far in Acme-Sub for the from the fabric perspective, right. Then what it will do, it will trigger questions on CloudProviderA site if there are any and how you have implemented.
Fabric also because see at the end of the day one of the aspect of this engagement is how basically fabric can be rinsed and repeated in other tenants. So we understand like hey from the setup perspective and from the security perspective this is a solid setup or if there are any gaps.
Apps. Then Participant_D, myself and Participant_A will come back with the recommendations. Participant_G, we are on the same page I assume here.

Participant_G   8:10
Yep.

Participant_C   8:11
Perfect. So if if someone can like you know so put it this way right the workshop today right the the introduction and and and whatnot. We we want to be the ears today and we want you to speak and we we have a you know I I I should say a pretty good understanding of the use case.
So, so let's start from there. If anyone could take us to, you know, on the journey of the fabric, what has been implemented?

Participant_P   8:38
I I I can walk you guys through what we have in Acme-Sub and then Participant_Q, I don't know if you want to show something later or afterwards, but I'm happy to start if.

Participant_A   8:47
Yes.

Participant_P   8:52
If that's OK.

Participant_C   8:52
Yes, sounds good, Participant_P.

Participant_D   8:52
Yeah, that's great. Yeah.

Participant_Q   8:53
Yes.

Participant_P   8:57
OK, sharing my screen. I guess I can walk you guys through a little bit of what we have set up in and then everything is related to Fabric in some sense. So we have a subscription called Acme-Sub OT Data Dev EA and we have these three resources.
Groups. These two are network related and this is where all the data stuff happens in the IoT data. Um.
We currently have a storage account, which is what we're using to store all of our OT data. So we're sending OT, we're sending barquet files from our MQTT broker to ADLS.
Every 5 seconds from data from one of our lines, from one of our plants at Acme-Sub, I can open this up real quick to just show you. It's a pretty straightforward.
Forward. Um.
Storage account 'cause it's just sensor data, right? So um, like I mentioned, every 5 seconds we'll see parquet files being uh ingested in here.
And as far as the security goes, the way Fabric is accessing this ADLS, I think we're using the.
Workspace ID to, you know, give it search block data contributor and data owner credentials there so.
That's that's pretty much it for the ADLS. Then we do have F2 capacity that we're using. This is our dev environment, right? So we're just testing connections and everything. We don't really need an F64.

Participant_C   10:49
Oh.

Participant_P   11:01
Um, then we also have, Yep.

Participant_A   11:02
Hey, Participant_P, sorry to interrupt and I would probably interrupt at some at at intervals. Just a heads up, we will probably interrupt at intervals in order to ask questions.
So Alain has a question I'd like to let him ask if it's OK.

Participant_P   11:21
Yeah, yeah, absolutely. Go ahead.

Participant_C   11:22
Yeah, yeah. Since we were on the storage account, right, so you're using ADLS, right? I saw that it's pretty flat in there. You just have a folder. Have you heard or have you, you know, anyone talked about the medallion architecture for?
The work that you guys are doing, do you understand the concept of Medallion Architecture?

Participant_P   11:46
Yes, absolutely. This is just the raw data. So this is kind of like your bronze layer, right? Later in fabric, we'll show you, we have kind of like the golden architecture or yeah, the medallion architecture in our lake house.

Participant_C   11:47
OK.
OK.
OK.

Participant_P   12:04
But this is just raw, raw data.

Participant_C   12:07
OK. Gotcha. Perfect. Thank you.

Participant_P   12:08
Yep, no problem.

Participant_A   12:09
So let let me ask some following questions if that's OK.

Participant_P   12:12
Yeah.

Participant_A   12:14
So a couple of thoughts. You plan to do machine learning model development on the data, right?

Participant_P   12:25
Yes.

Participant_A   12:27
Um, are you? Are you planning? Have you already started to do that?

Participant_P   12:32
Uh, a little bit. Yes, we.

Participant_A   12:35
Are you using the raw data when you do that?

Participant_P   12:40
So right now, because this has only been implemented for a couple of months, we're not using this quite yet. We need this data to build historically for us to be able to use it.
So in the future we'll definitely use this data. It might be coming from a lake, you know a delta table in our lake house once we clean it and we structure it like we need it to. But for now we're just referencing A historian on Prem that we have.

Participant_A   13:00
Mhm.

Participant_P   13:15
But yeah, like I said, once we build enough data to start training the models, yeah, absolutely. We'll be using this data to to train models and fabric.

Participant_A   13:24
OK.
So yeah, I think that gets to the medallion. Architecture is the if you do you prefer see the need to clean the data before you before you start trying to consume it in a in a model for model development. Sorry.

Participant_P   13:42
Like I said, this is pretty straightforward data. I mean it has like an identifier, a topic, right? So it tells you like the plant, the line, the sensor or the motor.

Participant_A   13:50
Mm-hmm.

Participant_P   13:57
And and those type of things and then the actual value. So it's like, yeah, in theory you can clean it a little bit, but it's pretty straightforward, right? You have a timestamp, a value and the sensor, so.

Participant_A   14:12
OK, I just know from from past experience that data scientists often like to work directly with the raw data, but I, you know, wanted to see what your your preference was in that regard.
Um, it looks like Participant_Q has a question.

Participant_Q   14:30
Yeah, yeah. I want to just make sure that you know the the medallion architecture, it's always bronze, silver, gold. But if the data doesn't, to your point, need transformation right per se from A to B and you can just land it and then do your gold level semantic model with whatever you need.
Is that is that considered OK? Because I I just don't want to, you know, my my problem sometimes with data, if we've got data that we're going to use that doesn't need any transforming, do we need to put it in the bronze and then write something to move it to to silver and then?
Move it into the goal layer.

Participant_A   15:09
Yeah. So it's a great question. I think it really depends on on the full landscape of what you want to do, try and do with that data because I'm I'm going to have some following questions about the use of Power BI.
And how you might need to use that data for Power BI or where that might fit into the picture. I don't know that. So that's kind of like part of the workshop is trying to understand the full spectrum of things. If you were just going to do ML, maybe you wouldn't need to transform it at all, especially as you said, if the schema is actually.
Quite straightforward, right. So I hope to suss that those kinds of things out. But yeah, that's a great question, Participant_Q. And then another question, Participant_P, for you right now you say you are.

Participant_Q   15:49
Yeah.

Participant_A   16:03
You have the fabric workspace identity connecting directly to the the BLOB storage to the data contributor role, right?

Participant_P   16:14
Yep.

Participant_A   16:15
Uh, but you are not using private endpoints, correct?

Participant_P   16:21
Right now, it doesn't look like we're using any. Yeah.

Participant_C   16:24
Next.

Participant_E   16:27
Correct.

Participant_A   16:28
Yeah, like, yeah, you you you could not be.

Participant_P   16:32
Yeah.

Participant_D   16:32
Yeah, you're using trusted workspace access, right?
Is that what you're saying, Rahul?

Participant_E   16:37
Yes, yes, and it is tied to workspace identity access. We started playing with private endpoints in the beginning a few months ago, but they were extremely limited to their capabilities, as in they only work with notebook.
Not data flows with this, but not that. And there is a lot of concerns that they were just barely released. So that's that's the main reason we're not doing private endpoints on that just there.
Capabilities to run the functionality of the fabric. I know it's growing, but that was one of our big concerns.

Participant_P   17:23
And and at that point in time, Andre, correct me if I'm wrong, but the shortcuts were weren't weren't part of the endpoints capabilities, right? Which is a big hitter for us cause we definitely need shortcuts for this type of.
Setup.

Participant_E   17:40
Yeah. And the way kind of just to step back and give you guys like a bigger picture understanding of like the things that we're trying to accomplish at at our own. And Participant_P, I hope you don't mind me just jumping in for a couple of minutes.

Participant_P   17:57
Go for it.

Participant_E   17:57
Let me share my screen real quick. I'll just give like a whole holistic overview of like what we're trying to accomplish here. And a a big piece of that is what Participant_P is describing, but we have like other pieces to that.
And maybe that will give a better context. Let me share my screen.
This is one of the don't read too much into it. I usually build stuff like this for myself and just a quick reference. So the way I see the whole architecture working together is where historically.

Participant_A   18:25
Thanks.

Participant_E   18:43
Using EntERPSys_A data for our business data and we never historically used OT data that Participant_P is describing. So on this chart you could see that we're putting that ADLS into a parquet format and then we wanna.
Shortcut that into a fabric workspace and then do all that transformations and all of that. But in addition to this one piece that we're doing, we also are moving away from BYOD jobs as much as we can on D3.
65 exports and we're also planning on doing the EntERPSys_A shortcuts and do access to a business data using the EntERPSys_A and then other pieces that are gonna be not as big of a project as these.
Two projects where we're also planning on using those shortcuts potentially and then in their bronze, silver, gold architecture will either use like materialized views or just a data engineering techniques to create those bronze, silver layers, go layer golds.
So for us, for the bigger picture, we're planning on integrating a lot more than just this project and I use it for reporting, kind of like Participant_A hinted at whether we're going to do reporting or just machine learning. Yes, we're planning to do.
To do to move away from BYOD in EntERPSys_A to Fabric connection, we're planning to ingest all this OT data. Then we're planning to marry that data in Fabric together and then do Power BI reporting as well as machine learning on that data.
So I hope that kind of connects the whole piece together into what we think we want to accomplish by the end of our project.

Participant_A   20:53
Yeah. OK. Yeah, that definitely helps. Um.
I have other questions about that bigger picture, but I don't want to completely derail Participant_P, so maybe I'll just hold on to those questions for now and let Participant_P continue.

Participant_P   21:17
OK.

Participant_E   21:18
Love it.

Participant_P   21:20
Sounds good. And then just guess the other things is.
Here's our MQTT broker, which is in a BM and this is the one that's routing all those.
Messages or Parquet files to ADLS. Then the rest is just some network security stuff. And yeah, that's kind of like the setup that we have for the OT data in Azure. I don't know if there's any other questions.

Participant_A   21:54
Yes, I have a question about that. So you are hosting a VM in in now in order to run the MQTT server on the on the side, right?

Participant_P   22:11
Mm-hmm. Yep. So.

Participant_A   22:11
And you and you have you have another one on the on Prem side, right?

Participant_P   22:17
Correct. And then we have an MQTT bridge between the two of them, so they can publish and yeah, messages between each other.

Participant_A   22:28
Have you considered um Event Hub?

Participant_P   22:33
We did, but this is kind of what we decided on using MKTD brokers.

Participant_A   22:40
OK, just just throwing it out there because with event stream you can you can land that stuff in one lake directly.

Participant_C   22:51
Plus you are depending on a VM as well, right? So I'm assuming in the in the in the future when you go production, you're going to have a scale set. If what if if that VM goes down, your your dependency on that VM becomes a bottleneck. So something to consider. But again, let's move on for now.

Participant_P   22:51
Yeah.

Participant_A   23:09
Yeah, yeah, just throwing it out there.

Participant_P   23:10
Yeah, that Yep, no, that's a good suggestion. We do have in our scope in the future having two VMS so that if one goes down, the other one jumps in because the software we're using have MQ has the capability to relocate resources between 2 VMS, but.
It can also go into Kubernetes Services, but anyways, yeah, that's out of scope.

Participant_C   23:35
Yep, Yep and and Yep, definitely right. So another thing, right? Maybe this is too early, you know, but I'll just say it before I forget. So have you done any kind of cost analysis right using a VM?
What says you know, maybe IoT Hub plus maybe you know Event Hub, something like that. If you have not done it, you know something to look into that because you don't want to have a, you know, some sort of dependency on the infrastructure of this kind, right? You should rely on.
Paas services because of, you know, the uptime and then you know everything else that comes with the Paas services. Just a thought, right?

Participant_P   24:17
Yep. Thank you. Yeah.

Participant_C   24:18
Yeah.

Participant_D   24:20
Yeah, one thing too, you know, just to build on to what Alim said, right? Like, so this is a completely separate tenant and subscriptions, right from ACME. How is security like overseeing this? Is it integrated to ACMES? Is logs being forwarded? Are these kind of like separate credentials that security folks?

Participant_C   24:25
Yeah.

Participant_D   24:39
So we'll have to go in, pop in and and and have visibility to things like the VMS, et cetera.

Participant_M   24:46
Yeah, so I couldn't speak to that. So we've got our centralized cloud service admin accounts that reside within the ACME tenant and then we've got the, I forget the exact term, but it's essentially like some of the peering across.
Sentinel and for log forwarding and things like that, but we actually have Sentinel instances set up in ACME and Acme-Sub and then set up app registrations to forward out all of the activity logs and sign insurance and things like that.
Um, Yep.

Participant_D   25:23
OK.

Participant_A   25:28
Yes.

Participant_M   25:30
Uh, Whitehouse is what we have set up. Last tenants.

Participant_A   25:31
OK.

Participant_D   25:35
OK.
How how about the like so for example now we don't need to dive deep into this but like the VMS are are they are you guys are you guys managing those if they're if they if the Acme-Sub folks spin up a VM?
Like this is there like um is it? Are these managed VMS instances or?
From a security perspective, like you have, you know, end property.

Participant_A   25:58
So.

Participant_M   26:01
Yeah. So they would hit, you know the when we're rolling out the landing zone policies. So that would hit like require essentially defender on the VM and that's that's what we would rely on for coverage there.

Participant_D   26:09
Uh.
OK, cool.
OK.

Participant_M   26:19
As far as policy management and configuration management on those VMS, I'd have to defer to probably our sys admin team and if they've done anything on that front, but I don't, I don't believe we've got a great tie in with.
Probably managing config on VMS in general.

Participant_D   26:39
OK. No worries. No, this is this, you know, landing zone policies and and you know the posture that we'll we'll get into that a little deeper, but no, that that that's good enough. Thank you so much, Participant_M.

Participant_C   26:52
Hey Participant_D, sorry, I need to latch on one of the things that I heard, so maybe I'm misheard it. Correct me if if I misheard it. You said you have two different Sentinel instances in each of the you know.

Participant_M   26:52
Yep.

Participant_C   27:08
Tenants. So you have one Sentinel instance in audio and one in Acme-Sub. Is that what I heard? Oh, why are you doing that?

Participant_M   27:16
Correct. Yep.
Yeah. So the way our managed detection and response partner operates is well and one we're leveraging the free log sources. So each tenant has their own E fives and downstream defender logs.
If we sent them to our core tenant, I would've not sure I guess how that would be built. But in essence, you know we've got the free Defender for end point, Defender for Identity, all those log sources flowing up, you know, to the respective tenants Sentinel instances.
And from our perspective, it rolls up into the MDR platform for a single pane of glass for us, so.
That's kind of how it's set up today. But I guess if it was, if it'd be free to centralize that even in a single Sentinel instance, there's no reason. I don't think that we would. I just would assume that we'd somehow be billed extra for that, yeah.

Participant_C   28:10
Yeah, that's exactly where I was going, Participant_M. That's exactly where I was going, right. Because you should be able to use, you know, centralized, you know, Sentinel workspace for multi tenant scenarios. And the reason is right, if I, if I'm not mistaken in the past, right, you know like a month or two or three months ago what we heard was.
Because the security team is centralized and ACME is the security team and the individual subsidy does not have that. So in those cases, right, I would never have multiple instances floating around in multiple tenants instead have a centralized workspace. But again we will discuss this.

Participant_M   28:36
Yep.

Participant_C   28:50
In detail at a later stage, me and Participant_D will definitely talk about it.

Participant_M   28:54
OK, sounds good. Just in quick too. So from the from the billing standpoint though, do you know if the free sources are even free for consolidating multiple tenants into one Sentinel instance?

Participant_C   28:55
Yeah.
So from the billing perspective, right, you are already ingesting the data right in in tenant A and tenant B, you are actually duplicating the data in a way, right? Because you have to still connect, you know tenant B workspace into tenant A. So you are not saving, you are actually spending more money.

Participant_M   29:12
Mhm.
Yeah.
Sure. So I should clarify too. We're not replicating anything over upstream to the first Sentinel instance. They're they're on islands. We just have Lighthouse to jump between the two tenants and then upstream we're pulling all the data out into a a separate SIM.

Participant_C   29:25
You know.
Mhm.
Yeah, yeah, Yep.

Participant_M   29:40
MDR platform.

Participant_C   29:42
OK, OK. Yeah, it's still like, you know, you don't need to make that complicated. Yep, Yep. Perfect. Thank you.

Participant_M   29:44
Yeah, Yep, Yep.

Participant_P   29:54
Any other Asher related questions?

Participant_A   30:00
I'm good. Uh, you can continue.

Participant_C   30:01
Uh, Yep.

Participant_P   30:02
OK.
Sounds good. All right. Well, I guess we can go to.
Fabric and stuff we've done in Fabric. Um.
Is I can walk you a little bit through couple of POCS, then the structured streaming script that takes all those parquet files, cleans them and.
Um.
It gets sent to this table in our silver layer quote UN quote.
Um, so I've done a couple of stuff with structure streaming.
As well as batch ingestion.
Or the same data. It's just PO seeing different different ways of ingesting the same data and structuring the delta table, playing around with the partitioning in the delta table and.
All those cool things in in delta tables, so um.
That's pretty much what we have for.
OT data. As far as the engineering, I've started to train a an ML model on a different capacity, but it's using historian data, not the one that we haven't.
In our ADLS environment, so yeah.

Participant_A   31:44
OK.
So historian data, that's data you managed to import from your existing system, right?

Participant_P   31:55
Yeah, just CSV files with historical data.

Participant_A   31:59
Right. So so you can like get a get a a model development process going while you're still building historical data of the current process. Yeah, OK and you're you're using.

Participant_P   32:09
Correct. Mhm.

Participant_A   32:14
Um, it's time to think here so.
So you are cleaning and restructuring the data, right? That's what I heard.

Participant_P   32:23
Bear slightly. Here's an example. So in the parquet file, you'll only see the topic, which is this big long column or big long row, and then you'll have the value, right? And that's all I get. And all I've been doing is just like separating it into.

Participant_A   32:38
Mhm.

Participant_P   32:43
Columns, site and adding a couple of files or like columns for dates and stuff like that. It's not necessarily for sure, but I just wanted to get a feel for the capabilities of Fabric and.

Participant_A   32:52
OK.

Participant_P   32:59
How fast it can, you know, do stuff, I guess.

Participant_A   33:02
OK, so it is impractical then for you to work off of the raw data. You need to parse it out and add some extra metadata in there if you will.

Participant_P   33:14
Yeah, yeah.

Participant_A   33:19
OK, OK.
All right, right. And then, so I guess that answers one of the questions that Participant_Q had, which was do do we really need to do any post processing? And it looks like at least from, you know, your staging to.
Um.
Your next zone you need to you need to do some processing at base. That's what it sounds like.

Participant_P   33:48
Yep, Yep. Nothing crazy, uh, to be honest. But yeah, separating columns is always kind of nice.

Participant_A   33:58
Right, right. Um.
Does oh, I'm curious, does the is it does the MQTT broker do any of can it? Is it capable of doing any of that kind of work for you?

Participant_P   34:14
It's. I have to continue to look into it. I know there's a couple of changes that are coming that I'll be pushing soon, like for example this value column is encrypted. I'll change it.
So that it's not encrypted and little things like that. But as far as I know, I'm I don't think it can, you know, do some data modeling itself and then just push the right format for the parquet file.

Participant_A   34:47
Well, there's there's mod. Yeah, there's modeling. And then there's just like, um.
A little bit data enrichment, right? So like, I know that Events Stream can do some of that work for you if you're just doing like a little bit of enrichment, especially if you're just parsing some fields out into separate fields.
Yeah, absolutely. Event Stream can do things like that for you. If you need to do more things than that, like actual cleansing of data, you know, that's a different, different kind of equation. So I guess.
I was throwing that out also just as a consideration.

Participant_P   35:31
OK, cool.

Participant_A   35:32
Yeah, go ahead. And so you want to go to the next step after you've got it in Fabric and you're working on your machine learning model and what else?

Participant_P   35:47
As far as fabric goes, I mean we do have another F2 capacity that we use on a daily basis to, you know, send data to an SFTP server or pull data from APIs into our data warehouse.
And um.
We also, I know that Andrea has been developing some, you know, stuff with the data burst connector in fabric as well. So that's kind of the gist of it.

Participant_A   36:24
OK.
Tell me more about that.
Because we're we're we're talking all things fabric now. So like this is 1 use case, but you have some expanded objectives beyond just this one use case and they will all affect you know what you would try to do and structure.
With with Fabric. So I'm curious just to get everything on the table, what are those other things? You mentioned SFTP bringing in some other data from an external source. What do you do with that? Where does it go? What is it used for?

Participant_P   37:05
Right. So I guess one scenario I can, I can pull it out. So this is the capacity that we use for running, you know, daily jobs we for example.
Have this notebook that runs on a daily basis that's pulling data from our data warehouse, restructuring that data into a proprietary format, quote UN quote for a company called Transect that you know receives our transfer orders.
Data and they create the reports and works with one of our departments here at Acme-Sub. So it's basically data warehouse transforming that data and then sending it to an SFDP server.
Then we have this Lehigh custom fit, same scenario pulling data from Data Warehouse, transforming the data, sending it to an SFTP server. This is an example for our Learning Management system.
Which it's pulling data from from their database via API I guess, and then transferring it to our data warehouse into in a in a daily basis.
So those are kind of like the standalone kind of projects on the side. Do you have? And then I guess we may have more of these little use cases in the future, but then I guess the next big hitter would be the EntERPSys_A.

Participant_A   38:37
OK.

Participant_P   38:50
The item.

Participant_A   38:51
OK, I'm just curious where what are you using for a data warehouse?
Where does that live?

Participant_P   38:58
So Asher's.
It's an Asher. Yeah, it's an ACME's tenant.

Participant_Q   39:08
Yeah. And it's not, it's not to be clear too. It's not what you would consider, sorry for interrupting a normal data warehouse. It's more of an operational data store and that's where the BYD goes and that's where some all of the ancillary kind of things and we do a little bit of a.

Participant_A   39:09
OK, OK.
OK.

Participant_Q   39:28
medallion architecture there, meaning we land the raw data in a in a schema and then we build another schema on top of that or different with views or or stored procedures. I think that's kind of how Andrea and Rahul, do you agree to that?

Participant_P   39:42
Yep, absolutely.

Participant_A   39:44
Here wait, I'm a little confused. So you have this data warehouse in Azure.
Um is it an sequel? Some other database?

Participant_P   39:55
Mm-hmm. SQL Server.

Participant_Q   39:56
Yeah, no, sorry. SQL Database. Yeah, SQL Database.

Participant_A   39:58
OK, and then you're using SFTP.
To transfer data from that database.

Participant_P   40:09
Yep. So our vendors have at their own SFTPS and we take data from the data warehouse and send it to their SFTPS.

Participant_Q   40:19
Yeah, through an ADF pipeline. Yeah, through an ADF pipeline, right?

Participant_A   40:19
Out to their SF TV's.

Participant_P   40:25
Yeah, so we have notebooks that do the transformation, extraction and sending of the data, but those notebooks are in a data pipeline that schedules the the notebooks to run every every day.

Participant_A   40:40
OK. And then it sounds like you use ADF to then send it via SFTP on some kind of schedule to vendors?

Participant_P   40:50
Yep, ADF.

Participant_A   40:53
OK. And then how does that, how does that, what's the flow of data as it goes into into this fabric capacity, into this workspace from the warehouse?

Participant_P   40:53
Sorry.
So it doesn't. I don't store the data in fabric right now. I just take the data, I manipulate it, create a file and then send it to them. I guess I do store the the file that that I sent the the.

Participant_A   41:24
Oh.

Participant_P   41:28
The end result I guess, but I do not store data warehouse data in a lake house per say. I just store the files that I created just.

Participant_A   41:30
OK.

Participant_Q   41:40
Right. You're just orchestrating at this point in in fabric, right? You know you're making the connection to the to the to the data store and doing it and then just keeping some archive.

Participant_P   41:53
Yeah.

Participant_Q   41:53
Yeah.

Participant_A   41:54
Oh, interesting. OK, so this is more about, I mean, you're using ADF, but you're not really using the capacity itself for.
Like the well, I'm sorry. So you're using you're using a a notebook and and and Fabric to do some transformation of that data is what you're saying, right?

Participant_P   42:14
Yep.

Participant_A   42:15
And then and then you you send it out. OK, so the fabric capacity is entirely for the purpose of hosting notebooks, otherwise you wouldn't need them.

Participant_P   42:26
Yeah, and running them, I guess.

Participant_A   42:31
OK, right, right.
OK, that's interesting. And then where does Power BI come into this way? You're not using anything from that capacity to flow into Power BI, right?

Participant_P   42:48
No, right now we're not. None of our workspaces that are power used for Power BI reports are connected to Fabric capacities. Right now we're just using the pro license per user.
At at least ACME is a different.

Participant_A   43:05
OK.
So let's go back to the other capacity then.

Participant_E   43:09
I.

Participant_A   43:13
I'm sorry, go ahead, Andre.

Participant_E   43:15
Sorry, I was just gonna say I do have one report but it's I just built last week so it's very early stages where fabric is being used to run Power BI on the end.
And we, I just connect to the SQL end point of a lake house for that one, but that's the that's the direction that we're trying to go. We're trying to walk away a little bit more away from the data warehouse or operational store that guys been.

Participant_A   43:37
Oh, OK.

Participant_E   43:51
Talking about and go more heavy on fabric. So store more data in fabric instead of the operational store or warehouse and do all the modeling in fabric at the end and then feed that into.

Participant_A   43:58
OK.
OK.

Participant_E   44:11
From Lakehouse endpoint or Warehouse into semantic models to be consumed using car BI.

Participant_A   44:21
OK. Do you foresee any need to um?
Connect or yeah, how should I put this? Any of the data that's in your operational data store right now, do you have any need to like connect that in any way with data that you're bringing into fabric from, you know, your OT data?

Participant_E   44:46
I I I think there is potential for that for some kind of mirroring in the future, but I can't foresee right now our.
Yeah, there is a deep topic about our EntERPSys_A having modules that are heavily modified by vendors or modules that we purchase from vendors that only support like BYOD jobs to a data warehouse.
To SQL Data Warehouse and they can't support the EntERPSys_A link to Fabric. So like without going too deep into it, we will potentially have some use cases where we will have data in that operational store that will.
Will need to mirror into one lake into like a lake house and then consume it that way. But majority of data I think will go away from using the SQL.
A database and we'll use the lake houses and warehouses in fabric. At least that's that's how I foresee it. And Participant_Q, I want to remind you again.

Participant_A   45:53
Mhm.
OK.

Participant_Q   46:02
Yeah, to follow up with that too. Yeah, we're gonna, we we're gonna be heavy with, you know, we've got a lot of no data, you know, islands or whatever. So we're gonna in our fabric journey, we're going to have to have that interconnectivity and you know, bringing.
Data over or or at least being accessible. So for sure we will be early on.

Participant_A   46:27
OK, So what I'm hearing is, and correct me if I'm wrong, that one scenario is that it might be valuable to have your OT, your operational data store, your ODS data eventually shifted over into the same works one like.
Same fabric semantic model space, shall we say as your OT data, because you might need to actually like do some, shall we say, joins or lookups in order to do some of the kinds of reporting you foresee in the future, although albeit maybe.
Far into the future.

Participant_Q   47:08
Yeah, 100%. Ultimately we we want to get into that space where everything is living in one spot, right? And it's going to take a while to get there, but we're still going to be able need to be able to as we do these legacy processes and routines that we got to pull data in and how we're doing our our Power BI and and and yeah.

Participant_E   47:09
Yeah.

Participant_A   47:29
OK, So what I'm hearing now is like.
A medallion architecture really is needed because you need that gold layer, your semantic model and your gold layer to be able to handle multiple different types of data sets and then be able to use run reporting.
Potentially direct query against against that from Power BI. Vincent's all gonna be in in Delta Lake.

Participant_Q   47:59
I would, yeah, I would, I would say that and Participant_G, you know a little bit more about this than I do. But I think right now our gold layer, our gold medallion is in the DAX and the data sets, right? Or is that?
Am I off there?

Participant_G   48:15
Yeah, a lot of what a lot of the final model mean today lives in the Power BI workspaces which we consider Mart ish right from from a post operational data store state to that workspace.
And that allowed us to move very, very quickly from a delivery standpoint. But yeah, we're the maturity model that we want is to go upstream into the fabric layer and begin to, you know, curate that data more more intentionally.

Participant_A   48:50
OK. OK. Um, yeah.
And OK, so from the from what kind of reporting are you planning? I guess we're shifting into the the reporting side of this question, these sets of questions.
And before we do, does anybody want to take a break? Like a bio break or something?

Participant_C   49:17
I think it's been about an hour. Sounds like a plan. We can we can come back three CST 7 minutes from now. Is that OK everyone?

Participant_A   49:19
Yeah, yeah.

Participant_G   49:27
That's a good idea, man, for everyone.

Participant_Q   49:27
Smith.

Participant_C   49:29
Perfect. Awesome. See you in seven.

Participant_A   49:29
Okay. See you if you.
St.

Participant_R   50:10
I'm on your screen, Sharon.

Participant_C   53:59
We are on a break for another two more minutes guys. Moyuddin, I know you just joined. So just an FII, we are on a break. We should be starting in about two minutes again.
All right.

Participant_A   56:16
All right, I'm back.

Participant_C   56:18
Yep, me too. Hey, Participant_A, I don't know. Do you remember who was talking about? There is a data warehouse in audio tenant. I forgot the name of the gentleman. I didn't make a note.

Participant_P   56:34
I I mentioned that.

Participant_C   56:37
Oh, OK, Participant_P. Hey, quick question, right. So are you doing any kind of ETL from that ACME database into fabric or you're mirroring it? What are you guys doing with that?

Participant_P   56:50
I'm using a.
Trying to think inside of fabric.
I mean, we do have a bunch of Power BI reports that reference that data warehouse and then we also have a couple of notebooks that also connect to it using some Python.
Libraries.

Participant_C   57:15
Uh huh.

Participant_P   57:17
Yep.

Participant_C   57:17
OK, no the reason is right. I'm I'm not sure if if you know that SQL mirroring in fabric is basically a real time data replication feature and what it does, it mirrors that SQL DB.

Participant_A   57:27
Yes.

Participant_P   57:29
Mhm.

Participant_C   57:33
Like you know in that you have into Fabric so you don't have to do any you know ETL if if you're doing anything and it it basically gives you instantly like you know to consume real time sync right? So I just want to bring it to your attention if you are already aware that's good, if not something to ponder on.

Participant_P   57:42
Yeah.
Yeah, we did try that, but it doesn't support multi tenant or cross tenancy last time we checked into it.

Participant_Q   57:53
And we we kind of tried to look into that. Oh, go ahead.

Participant_A   57:53
I think I actually heard Andre mentioned that.

Participant_Q   58:04
Yeah, and there's a table limitation too with that, right? Or it used to be it's 500 with with all of our schemas and all the different data sources we would have to take, you know, a very limited subset and then that just kind of.

Participant_C   58:04
Um.
OK.
OK. I didn't know about the limitation. I will have to check that. That's the first time I'm hearing, yeah.

Participant_Q   58:26
I will check it too.

Participant_P   58:30
Yeah, yeah. I mean, and if that's an issue that is no longer there, the cross tenancy limitation, that'd be awesome cause then we would definitely start using it, but yeah.

Participant_C   58:39
Yeah.
I'll I'll, I'll take that as my action item because he is just a matter of like you know a connection string, right. But again let me let me look into that and I'll get back to you for sure because we I don't have a lot of customers with the.

Participant_A   58:44
And I.

Participant_C   58:56
Multi tenancy for this kind of scenario, but you know I'll let you know.

Participant_P   59:00
Yeah. Thank you. Appreciate it.

Participant_C   59:01
Perfect.

Participant_A   59:01
I mean either that or perhaps shortcuts.

Participant_C   59:06
Pardon media shortcuts, right? Shortcuts.

Participant_A   59:09
Yeah. All right, let me get back.

Participant_C   59:11
Yeah, perfect.

Participant_A   59:15
So Participant_P, I think you are about to get into Power BI reporting requirements, is that right?

Participant_P   59:28
Yes. Can you repeat the question and exactly what you're trying to look for?

Participant_A   59:33
Yeah, So what I'm trying to understand is the landscape of reporting needs. So I got to hear some of what your reporting needs are out of the ODS database that you use, but which is apparently in a different tenant.
And it sounds like you have Power BI pointing directly.
At the database itself.
Whereas for the OTD that you'll be bringing in, what kind of reporting would you have off of that?

Participant_P   1:00:09
There could be some alerting for our employees at the plants. That's something we can probably do with fabric. You know, based off of the reading of a sensor, we can send a message in teams or send an e-mail out.
That's probably more on the notification side of things, but we could also have Power BI reports that utilize that data in a summarized way potentially. Then the other use case that we are thinking about is.

Participant_A   1:00:41
Mhm.

Participant_P   1:00:47
Uh, you know, doing some.
Tracking of our MO models, you know, making sure data's not drifting and and things like that potentially in a Power BI report.
Ort.

Participant_A   1:01:01
Yeah. OK. So as the, yes, I do foresee that as a real scenario, right. You are trying to build a call, you call it a deterministic machine learning model to run your plants.
And.
It is, I think, fairly standard to do something like output data from the model.
Are uh from the training of the model and.
And then use Power BI to report that and that helps you see.
How well the model's performing.

Participant_P   1:01:42
Mm-hmm.

Participant_A   1:01:44
Now that that also means using some, you know, some notebooks and things like that to kind of do some work against that data. But yeah, then the result of the that output can then be used in in the reporting.

Participant_E   1:01:44
Yeah, in the book.

Participant_A   1:01:59
But yeah, it's it's primarily around measuring the performance of the model.

Participant_E   1:02:07
Yeah. And another another pretty big reporting ask, I think that will come down the pipeline from our leadership team is right now we have all the dollar values living in EntERPSys_A.

Participant_P   1:02:07
Yep, I I agree.

Participant_E   1:02:26
And none of that dollar values really traverse into the OT world outside of Excel reporting where like a cost accounting takes dollar values of labor, applies it against OT data and produces some kind of report. So as soon as we put both OT data.
Machine data into Fabric and the these 365 dollar amounts into Fabric. That marriage will happen and bring a child of reporting of new level reporting where everything on the plants will be assigned dollar amounts.
And that's kind of where our strategic leadership team wants to take this whole thing as well. So that's going to be another scenario to add to what Participant_P already specified as well.

Participant_A   1:03:15
OK, OK, so there I see some scenarios here where you're going to use, let's say shortcuts to into EntERPSys_A to try and pull in some of that data and then as you said, marry it with the OT data.

Participant_E   1:03:24
OK.

Participant_A   1:03:33
A assign dollar amounts, dollar valuations to the results somehow and then you can produce reporting off of that and also potentially and I would imagine at an executive level KPIs, right? And especially where KPIs can be like.

Participant_E   1:03:51
Yes.

Participant_A   1:03:53
Green, red, yellow and something is red and we're like.
All hands on deck. We need to pay attention to this.

Participant_E   1:04:00
Yes, that's exactly, Participant_A. Thank you.

Participant_A   1:04:04
OK. OK. Yeah. I mean, that kind of capability has been around for a long time regardless of, you know, your your platform. But yes, this is the kind of thing we would be doing.
OK, OK, so I get an idea now of like.
I I think I have a reasonable picture of the landscape. Anything else you want to like fill out? I'm thinking of it like a game map and I'm exploring around the map and I'm trying to see, you know, if I cover the entire map.
Anything I'm missing?

Participant_C   1:04:45
I I do have one question. I I think we kind of touched it, but maybe I didn't hear properly in terms of the Power BI, right. So once the model you know runs and then you know you have the Power BI, people are looking at it.
Are you taking some of the, you know, high and low values or whatever that may be and trying to alert people? I'm just trying to get to the data activator in CloudProviderA Fabric, right? Because you know if you are sending that data, right?
And it it helps, you know, alert the appropriate people, right? So not sure if you guys are thinking about that. Have you heard about that CloudProviderA data activator?

Participant_P   1:05:30
Yeah, I've heard a little bit. Um.

Participant_E   1:05:34
Yes.

Participant_P   1:05:34
And it is, it is an option. But the yeah, Long story short, the ML model will live on Prem cause we don't want a dependency on the Internet and the the OT world has a lot of different tools that they wanna leverage there.

Participant_C   1:05:37
OK.
OK.

Participant_P   1:05:52
So it is a possibility, but I'm not sure how much will go into there, but yeah.

Participant_C   1:05:56
OK.
Fair enough. And you know now that you mentioned about that the model will actually run locally. What are you guys thinking when when you say locally, how are you going to run it? Where are you going to run it?

Participant_A   1:05:59
OK.

Participant_P   1:06:10
It'll be a Docker container that connects to our MQTT broker, receives all the input values from the MQTT broker, makes the model inference, pushes back the outputs to the MQTT broker on Prem.
The MQTT broker will push up to the cloud all the inputs, the outputs, the model utilized to create or get all the inputs and and everything. All the data related to the model will get pushed from that MQTT broker to the cloud.
And also they'll be using Ignition to connect to the MQC2 broker and Ignition will push those values to the PLCS and whatever they're they're gonna be using out there.

Participant_C   1:06:59
OK. OK. Lots of moving parts there, I think, but that's fine, right. So the reason I'm asking, right, I think we may have touched this, Participant_G, you know, because The thing is, yeah, Docker is a great choice, don't get me wrong, right. But how about like, you know, leveraging some of the other cloud capabilities, have you guys thought?
About using Local by any chance? Have you guys explored that option?

Participant_G   1:07:22
That came up in that did come up in discussion. Was there a limitation Andre Participant_P that that we bumped into on that or just?
We found very, very similar to what there was going on.

Participant_E   1:07:36
Yeah, when we evaluated the disconnected operations were like a new thing for Local because we wanted to separate the control layer of the cluster from the Internet and not have any.
Rendencies at all and Local at that point didn't have the capabilities or they just were released I think in November and there were other options that we wanted to pursue with the OT world I think.
Some of those limitations played a role in US not wanting to go that route.

Participant_G   1:08:19
Yeah, yeah. If I remember it was there was very, very new and then it had a a pipe to the Internet which raised a flag. I think if that's.

Participant_E   1:08:19
If I remember correctly.

Participant_C   1:08:19
OK.
Yeah, it's not required to have connectivity to the Internet. Honestly speaking, you can run it like, you know, as if you know not connected to Azure. It's not a requirement.

Participant_G   1:08:33
Uh, OK.

Participant_E   1:08:40
Well, uh.
Yeah, I think the the piece that that's not a requirement was that like the control and reporting pieces were going to be in the cloud in that space. Even if we do local, it's connected to tenants and like Grafana or any.
Prometheus or other tools are used gonna be in the cloud, right? And we wanted to make it like a truly disconnected experience for some of the user requirements where it's gonna be on the Prem.

Participant_C   1:09:08
Yeah.

Participant_E   1:09:18
So like logging and operations and reporting off of the cluster and performance and running will all be disconnected. So let's say Internet drops and you can't go to and refresh a dashboard that shows how cluster is doing right now.
Now I think that was kind of a drawback on that one, just just to give a little bit of feedback. Hopefully that helps.

Participant_C   1:09:43
Yeah, you you do have some stale and old information for sure, right? You can absolutely run this in a complete disconnected mode. Yes, you need a subscription, you know to register it, but otherwise you should be good to go. But again, like you know, I don't know all the scenarios that you guys have run through. Maybe we.

Participant_E   1:10:02
Yes.

Participant_C   1:10:03
Can actually discuss this in detail if you can send me you know the the you know a list of things that didn't appeal. But again right remember you know the world is moving in a AI you know arena right now that we talked about fabric right.
You know, I don't know how much control you got you, you, you, you know, Aidan is thinking to give to the operators, right. Will copilot, you know, help you in any scenario here, right. So you know, can a operator, you know, question something, go back to historical data, look at it, you know and.
You know how you can make your operators more productive instead of the mundane or manual task. So you know we can definitely discuss that Andrea and Participant_G.
OK.

Participant_G   1:10:59
Yeah, thank you. That's a good, good plan.

Participant_A   1:11:03
So you guys brought up an interesting point about the needing to be completely offline and and I, you know, going back to our original conversations, you know, some weeks ago.

Participant_C   1:11:18
3.

Participant_A   1:11:18
Ago. Um, that was that was brought up then as well.
So I I'm taking that as as you know, this is a very serious consideration for business continuity.
What is your strategy for how you want to do that?
Like let's start from a big picture and then drill down into specifics because I'm thinking like about things like OK, do you want to continue to refine your? You have to host a model and allow it to run operations the platform, but you still want to push data up into the.
Up into fabric to continue to test the performance of the model. If you go offline, what's your plan for that? You know these kinds of things, so.
You have the floor.

Participant_P   1:12:21
So it's our current plan is to have a kind of like a digital twin. You could say all those inputs, outputs from the ML model are gonna be stored in a historian on Prem so that those values even if the connection gets.

Participant_A   1:12:36
OK.

Participant_P   1:12:40
You know, interrupted to the Internet are being stored and we have access to them on Prem. Additionally, I mean they'll be stored there. We'll have methods to taken out of on Prem to the cloud if we need.
All that historical data, but our MQTT brokers are able to, you know, retain a couple of messages. I can't remember what the limit is, but yeah, so that's kind of our plan as of right now and it's evolving so.

Participant_A   1:13:01
Mhm.

Participant_P   1:13:16
It's in its early stations, but we do have a consulting.
Company that is helping us get to that point and yeah.

Participant_A   1:13:28
OK, so one of the things I'm hearing is, and this is is just a point of interest for me perhaps is is let's say that you know the plant goes loses connection to Internet, your broker is able to cache a lot of those messages until until it regains.
Connectivity and then is able to flush those messages, but at the same time it's feeding them into the local model that's running the plant floor.

Participant_P   1:13:51
Mhm.
Yes and and also storing it in a historian database so.

Participant_A   1:14:02
Got it. Got it.

Participant_P   1:14:03
Yeah.

Participant_A   1:14:05
Um.
The historian database is based on what? That's a that's the one you're using currently. That's SQL based, right?

Participant_P   1:14:17
Yeah, it's a Pi Historian, but I I'd have to talk to the OT guys, but they they'll be moving it to a SQL Server, something like that. I don't know exactly what their plans is, but yeah.

Participant_A   1:14:28
Mhm.
OK. And that, so that's an additional.
Um, let me think about this, but that's how are you scaling that on Prem?
'Cause it sounds like you have a lot of data.

Participant_P   1:14:53
For the oh, can you expand on that question I guess?

Participant_A   1:14:55
Historian.
Yeah, so it sounds like you're also storing this locally on Historian. That was one of your challenges too, is that that database doesn't necessarily scale, but how? How do you? What's your strategy for that?

Participant_P   1:15:14
So I you know, that's kind of like the OT space, but I believe they're gonna keep their Pi historian for all the PLC data and everything's gonna continue to get ingested and it may be that the new SQL warehouse is for.
The what they called the unified namespace and it's a big world, but it they'll potentially have this new historian with.
Calculations on metrics like OEE and all these different metrics they'll they're building in the plans and additionally to that we'll be storing those ML inputs and outputs in that historian specifically.
So I guess there's two options. Either we keep the current historian and we add another historian for calculated metrics and stuff like that ML outputs, or we move all the historian to to the new historian.
And build upon that. How that looks exactly, I'm not sure. It's not something I'm.
Super familiarized on.

Participant_A   1:16:29
OK, it sounds almost like you you need your own data in like mini data center right there on the plant.

Participant_P   1:16:29
Being onrem.

Participant_J   1:16:39
We have a data center at the plant.

Participant_A   1:17:03
Sorry, long silence, but I guess I'm waiting for maybe some more.

Participant_J   1:17:14
Each plan has its own server stack with storage that runs the VMS that run the plant floor.

Participant_A   1:17:23
OK.

Participant_J   1:17:31
So in the case of the current currently running production, it's Rockwell software and the the new stuff that Participant_P is referring to is Ignition.
Software.
For the OT side of the house.

Participant_A   1:17:50
Oh, I see. So different software, which means if you went all to all new one, then that would be its own separate little migration project.

Participant_J   1:18:02
That's correct.

Participant_A   1:18:06
Okay, just staying.

Participant_J   1:18:07
Basically switching architecture of the software that is running the PLCS on the plant floor.

Participant_A   1:18:16
OK.
Hmm, a lot of movie.

Participant_J   1:18:19
So part of the catalyst of all this project was the new, the new receiving area, one of our plants that was built out and that I believe that's the pilot program for the ignition software that's going to be implemented and then it will expand after that project has completed.

Participant_A   1:18:39
Oh, I see. Because I was wondering about the operational operationalization of that, which is how do you ensure that a new software package is meeting all of your your operational expectations, your performance expectations?
Without jeopardizing, which you're already running. So it sounds like you have a new part of the plant that's just running on that part.

Participant_J   1:19:05
Yeah, they're both. We'll be running both stacks in tandem, so the current stuff will not be changing. The new expansion will be running on the new software as the pilot for that software.

Participant_A   1:19:10
Got it.
OK.
Um.
So how does that Participant_P, how does that play into you've got this other these other moving parts with ignition and can't remember the other name you had ignition.

Participant_J   1:19:40
Rockwell.

Participant_A   1:19:43
Rockwell, how do you how do these this, this moving parts between Rockwell and Ignition play into your um?
The operational, how should I put this? How does this play into what you're trying to do with your MQTT broker and all those parts of it?

Participant_P   1:20:10
Yeah. So as part of this Ignition and all these new softwares that we're leveraging, what the OT guys are trying to accomplish is they're trying to build a unified namespace.
Where you essentially take data from everywhere in your plant and put it into an MQTT broker. And so Dell right now how it works is Ignition is connecting to PLCS.
And then they take that data and funnel it to and to the MQTT broker and that's an oversimplification of what happens. But that's just that's in a nutshell what they're doing and so.
All of what you saw in the cloud is based off of what they're building with the new infrastructure, AKA Ignition and Hive MQ, the MQTT broker, so.

Participant_A   1:21:25
Hmm.
So you're assuming, you're assuming going forward that it's all going to be ignition, but that's not where you are right now.
And you're trying to use MQTT broker as a common interface for both systems.

Participant_P   1:21:45
Yeah.

Participant_A   1:21:46
OK. OK. And then you're saying eventually?
Let me get this right. Eventually you're gonna be all entirely on ignition across the entire plant floor, and that at that point you'll bring back your model local, your your, your model, your train model locally, and try to run the plant floor off of that.
uh Entirely locally after you've got, after you're consolidated on ignition.

Participant_P   1:22:21
Correct. So right now in Ignition, they've placed like all of the data for one line, which is where we're building the ML model. And so that's already in place or they're almost done with it.
And so, yeah.

Participant_A   1:22:38
OK. Oh, so you're training off of one line then? I I see. And you did say that before. I just didn't know what that meant until now, I guess, as you've got multiple lines in the same plant, but the other one's all running on Rockwell.

Participant_P   1:22:42
Correct.
Mhm.
Yep.

Participant_J   1:22:58
Yes.

Participant_A   1:22:58
OK, OK.
Interesting.
And how core is the is that one line to your operations?

Participant_P   1:23:17
Yeah, I guess you can't do anything if everything passes through the the flake line. That's kind of like the base product for everything we do.

Participant_A   1:23:31
OK.

Participant_P   1:23:32
Or I guess for real, but yeah.

Participant_A   1:23:37
I mean, I guess you've got your other lines are your core production lines, is that right? And then this line is your OK, we're experimenting and testing and until we get everything like up to like the performance level that you're you're looking for and then you can start really.
Um, trying to to scale that out.

Participant_P   1:23:59
No, this production line is actually in place and it's it's core to the business, so yeah.
We're we're running 24/7.

Participant_A   1:24:11
I see. So if there are any hitches with the performance, then that will actually have a dollar sign next to it.
OK.
That and that's and the but right now you have um.
What is what is running that right now and how are you planning to test that that ML model? Are you just are you me doing? Oh, I OK, I think I understand so right now.
Ignition is your is what's running that line, and you're gonna be comparing the performance of your model against what it's currently doing.

Participant_P   1:25:02
So I don't know that Ignition is running that line. I think that's what.

Participant_A   1:25:05
Welcome.

Participant_J   1:25:07
We haven't went live with that line yet.

Participant_A   1:25:08
OK.

Participant_P   1:25:11
Well, I think we're kinda getting confused a little bit, Participant_J, because the ML model is gonna be built on the flake line, which is the the flake line one. I mean it, it is running right now.

Participant_J   1:25:26
Oh, OK.

Participant_P   1:25:27
But yeah, to your point, they are gonna put ignition there and on the expansion, which is the receiving, right? So.

Participant_J   1:25:37
Yeah, and I was referring to the receiving 'cause that is the new, the new construction that hasn't went live yet. So that's my mistake.

Participant_P   1:25:39
Mhm.
Yeah, no, no, no. And it's, you know, it's something good to bring up. But yeah, so there's a lot of moving components, Participant_A, to to what we're doing right now. But yeah, in a nutshell, ignition will be part of the flake line.

Participant_A   1:26:03
Thanks.

Participant_P   1:26:03
And the receiving and everything right now is being ran based off of Rockwell stuff.

Participant_A   1:26:14
OK, So what one of the things I'm I'm I'm look I'm I'm searching for is.
When you build an ML model, you want to compare it to something that's already working and it needs to meet that level of performance or exceed it, and that's how you know that it's actually.
Where you wanted to be.

Participant_P   1:26:42
Correct.

Participant_A   1:26:44
So how does that, how is, what's your, how is that going to work? How are you doing that?

Participant_P   1:26:51
So we do have a target variable which will be the moisture in the flake that we produce at that line. That's going to be the feature that will I guess focus on on this first ML project and.
And will tell us how well this ML model is working or not. So they'll be doing. Like I said, we do have a consulting firm that is helping us develop this ML model.
They are going to do a soft, I guess release you could say for a lack of better word in that they'll display the outputs of the model in a screen and the operator operators will be able to, you know, compare what they see on the screen versus what the actual.

Participant_A   1:27:31
Mhm.

Participant_P   1:27:45
You know, settings for the machines is at that point in time. And so they'll they'll be able to, you know, get familiarized with the, you know, ML outputs versus what's on the screen and you know, give our consulting firm.
Feedback on what's working, what's not, and then continue to develop that ML model. Once we feel like it's ready for production, then we'll Dockerize it and start feeding those outputs into Ignition so that from that point in time then it.
Moves it or pushes those outputs to to the machines.

Participant_A   1:28:24
OK. And do you think that's gonna be like a one time operation or do you gonna you think you're gonna have to um?
Refine the training of the model over time.

Participant_P   1:28:37
I mean, I hope we'll never have to retrain the model ever again, but that's not very realistic. So yeah, to answer your question, I think there's definitely gonna be some retraining eventually, especially as the process or the production process changes.
Then we'll have to modify the mill model for sure.

Participant_A   1:29:01
Yeah, I mean, I suppose a lot depends on like if we're talking potatoes, like the a lot depends on the product that's going into the machine.

Participant_P   1:29:13
Mm-hmm. Yep.

Participant_A   1:29:13
It has to be able to adapt to, I don't know, different level starch levels in the in the core product that's going in there and that may change based on how the world changes. Who knows?

Participant_P   1:29:28
Yep.

Participant_A   1:29:29
Um, yeah, OK.
OK.
I see and so but you're one of the thing. So one of the things I was searching for I think was that is a place where Power BI reporting might actually be useful is to show.
You know how well the model is output is tracking to.
What the machine is doing when it's doing it right and but instead what I heard was somebody's going to be looking at a screen and manually.
Um, pulling numbers off of it? Did I miss something there?

Participant_P   1:30:19
No, I mean there there's multiple options, right? So you you can display the Power BI report for people that are, you know, not in the plant physically present, right. But it's important also to have our operators be aware.

Participant_A   1:30:33
OK.

Participant_P   1:30:38
Aware of what this ML output or this ML algorithm is doing and so in order to get their feedback we also have things like Redstone or Ignition that is able to display dashboards on.
On the plant itself. So I I mean we don't know at this point, we don't even know if the ML model is going to work out in the end. So but we do have a couple of options as far as reporting, right. I can definitely see us doing some on Prem reporting on the plant on the screen right next.

Participant_A   1:31:15
OK.

Participant_P   1:31:17
To the machine and also some Power BI reporting on the cloud for executives for other people that are not necessarily right next to the machine. That's what I'm trying to get to.

Participant_A   1:31:28
OK, OK.

Participant_P   1:31:33
Yeah. So there's definitely flexibility. We're we're not tied to one specific way of doing things.

Participant_A   1:31:33
Um.
Right.
I'm sorry, say that again.

Participant_P   1:31:45
We're just not we're we're flexible is all I'm saying, yeah.

Participant_A   1:31:49
Got it. Got it.
What is your time horizon for accomplishing all these things? Do you know?

Participant_P   1:32:00
They they talk about the end of the year. I'm not sure exactly. I'm not the project manager, but yeah, sometime within the next year, I guess at the latest. Not very entirely sure.

Participant_A   1:32:17
OK, OK. Um.
I can't think of any more questions. Does anybody else have any?
Have any more questions? Participant_C, Participant_D, I don't know.

Participant_C   1:32:31
Nothing at the moment from me, but definitely there will be follow-ups once we have our internal call.

Participant_A   1:32:38
Yeah.

Participant_D   1:32:39
Yeah, no, I don't have anything else. Hey, Participant_P, are you able to share that diagram? I think somebody had a had a a very clear picture of the workspace. Andre or who was it?

Participant_A   1:32:49
Andre, yeah.

Participant_P   1:32:51
Under, Yep.

Participant_G   1:32:51
I was Andre.

Participant_D   1:32:53
Yeah.

Participant_E   1:32:54
Yeah, as long as you guys are OK looking at something raw and unfinished, I I can get it a little bit closer, but.

Participant_D   1:33:01
Yeah, I think. I think it will help.

Participant_G   1:33:03
It's every architecture picture ever. Yeah.

Participant_D   1:33:06
Yeah, no, I think, I think it helps. It just helps. It helps us like when we, when we have our internal conversations, just kind of visualizing what's going on and then you know it also when we do make recommendations, it'll help us kind of you know.

Participant_C   1:33:08
Thanks.

Participant_D   1:33:22
You know, create documents if we have to write our reference architectures for recommendations.

Participant_A   1:33:30
Yeah, Andre, in our world, everything is a work in progress, so.

Participant_E   1:33:31
Yeah.

Participant_D   1:33:34
Yeah, yeah.

Participant_E   1:33:35
Yeah.

Participant_G   1:33:36
Yeah, 'cause a lot of times it's, you know, phased out.

Participant_E   1:33:37
Yeah.

Participant_A   1:33:38
Yes.

Participant_E   1:33:43
That's true.

Participant_G   1:33:44
Well, that's discontinued. Never mind.

Participant_A   1:33:49
Yeah, yeah.
That.
Do you have any questions for us?

Participant_E   1:34:03
One one of the things that I hope that you guys can advise us with is choice between Power BI reporting off of a like house versus warehouse. I know they used to be very different back in the day when fabric just.
Came out, but all the connections seem to kind of get more same between the two and that's one of the architectural questions that I think that we kind of talked about internally and.
We have our preferences and we're leaning towards one, but just wanted to to throw that out there. That's that's one of the things that we would want to have you guys talk about a little bit maybe in the future.

Participant_A   1:34:53
OK.
I can speak to that. What? But I just out of curiosity, what is your preference? Cause we might be aligned actually.

Participant_E   1:35:04
My personal is Warehouse on the end of it right before the semantic models, but but there is there is obviously like different things like shortcuts between lakehouse to lakehouse.
In different workspaces that is not possible with the warehouse, but then at the same time you have the multi table transactions that are only available in warehouse where you can roll back transactions on updating multiple tables. There's just.

Participant_A   1:35:25
Mhm.

Participant_E   1:35:40
A lot of invisible things that I think you guys would probably know best and I hope you guys could kind of advise us through through that on on our side.

Participant_P   1:35:50
Along with that, which of the two solutions is more capacity efficient? I guess because since we're dealing with capacities, we only have so much computing power and it's important to to know which ones.
More efficient at doing the same task.

Participant_A   1:36:10
Yeah. So are you familiar with Direct Lite then?

Participant_E   1:36:16
Yes.

Participant_G   1:36:16
Yeah.

Participant_A   1:36:17
Yeah, so if you have your semantic model and you're using and you've if you configured your your model to, how should I put this?
So the original Power BI data model was sort of like built on this notion of originally of Analysis Services, SQL Server Analysis Services, the Vertipaq engine, it's expanded a little bit with Power BI.
And then they're really trying to implement a specific type of of compression on the parquet files themselves that in in one like when you're.
That works really well for Power BI so that it's compressed, but it's also optimized for query performance and allows you to do all the same DAX types expressions. Previously it was like.
My experience personally was I lost too much functionality in trying to kind of do a hybrid model where some of the data was queried direct to direct query and and some of it was using like full.
Pulp Powers DAX expressions with Direct Lake you get. You basically get all your DAX, but you don't have to go through the trouble of sucking it in.
Into that analysis service, it stay, the data stays where it is and the you bring the compute to the data essentially. Now I understand that might affect your capacity to some degree. I'm not sure, but we'd have to come back to you on what that would look like.

Participant_E   1:38:07
Mhm.

Participant_A   1:38:16
On how much you actually.
How much reporting demand you would actually have on that over that data, but essentially what that does do is save you the trouble of actually having to move the data.

Participant_E   1:38:31
And there's so many little things like as you were talking, I remember there's like a limitation on the lake house where you can't do calculated columns because the SQL like semantic model, you can't add a calculated column to a data set. Essentially you just got to go upstream.
And add that to the actual. So there's like a lot of these little things and maybe you guys have like a list of them that you could share that we could take and as a team look at them like oh, Warehouse versus Lakehouse. Do we really need to roll back transactions? Yes. No. Do we really need to create calculated columns?
Post fact of the gold layer modeling or do we want to model that before and just just kind of like have that little bit of a back and forth to analyze and then the big big thing like Participant_P said is also capacity utilization because if we do have to do the multiple server engine.
Whatever that's called and it's heavy on performance versus data lake, we might just refrain from do a post modeling and do like a notebook modeling in the data engineering layers, you know, so little bit of a trade-offs that I think are not.

Participant_A   1:39:51
Yeah.

Participant_E   1:39:51
That's readily available, but you guys definitely can tell us so.

Participant_G   1:39:54
Right.

Participant_A   1:39:57
Yeah. So on that front, you know it, the answer is it always depends, of course, but I guess the the considerations are going to be, do you want a lot of control? Do you want like maximum control, but you don't have?
Huge volumes of data because it's actually going to be.
Really summarized in that case, you know, then maybe just pull it into, you know, a typical Power BI data set, right? If you have huge volumes of data though, that you're trying to report off of.
Then Direct Lake is going to really be your friend.
Because the trying to the problem is moving so much data into a Power BI data set, hosting it the the volume of the data, how quickly you can report off of that data with that level of volume the need to use.

Participant_E   1:40:42
Mhm.

Participant_A   1:41:01
You know a Power BI data gateway to get at the data in the 1st place. All of these things start to become a real challenge when you have large volumes of data if if it's very reasonable size though.
Yeah, I would just pull it in and then if you do need all those extra, all those extra.
Features that you might just use DAX expressions to derive columns with then and you and it's the volume of the data is too large to just pull in then yeah you're you're talking about a data engineering effort to basically.
Um.
Not cleanse, but enrich the data. I guess it's the charm.

Participant_E   1:41:50
Mhm.

Participant_A   1:41:52
That's basically it in a nutshell.

Participant_G   1:41:54
I mean too for us, I mean we think we need to consider the users that we're talking about from from both perspective or both tool sets. I mean today there's not a large user group of.
Individuals accessing data at that at either look at except for those who use, you know, Power BI. And yeah, we've got a you've got some, but we need to understand which would be better for X persona. You know, is it?

Participant_A   1:42:14
Mhm.

Participant_G   1:42:30
Because because that's I think what we need to solve and and probably at our Acme-Sub and Andrea and Participant_P and Tona there's there's maybe more more use cases around individuals accessing warehoused or curated data.

Participant_A   1:42:48
OK, so yeah, that becomes a whole that might become a a a separate workshop just to explore the the reporting personas.
I realize we have maybe one hour. I don't know how much people want to, how much time people want to spend going through that, but.
I I'll leave that up to you.
That is. And if you want to have that conversation and you don't think you have all the right people in the room to have that, that particular like persona conversation, then we can totally, you know, come back to that on another day.

Participant_P   1:43:33
Yeah, I I think that would be good. And I would add to that same workshop couple of the issues that we've been undergoing or going through with Fabric notebooks specifically. So I do have a couple of scenarios.
Where one of my notebooks randomly fails and it's been running successfully for a month, fails on that day and successfully runs the days after.
And so scenarios like that that I'm not sure what's going on with Fabric and like when you take a look at the, you know, errors and the run details for for the Pi Spark notebook, there's nothing in there to help me debug what happened or there's.
I've seen errors where the notebook is running for 40 minutes and out of those 40 minutes there's total like 100% of that is total idle time for the notebook. And so it's really hard to debug these specific scenarios because there's not enough.
Of details as to what is going on with the notebook, why it just all of a sudden fails when it's running OK and it continues to run OK after that random day. And that's a big concern on my end as we go.

Participant_A   1:44:49
Mhm.

Participant_P   1:45:02
Deep into fabric. Like right now we only run 5 notebooks, you know, on a daily basis. But what happens when we have to run all these data engineering notebooks? Let's say we have 100. Will those scenarios, you know, those random errors we're getting right now just exponentially?
Increase or or and part of the issue I would like to identify. Is it something that I'm building wrong like some sort of setup that I'm not doing correctly or is it just random errors in fabric in the platform? Because I have seen Reddit.
Um channels where people complain about those issues. So um, that's something I would love to address with you guys and see where you guys can help us get it up to, you know, a production level Um platform.

Participant_Q   1:45:53
Yeah. As a as a follow-up to that too, right, Participant_P is absolutely correct. They see that and we see it a little bit in our environment too. And we're not even as far along as they are in terms of we're in an F64 capacity and we see where it takes time to spin things up and you know we're all forward. This is the direction.
But performance is a really crucial thing in addition to not failing obviously. But if there could be some, maybe even a deep dive doesn't have to be today, but if there's some best practices we can follow or just you know, how are we?
Shaping our our the way we're doing things, you know?

Participant_A   1:46:35
Um, that leads me to a question. Um.
Would you be willing to give us access to some of these environments?
In order to.
I mean for so a couple things there. What I heard was one, we can actually look around and see what you what you're doing in fabric just based on the the original premise of this of this workshop and then.

Participant_Q   1:47:06
Yeah, I'd look for Participant_G and Participant_M to answer that because they're, you know, that's that's their guys. But I would, I would say myself.

Participant_A   1:47:12
Right.
Yeah. And then the the second part is you asked a very specific question about what's happening with specific notebooks and you know, having some access what might allow us to actually look at that real time and with you and see what's going on.

Participant_P   1:47:31
Yeah.

Participant_A   1:47:31
And as a point of curiosity, when you those notebooks, are you running them ad hoc or are you setting them up as jobs?

Participant_P   1:47:42
Their jobs in ADF pipeline, not ADFADF, but like fabric ADF, if you know what I mean.

Participant_A   1:47:46
OK, I wanna.
Right, right. Well, there. Well, there's that. And then I think there's um.

Participant_P   1:47:53
No.

Participant_A   1:47:59
I think there's a a a specific type of job scheduler for for pipelines, but yeah, I was just curious like how you're actually running them so.
OK, OK. Yeah. So get back to me on on access and let or back to us on access and let us know like what's feasible.

Participant_M   1:48:22
Yeah, I mean it's no problem. We've we've done some engagements and some fast track programs with various CloudProviderA teams and then get them at least read access into certain resource groups and subscriptions and and such. So.
Yeah, shouldn't be a problem.

Participant_A   1:48:42
OK, OK.
Great, great.

Participant_Q   1:48:45
I can help facilitate that too if somebody just gives me the the info from an ACME standpoint, but I think Participant_P or which one of you, Participant_P or Andre or do you guys do that as far as workspaces and access?

Participant_P   1:49:03
Yeah, we can. We can work with Participant_J, I believe the one who would help us get the guest account set up or or whatever we want to go with and then we can give them access to the workspace itself.

Participant_Q   1:49:08
OK.

Participant_A   1:49:24
OK.
Um, any more questions for us?

Participant_G   1:49:37
I posted a quick reference guide between the services in in the chat. I know the team here tends to lean towards Warehouse because of the T SQL support versus.

Participant_A   1:49:45
I saw it.

Participant_G   1:49:53
I I think that's, you know, historically we're big T SQL and SQL users, but you know that may be different across Acme-Sub and team may not be that's such a big deal.

Participant_A   1:50:05
Yeah, I'm a big two sequel guy too, so I I get that. I totally get that, yeah.

Participant_G   1:50:14
Though we're all dabbling. We're getting better at the Python pieces, but.

Participant_A   1:50:23
All right. I mean, if if nobody's got any more any more questions, I guess we can wrap it up.
or today.

Participant_Q   1:50:34
This is super helpful for sure.

Participant_B   1:50:34
OK.
Great. That's good to hear. Thanks for the feedback. You know any any additional feedback, you know, feel free to to to reach out if there are things that you think we can do better or you know things you want to see. Thank you, you know, Participant_A, Participant_C, the team and you know all of you for contributing.
I I just want to spend a minute here to look at our, you know, our list of items that we said we would talk about our topics. I don't know if we've exhausted any of these or if if, you know, we can come back to them.
And what what should we be queuing up for for Monday, right. We we I know there's been some mention of Lake House Warehouse one lake you know that maybe that's been somewhat discussed here but I don't know to the extent that you want to what what are the what topics here I don't know.
Participant_A or anyone have any input?
And we can take it offline too, Participant_A, if you want with with Falim in the.

Participant_A   1:51:40
Yeah, I mean, um, you know, something to follow up on with might be um.
Um.
Or is it here?
Like we start getting into semantic models and data set review and that's kind of like we're getting down into very into real specifics. I think that might not be well, you know eventually we will get into that, but that's like.
Going from feature to user story kind of.

Participant_B   1:52:12
Mhm.

Participant_A   1:52:13
Kind of level dashboards, name intervention, reference architecture, comparisons.
Integration landscape, we covered integrations I think pretty well. Fabric capacity, what kind of things we're going to, we're going to go into those workspaces.
We they showed us their current fabric workspace that they're using or workspaces. We haven't talked about purview.

Participant_C   1:52:47
It's not in the scope. Perview is not in the scope.

Participant_D   1:52:48
Yeah, so yeah, I think it was actually removed. Are you guys using something else for like data security or?

Participant_A   1:52:50
Got it. Um, law.

Participant_G   1:52:59
We've got a purview thread with a with another session with CloudProviderA folks.

Participant_D   1:53:04
OK.
OK.

Participant_C   1:53:07
Oh, you do?

Participant_G   1:53:08
Yep, coming up. So I wouldn't. I wouldn't want to waste your time and overlap the team, so.

Participant_C   1:53:09
OK.
Yeah, no, makes sense. Thanks, Participant_G. Yep, Yep, Yep. You know, try to get us access as soon as possible. One of the things that Participant_A asked, right, that will actually help us. So please do that. Whatever you need from us, like, you know, we can use, we can share our CloudProviderA IDs with you. Obviously you already have them.

Participant_D   1:53:17
OK.

Participant_A   1:53:17
And then?

Participant_B   1:53:26
Yeah.

Participant_G   1:53:31
Hmm.

Participant_C   1:53:32
But if you need anything like a phone number for MFA and whatnot, please feel free to, you know, let your PM know and Participant_B will provide that information.

Participant_G   1:53:41
OK.

Participant_A   1:53:42
I think the second to last item on 16 is probably the one space that we haven't really talked about, just logging, monitoring and health checks.

Participant_B   1:53:59
How long do you think we need on that topic? Do you think that's another session? Do you think we want to? Do we have the right audience for it? And and I know there's admins here, but.

Participant_G   1:54:08
Yes.
Hmm.

Participant_B   1:54:12
You want to take a break and.

Participant_G   1:54:12
I think other folks would be interested and it would be interested as well in hearing about some of that I think speaking.

Participant_C   1:54:21
Yeah, it's a 45 minute to an hour session, Participant_B. We can definitely dive into that.

Participant_G   1:54:21
Maybe.

Participant_B   1:54:21
Mhm.
Mm-hmm.
Right. Do you want to take a, you know, 10 minute break and then come back and and and dive into that or do you want to save it for another day? How are people feeling?

Participant_C   1:54:35
Let's do it for some other day.

Participant_B   1:54:38
Yeah.

Participant_C   1:54:38
Yeah.

Participant_G   1:54:39
Yeah, I'm kinda leaning towards that too.

Participant_B   1:54:41
OK, we're getting kind of exhausted here, but it.

Participant_G   1:54:43
I'm getting well, I've been tackled a few times here at my desk. Yeah. Do we have next steps based on what we've heard in this session? I mean, are there some follow-ups that we need?

Participant_Q   1:54:43
That sounds good.

Participant_C   1:54:44
Let's not do it. Let's not do a fire hose.

Participant_B   1:54:48
Oh.
OK. Well, obviously.

Participant_G   1:54:58
Based on what we've seen and discussed.

Participant_C   1:55:06
I have one action item on my side about the mirroring which I will get back to the. Actually I know the answer. You know if you want to try I can provide the steps to you guys if you are interested whoever wants to work and if you tried and worked is great. If not I can definitely help you.

Participant_G   1:55:09
OK.
Mhm.

Participant_C   1:55:24
With those steps as well. So just let me know once I provide the steps how to tackle that and then you know, I think someone already mentioned that the the capacity has been doubled since then. So that's another good news for you guys.

Participant_A   1:55:41
Yeah. So what I'm I'm hearing is, you know, logging, monitoring, health techs might be a good 45 minutes to an hour session. And then I know we've got, we probably want to get into reporting use cases and audiences.

Participant_P   1:55:58
For the logging, monitoring and all that stuff, I don't know if you can make a note there and add that our capacity metrics dashboard or I can't remember exactly what it is, but you know that CloudProviderA Fabric capacity metrics that shows.
You how much capacity you're using at a certain point of time. That thing has been broken and we haven't been able to fix it. We've reinstalled that and try adding back those capacity IDs back into it, but for some reason.
It's broken and we don't know exactly how to fix that one, so that would be awesome to to go through.

Participant_A   1:56:40
Oh.

Participant_Q   1:56:42
That's a good call out and and to even maybe even go into a little deeper on get a more thorough understanding of the metrics in that in that Power BI up.

Participant_C   1:56:58
OK.

Participant_E   1:57:01
Participant_P, as additional topic, did you want to bring up the Fabric ML capabilities into this engagement? I I don't see it on the meeting topics, but I know we've kind of talked about it back and forth.

Participant_P   1:57:19
Yeah, that'll be good to to have, uh, have your perspective on the ML flow experiments, runs and all that stuff that's available in fabric. Like I mentioned earlier, I've been playing a little bit around with it, but uh.
Um.

Participant_A   1:57:37
Yeah.

Participant_P   1:57:38
I'm not an expert, so having your perspective would be awesome.

Participant_A   1:57:42
Yeah, ML OPS. Um, and then.
That that brings into question also as you're working with notebooks or source control and and DevOps deployments and what tools are you using for that?

Participant_E   1:58:05
Yeah, that's something we can definitely talk a bit about. I know we looked into using the deployment pipelines in Fabric when those just got released back in the day and the lack of support for most of the.
Tools kind of dissuade us from that. And here on on either home team, it's only three of us. So we're very small comparatively. But I I mean ACME might be benefiting from something like that a lot more. So up to Participant_G if we want to dive.
Into that a little more or not.

Participant_A   1:58:45
Mm-hmm.
Oh, he's on Participant_G.

Participant_B   1:58:57
Like.

Participant_G   1:58:57
We could, we could take, we could take this offline, talk to talk amongst the team to see.

Participant_B   1:58:59
Yep.
OK.

Participant_A   1:59:02
OK, OK.

Participant_B   1:59:05
Any other, any other topics, any anything else you think we should hit on next time? And so the next time would I and I'll I'll ask, you know is it the same audience Participant_R for for all these sessions? Should I just set out the meeting notices for all the sessions or I could set at least Monday or or next?
Next week's sessions, if you'd like.

Participant_R   1:59:27
Yeah, I think we'll do some internal discussions too on making sure the right people are at the right meetings. We we included everybody today for the first one just to kind of see how it how it goes. Yeah, if you if you can just send out the the list, we can kind of manage the or excuse me, send out the invite, we can kind of manage the.

Participant_B   1:59:36
OK.

Participant_R   1:59:44
The attendees. That works for you, Participant_B.

Participant_B   1:59:46
OK. Yeah, I think you have Monday's meet. Oh, maybe you don't. OK, I'll add you to the list and then you can add them, OK.

Participant_R   1:59:52
OK.

Participant_A   1:59:59
Yes.

Participant_B   2:00:00
OK.
Well, if you think of anything, when you have your internal discussions, if there's anything else that comes to mind that you want to add in for Monday, right, we will kind of do a recap what I'll be doing and and often if there's an opportunity also to share the recording with you, the A I notes and and the recording.
You know that could be taken back and if there's something that's comes to mind that you want to add to the agenda, please, you know, speak up and we'll we'll make sure we're prepared for that as well.
You know, so that that'll be for Monday.
Anything else?

Participant_R   2:00:40
Participant_B, I'll reach out. I'm gonna meet with Participant_J here tomorrow to to look at getting a SharePoint set up so we can do some of that note and recording sharing.

Participant_B   2:00:49
OK.
Perfect. OK, great. Well, listen, thank you everyone. We'll give you probably around 55 minutes back and good session. It will, you know, bring, bring your thoughts, bring your your questions and let's shoot for Monday.
To to continue the discussions.

Participant_B stopped transcription